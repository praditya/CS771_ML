{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Submit_Prox_Harsh.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OQbhqJNIqsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loOC6n9-JFg3",
        "colab_type": "code",
        "outputId": "e0c28d75-58fe-430d-8a13-24b6e1c8c2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8GdjO-9Io-Q",
        "colab_type": "code",
        "outputId": "7c73d835-c5e9-473b-a628-1da1e40a3212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "#  PROX GD SOLVE\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "import time as tm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "# SUBMIT YOUR CODE AS A SINGLE PYTHON (.PY) FILE INSIDE A ZIP ARCHIVE\n",
        "# THE NAME OF THE PYTHON FILE MUST BE SUBMIT.PY\n",
        "# DO NOT INCLUDE PACKAGES LIKE SKLEARN, SCIPY, KERAS ETC IN YOUR CODE\n",
        "# THE USE OF ANY MACHINE LEARNING LIBRARIES FOR WHATEVER REASON WILL RESULT IN A STRAIGHT ZERO\n",
        "# THIS IS BECAUSE THESE PACKAGES CONTAIN SOLVERS WHICH MAKE THIS ASSIGNMENT TRIVIAL\n",
        "\n",
        "# DO NOT CHANGE THE NAME OF THE METHOD \"solver\" BELOW. THIS ACTS AS THE MAIN METHOD AND\n",
        "# WILL BE INVOKED BY THE EVALUATION SCRIPT. CHANGING THIS NAME WILL CAUSE EVALUATION FAILURES\n",
        "\n",
        "\n",
        "def stepLengthGenerator(mode, eta):\n",
        "    if mode == \"constant\":\n",
        "        return lambda t: eta\n",
        "    elif mode == \"linear\":\n",
        "        return lambda t: eta/(t+1)\n",
        "    elif mode == \"quadratic\":\n",
        "        return lambda t: eta/np.sqrt(t+1)\n",
        "\n",
        "# You may define any new functions, variables, classes here\n",
        "# For example, functions to calculate next coordinate or step length\n",
        "def normalGD(X, y, w):\n",
        "    value=2*((X.T)@(X@w-y))\n",
        "    return value\n",
        "\n",
        "def LassoGD(X, y, wHat):\n",
        "    res = X.dot(wHat)-y\n",
        "    GradL = (np.sign(wHat))+2*X.T.dot(res)\n",
        "    return GradL\n",
        "\n",
        "def Softhreshold(w,StepFunc,t):\n",
        "    alpha = StepFunc(t)\n",
        "    # alpha = stepLengthGenerator( \"linear\", eta )\n",
        "    prox = np.zeros_like(w)\n",
        "    for i in range(len(w)):\n",
        "        if w[i] > alpha:\n",
        "            prox[i] = w[i]-alpha\n",
        "        elif w[i] < -alpha:\n",
        "            prox[i] = w[i]+alpha\n",
        "        else:\n",
        "            prox[i] = 0\n",
        "    return prox\n",
        "\n",
        "def DoGD(X,y,w,stepFunc,t):\n",
        "    g = LassoGD(X, y, w)\n",
        "    w = w-stepFunc(t)*g\n",
        "    return w\n",
        "\n",
        "def DoProxGD(X,y,w,StepFunc,t):\n",
        "    g=normalGD(X,y,w)\n",
        "    alpha = StepFunc(t)\n",
        "    w_new=Softhreshold(w-alpha*g,StepFunc,t)\n",
        "    return w_new\n",
        "\n",
        "def DoCD(X,y,w,StepFunc,t):\n",
        "    alpha = 1\n",
        "    (n, d) = X.shape\n",
        "    z  = np.sum(X**2,axis=0)\n",
        "    # used 'a' for random permutation CD \n",
        "    a = np.random.permutation(d)\n",
        "    for j in range(d):\n",
        "        # pho = 0\n",
        "        j = a[j]\n",
        "        Xj = X[:,j]\n",
        "        res = y-X.dot(w)+w[j]*Xj\n",
        "        pho = Xj.T.dot(res)\n",
        "        g = -2*pho + 2*w[j]*z[j]+alpha*np.sign(w[j])\n",
        "        w[j] = w[j]-StepFunc(t)*g \n",
        "    return w     \n",
        "    # gt =\n",
        "    # w[i]=w[i]-StepFunc(t)*gt\n",
        "    # np.put(w,i,w[i])\n",
        "\n",
        "def getObjValue(X, y, wHat):\n",
        "    lassoLoss = np.linalg.norm(wHat, 1) + pow(np.linalg.norm(X.dot(wHat) - y, 2), 2)\n",
        "    return lassoLoss\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "\n",
        "\n",
        "def solver(X, y, timeout, spacing, eta):\n",
        "    (n, d) = X.shape\n",
        "    t = 0\n",
        "    totTime = 0\n",
        "\n",
        "    # w is the model vector and will get returned once timeout happens\n",
        "    # w = 1.5*np.ones((d,))\n",
        "    w = np.zeros((d,))\n",
        "    tic = tm.perf_counter()\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "    # You may reinitialize w to your liking here\n",
        "    # You may also define new variables here e.g. step_length, mini-batch size etc\n",
        "    # eta = 5e-3\n",
        "    # takes time around 10\n",
        "    \n",
        "    # eta = 0.01\n",
        "    # above value and quadratic for GD\n",
        "    # allowed to take such large step?\n",
        "    \n",
        "    # eta = 0.32\n",
        "    # above value and linear for CD \n",
        "    \n",
        "    B = 100\n",
        "    # GD works well with quadratic step function\n",
        "    stepFunc = stepLengthGenerator( \"constant\", eta )\n",
        "\n",
        "    # coordinateGenerator(mode, d)\n",
        "\n",
        "    # w = np.ones((d,))\n",
        "    objValseries = []\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "    while True:\n",
        "        t = t + 1\n",
        "        if t % spacing == 0:\n",
        "            toc = tm.perf_counter()\n",
        "            totTime = totTime + (toc - tic)\n",
        "            if totTime > timeout:\n",
        "                return (w, totTime, objValseries)\n",
        "            else:\n",
        "                tic = tm.perf_counter()\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "\n",
        "        # w = DoGD(X,y,w,stepFunc,t)\n",
        "        w = DoProxGD(X,y,w,stepFunc,t)\n",
        "        # w = DoCD(X,y,w,stepFunc,t)\n",
        "\n",
        "        objValseries = np.append(objValseries,getObjValue(X,y,w))\n",
        "    # Write all code to perform your method updates here within the infinite while loop\n",
        "    # The infinite loop will terminate once timeout is reached\n",
        "    # Do not try to bypass the timer check e.g. by using continue\n",
        "    # It is very easy for us to detect such bypasses which will be strictly penalized\n",
        "\n",
        "    # Please note that once timeout is reached, the code will simply return w\n",
        "    # Thus, if you wish to return the average model (as is sometimes done for GD),\n",
        "    # you need to make sure that w stores the average at all times\n",
        "    # One way to do so is to define a \"running\" variable w_run\n",
        "    # Make all GD updates to w_run e.g. w_run = w_run - step * delw\n",
        "    # Then use a running average formula to update w\n",
        "    # w = (w * (t-1) + w_run)/t\n",
        "    # This way, w will always store the average and can be returned at any time\n",
        "    # In this scheme, w plays the role of the \"cumulative\" variable in the course module optLib\n",
        "    # w_run on the other hand, plays the role of the \"theta\" variable in the course module optLib\n",
        "\n",
        "    return (w, totTime, objValseries)  # This return statement will never be reached\n",
        "\n",
        "\n",
        "\n",
        "N = 100\n",
        "eta = np.linspace(0.1,0.34,N)\n",
        "# # eta = [0.5]\n",
        "# eta = [0.376]\n",
        "eta=[0.09]\n",
        "# eta =0.04 constant 37 1\n",
        "# eta 0.3 linear 2 41\n",
        "traindata = np.loadtxt( \"/content/drive/My Drive/assn1/train\" )\n",
        "wAst = np.loadtxt( \"/content/drive/My Drive/assn1 (1)/assn1/wAstTrain\" )\n",
        "k = 20\n",
        "# objValseries = []\n",
        "y = traindata[:,0]\n",
        "X = traindata[:,1:]\n",
        "\n",
        "ObjValBest = getObjValue(X,y,wAst)\n",
        "\n",
        "# Tuning eta\n",
        "min1 = 1000\n",
        "min2 = 1000\n",
        "\n",
        "for i in range(1):\n",
        "    \n",
        "    (w,totTime,objValseries)=solver(X,y,0.1,10,eta[i])\n",
        "# print (w)\n",
        "    wsparse_idx = np.argsort( np.abs(w) )[::-1][:20]\n",
        "    w2 = w[wsparse_idx]\n",
        "    \n",
        "    wreduce_idx = np.argsort( np.abs(w) )[0:799]\n",
        "    w[wreduce_idx] = 0\n",
        "    ObjCal = getObjValue(X,y,w)\n",
        "# removing the remaining indices from w\n",
        "# w1 = w\n",
        "# np.put(w1,wsparse_idx,np.zeros(20))\n",
        "#\n",
        "# wsparse = w - w1\n",
        "# print (w)\n",
        "    \n",
        "    norm1 = np.linalg.norm(w,2)\n",
        "    normBest = np.linalg.norm(wAst,2)\n",
        "    \n",
        "    if np.abs(ObjValBest-ObjCal) < min1:\n",
        "        min1 =  np.abs(ObjValBest-ObjCal)\n",
        "        eta_cr_o = eta[i]\n",
        "        ObjCal1 = ObjCal\n",
        "    \n",
        "    if np.abs(norm1 - normBest) < min2:\n",
        "        min2 = np.abs(norm1 - normBest)\n",
        "        eta_cr = eta[i]\n",
        "    \n",
        "    idxAst = np.abs(wAst).argsort()[::-1][:k]\n",
        "    idxHat = np.abs(w).argsort()[::-1][:k]\n",
        "    a = np.zeros_like( wAst )\n",
        "    a[idxAst] = 1\n",
        "    b = np.zeros_like( wAst )\n",
        "    b[idxHat] = 1\n",
        "    min3 = np.linalg.norm( a - b, 1 )//2\n",
        "    # print (normBest,norm1)\n",
        "    # print (ObjValBest,objValseries[-1])\n",
        "    print (i)\n",
        "\n",
        "print (eta_cr,eta_cr_o,min1,min2,min3,ObjCal1)\n",
        "\n",
        "# Plot the objective value function\n",
        "plt.plot(objValseries)\n",
        "plt.show()\n",
        "\n",
        "# bJw9dPi8bZPSCTM\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0.09000000000000001 0.034 1000 1000 19.0 37.97997968209439\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG5haAFUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZVl2gS_Io-d",
        "colab_type": "code",
        "outputId": "d3fc630c-3d60-4d4c-fac3-755d0be5c7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Coordinate Descent\n",
        "\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "# SUBMIT YOUR CODE AS A SINGLE PYTHON (.PY) FILE INSIDE A ZIP ARCHIVE\n",
        "# THE NAME OF THE PYTHON FILE MUST BE SUBMIT.PY\n",
        "# DO NOT INCLUDE PACKAGES LIKE SKLEARN, SCIPY, KERAS ETC IN YOUR CODE\n",
        "# THE USE OF ANY MACHINE LEARNING LIBRARIES FOR WHATEVER REASON WILL RESULT IN A STRAIGHT ZERO\n",
        "# THIS IS BECAUSE THESE PACKAGES CONTAIN SOLVERS WHICH MAKE THIS ASSIGNMENT TRIVIAL\n",
        "\n",
        "# DO NOT CHANGE THE NAME OF THE METHOD \"solver\" BELOW. THIS ACTS AS THE MAIN METHOD AND\n",
        "# WILL BE INVOKED BY THE EVALUATION SCRIPT. CHANGING THIS NAME WILL CAUSE EVALUATION FAILURES\n",
        "\n",
        "\n",
        "def stepLengthGenerator(mode, eta):\n",
        "    if mode == \"constant\":\n",
        "        return lambda t: eta\n",
        "    elif mode == \"linear\":\n",
        "        return lambda t: eta/(t+1)\n",
        "    elif mode == \"quadratic\":\n",
        "        return lambda t: eta/np.sqrt(t+1)\n",
        "\n",
        "# You may define any new functions, variables, classes here\n",
        "# For example, functions to calculate next coordinate or step length\n",
        "def LassoGD(X, y, wHat):\n",
        "    res = X.dot(wHat)-y\n",
        "    GradL = (np.sign(wHat))+2*X.T.dot(res)\n",
        "    return GradL\n",
        "\n",
        "def Softhreshold(w,stepFunc,t):\n",
        "    # alpha = stepFunc(t)\n",
        "    # alpha = stepLengthGenerator( \"linear\", eta )\n",
        "    prox = np.zeros_like(w)\n",
        "    for i in range(len(w)):\n",
        "        if w[i] > alpha:\n",
        "            prox[i] = w[i]-alpha\n",
        "        elif w[i] < -alpha:\n",
        "            prox[i] = w[i]+alpha\n",
        "        else:\n",
        "            prox[i] = 0\n",
        "    return prox\n",
        "\n",
        "def DoGD(X,y,w,stepFunc,t):\n",
        "    g = LassoGD(X, y, w)\n",
        "    w = w-stepFunc(t)*g\n",
        "    return w\n",
        "\n",
        "def DoProxGD(X,y,w,stepFunc,t):\n",
        "    res = X.dot(w)-y\n",
        "    wp = w-stepFunc(t)*X.T.dot(res)\n",
        "    prox1 = Softhreshold(wp,stepFunc,t)\n",
        "    return prox1\n",
        "\n",
        "def DoCD(X,y,w,StepFunc,t):\n",
        "    alpha = 1\n",
        "    (n, d) = X.shape\n",
        "    z  = np.sum(X**2,axis=0)\n",
        "    # used 'a' for random permutation CD \n",
        "    a = np.random.permutation(d)\n",
        "    for j in range(d):\n",
        "        # pho = 0\n",
        "        j = a[j]\n",
        "        Xj = X[:,j]\n",
        "        res = y-X.dot(w)+w[j]*Xj\n",
        "        pho = Xj.T.dot(res)\n",
        "        # for i in range(n):\n",
        "        #     if i!=j:\n",
        "        #         pho = pho + X[i][j]*(y[i]-y[i]*w[j])\n",
        "        #     else:\n",
        "        #         pho = pho + X[i][j]*y[i]\n",
        "        # if pho < -alpha/2:\n",
        "        #     w[j] = (pho + alpha/2)/z[j]\n",
        "        # elif pho > alpha/2:\n",
        "        #     w[j] = (pho - alpha/2)/z[j]\n",
        "        # else:\n",
        "        #     w[j] = 0\n",
        "        g = -2*pho + 2*w[j]*z[j]+alpha*np.sign(w[j])\n",
        "        w[j] = w[j]-StepFunc(t)*g \n",
        "    return w     \n",
        "    # gt =\n",
        "    # w[i]=w[i]-StepFunc(t)*gt\n",
        "    # np.put(w,i,w[i])\n",
        "\n",
        "def getObjValue(X, y, wHat):\n",
        "    lassoLoss = np.linalg.norm(wHat, 1) + pow(np.linalg.norm(X.dot(wHat) - y, 2), 2)\n",
        "    return lassoLoss\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "\n",
        "\n",
        "def solver(X, y, timeout, spacing):\n",
        "    (n, d) = X.shape\n",
        "    t = 0\n",
        "    totTime = 0\n",
        "\n",
        "    # w is the model vector and will get returned once timeout happens\n",
        "    # w = 1.5*np.ones((d,))\n",
        "    w = np.zeros((d,))\n",
        "    tic = tm.perf_counter()\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "    # You may reinitialize w to your liking here\n",
        "    # You may also define new variables here e.g. step_length, mini-batch size etc\n",
        "    # eta = 5e-3\n",
        "    # takes time around 10\n",
        "    \n",
        "    # eta = 0.01\n",
        "    # above value and quadratic for GD\n",
        "    # allowed to take such large step?\n",
        "    eta = 0.24646\n",
        "    # above value and linear for CD \n",
        "    B = 100\n",
        "    # GD works well with quadratic step function\n",
        "    stepFunc = stepLengthGenerator( \"linear\", eta )\n",
        "\n",
        "    # coordinateGenerator(mode, d)\n",
        "\n",
        "    # w = np.ones((d,))\n",
        "    objValseries = []\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "    while True:\n",
        "        t = t + 1\n",
        "        if t % spacing == 0:\n",
        "            toc = tm.perf_counter()\n",
        "            totTime = totTime + (toc - tic)\n",
        "            if totTime > timeout:\n",
        "                return (w, totTime, objValseries)\n",
        "            else:\n",
        "                tic = tm.perf_counter()\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "\n",
        "        # w = DoGD(X,y,w,stepFunc,t)\n",
        "        # w = DoProxGD(X,y,w,stepFunc,t)\n",
        "        w = DoCD(X,y,w,stepFunc,t)\n",
        "        objValseries = np.append(objValseries,getObjValue(X,y,w))\n",
        "    # Write all code to perform your method updates here within the infinite while loop\n",
        "    # The infinite loop will terminate once timeout is reached\n",
        "    # Do not try to bypass the timer check e.g. by using continue\n",
        "    # It is very easy for us to detect such bypasses which will be strictly penalized\n",
        "\n",
        "    # Please note that once timeout is reached, the code will simply return w\n",
        "    # Thus, if you wish to return the average model (as is sometimes done for GD),\n",
        "    # you need to make sure that w stores the average at all times\n",
        "    # One way to do so is to define a \"running\" variable w_run\n",
        "    # Make all GD updates to w_run e.g. w_run = w_run - step * delw\n",
        "    # Then use a running average formula to update w\n",
        "    # w = (w * (t-1) + w_run)/t\n",
        "    # This way, w will always store the average and can be returned at any time\n",
        "    # In this scheme, w plays the role of the \"cumulative\" variable in the course module optLib\n",
        "    # w_run on the other hand, plays the role of the \"theta\" variable in the course module optLib\n",
        "\n",
        "    return (w, totTime, objValseries)  # This return statement will never be reached\n",
        "\n",
        "\n",
        "traindata = np.loadtxt( \"/content/drive/My Drive/assn1/train\" )\n",
        "wAst = np.loadtxt( \"/content/drive/My Drive/assn1 (1)/assn1/wAstTrain\" )\n",
        "# wAst = np.loadtxt( \"wAstTrain\" )\n",
        "k = 20\n",
        "# objValseries = []\n",
        "y = traindata[:,0]\n",
        "X = traindata[:,1:]\n",
        "\n",
        "ObjValBest = getObjValue(X,y,wAst)\n",
        "\n",
        "(w,totTime,objValseries)=solver(X,y,10,10)\n",
        "# print (w)\n",
        "wsparse_idx = np.argsort( np.abs(w) )[::-1][:20]\n",
        "w2 = w[wsparse_idx]\n",
        "    \n",
        "wreduce_idx = np.argsort( np.abs(w) )[0:799]\n",
        "w[wreduce_idx] = 0\n",
        "ObjCal = getObjValue(X,y,w)\n",
        "    \n",
        "norm1 = np.linalg.norm(w,2)\n",
        "normBest = np.linalg.norm(wAst,2)\n",
        "    \n",
        "idxAst = np.abs(wAst).argsort()[::-1][:k]\n",
        "idxHat = np.abs(w).argsort()[::-1][:k]\n",
        "a = np.zeros_like( wAst )\n",
        "a[idxAst] = 1\n",
        "b = np.zeros_like( wAst )\n",
        "b[idxHat] = 1\n",
        "diff_ind = np.linalg.norm( a - b, 1 )//2\n",
        "\n",
        "print (diff_ind,ObjCal)\n",
        "\n",
        "# Plot the objective value function\n",
        "# plt.plot(objValseries)\n",
        "# plt.show()\n",
        "\n",
        "# bJw9dPi8bZPSCTM"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.0 45.42452684053798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnJEFUyeMMSO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "53a80ade-23f5-49ac-a622-ec1f0ed35646"
      },
      "source": [
        "# Tuning of eta\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "import time as tm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "# SUBMIT YOUR CODE AS A SINGLE PYTHON (.PY) FILE INSIDE A ZIP ARCHIVE\n",
        "# THE NAME OF THE PYTHON FILE MUST BE SUBMIT.PY\n",
        "# DO NOT INCLUDE PACKAGES LIKE SKLEARN, SCIPY, KERAS ETC IN YOUR CODE\n",
        "# THE USE OF ANY MACHINE LEARNING LIBRARIES FOR WHATEVER REASON WILL RESULT IN A STRAIGHT ZERO\n",
        "# THIS IS BECAUSE THESE PACKAGES CONTAIN SOLVERS WHICH MAKE THIS ASSIGNMENT TRIVIAL\n",
        "\n",
        "# DO NOT CHANGE THE NAME OF THE METHOD \"solver\" BELOW. THIS ACTS AS THE MAIN METHOD AND\n",
        "# WILL BE INVOKED BY THE EVALUATION SCRIPT. CHANGING THIS NAME WILL CAUSE EVALUATION FAILURES\n",
        "\n",
        "\n",
        "def stepLengthGenerator(mode, eta):\n",
        "    if mode == \"constant\":\n",
        "        return lambda t: eta\n",
        "    elif mode == \"linear\":\n",
        "        return lambda t: eta/(t+1)\n",
        "    elif mode == \"quadratic\":\n",
        "        return lambda t: eta/np.sqrt(t+1)\n",
        "\n",
        "# You may define any new functions, variables, classes here\n",
        "# For example, functions to calculate next coordinate or step length\n",
        "def normalGD(X, y, w):\n",
        "    value=2*((X.T)@(X@w-y))\n",
        "    return value\n",
        "\n",
        "def LassoGD(X, y, wHat):\n",
        "    res = X.dot(wHat)-y\n",
        "    GradL = (np.sign(wHat))+2*X.T.dot(res)\n",
        "    return GradL\n",
        "\n",
        "def Softhreshold(w,StepFunc,t):\n",
        "    alpha = StepFunc(t)\n",
        "    # alpha = stepLengthGenerator( \"linear\", eta )\n",
        "    prox = np.zeros_like(w)\n",
        "    for i in range(len(w)):\n",
        "        if w[i] > alpha:\n",
        "            prox[i] = w[i]-alpha\n",
        "        elif w[i] < -alpha:\n",
        "            prox[i] = w[i]+alpha\n",
        "        else:\n",
        "            prox[i] = 0\n",
        "    return prox\n",
        "\n",
        "def DoGD(X,y,w,stepFunc,t):\n",
        "    g = LassoGD(X, y, w)\n",
        "    w = w-stepFunc(t)*g\n",
        "    return w\n",
        "\n",
        "def DoProxGD(X,y,w,StepFunc,t):\n",
        "    g=normalGD(X,y,w)\n",
        "    alpha = StepFunc(t)\n",
        "    w_new=Softhreshold(w-alpha*g,StepFunc,t)\n",
        "    return w_new\n",
        "\n",
        "def DoCD(X,y,w,StepFunc,t):\n",
        "    alpha = 1\n",
        "    (n, d) = X.shape\n",
        "    z  = np.sum(X**2,axis=0)\n",
        "    # used 'a' for random permutation CD \n",
        "    a = np.random.permutation(d)\n",
        "    for j in range(d):\n",
        "        # pho = 0\n",
        "        j = a[j]\n",
        "        Xj = X[:,j]\n",
        "        res = y-X.dot(w)+w[j]*Xj\n",
        "        pho = Xj.T.dot(res)\n",
        "        g = -2*pho + 2*w[j]*z[j]+alpha*np.sign(w[j])\n",
        "        w[j] = w[j]-StepFunc(t)*g \n",
        "    return w     \n",
        "    # gt =\n",
        "    # w[i]=w[i]-StepFunc(t)*gt\n",
        "    # np.put(w,i,w[i])\n",
        "\n",
        "def getObjValue(X, y, wHat):\n",
        "    lassoLoss = np.linalg.norm(wHat, 1) + pow(np.linalg.norm(X.dot(wHat) - y, 2), 2)\n",
        "    return lassoLoss\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "\n",
        "\n",
        "def solver(X, y, timeout, spacing, eta):\n",
        "    (n, d) = X.shape\n",
        "    t = 0\n",
        "    totTime = 0\n",
        "\n",
        "    # w is the model vector and will get returned once timeout happens\n",
        "    # w = 1.5*np.ones((d,))\n",
        "    w = np.zeros((d,))\n",
        "    tic = tm.perf_counter()\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "    # You may reinitialize w to your liking here\n",
        "    # You may also define new variables here e.g. step_length, mini-batch size etc\n",
        "    # eta = 5e-3\n",
        "    # takes time around 10\n",
        "    \n",
        "    # eta = 0.01\n",
        "    # above value and quadratic for GD\n",
        "    # allowed to take such large step?\n",
        "    \n",
        "    # eta = 0.32\n",
        "    # above value and linear for CD \n",
        "    \n",
        "    B = 100\n",
        "    # GD works well with quadratic step function\n",
        "    stepFunc = stepLengthGenerator( \"constant\", eta )\n",
        "\n",
        "    # coordinateGenerator(mode, d)\n",
        "\n",
        "    # w = np.ones((d,))\n",
        "    objValseries = []\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "    while True:\n",
        "        t = t + 1\n",
        "        if t % spacing == 0:\n",
        "            toc = tm.perf_counter()\n",
        "            totTime = totTime + (toc - tic)\n",
        "            if totTime > timeout:\n",
        "                return (w, totTime, objValseries)\n",
        "            else:\n",
        "                tic = tm.perf_counter()\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "\n",
        "        # w = DoGD(X,y,w,stepFunc,t)\n",
        "        w = DoProxGD(X,y,w,stepFunc,t)\n",
        "        # w = DoCD(X,y,w,stepFunc,t)\n",
        "\n",
        "        objValseries = np.append(objValseries,getObjValue(X,y,w))\n",
        "    # Write all code to perform your method updates here within the infinite while loop\n",
        "    # The infinite loop will terminate once timeout is reached\n",
        "    # Do not try to bypass the timer check e.g. by using continue\n",
        "    # It is very easy for us to detect such bypasses which will be strictly penalized\n",
        "\n",
        "    # Please note that once timeout is reached, the code will simply return w\n",
        "    # Thus, if you wish to return the average model (as is sometimes done for GD),\n",
        "    # you need to make sure that w stores the average at all times\n",
        "    # One way to do so is to define a \"running\" variable w_run\n",
        "    # Make all GD updates to w_run e.g. w_run = w_run - step * delw\n",
        "    # Then use a running average formula to update w\n",
        "    # w = (w * (t-1) + w_run)/t\n",
        "    # This way, w will always store the average and can be returned at any time\n",
        "    # In this scheme, w plays the role of the \"cumulative\" variable in the course module optLib\n",
        "    # w_run on the other hand, plays the role of the \"theta\" variable in the course module optLib\n",
        "\n",
        "    return (w, totTime, objValseries)  # This return statement will never be reached\n",
        "\n",
        "\n",
        "\n",
        "# cross-validation\n",
        "k_f=5\n",
        "idx=np.arange(800)\n",
        "data = np.loadtxt( \"/content/drive/My Drive/assn1/train\" )\n",
        "wAst = np.loadtxt( \"/content/drive/My Drive/assn1 (1)/assn1/wAstTrain\" )\n",
        "k = 20\n",
        "N = 100\n",
        "eta = np.linspace(0.01,0.1,N)\n",
        "# objValseries = []\n",
        "y = data[:,0]\n",
        "X = data[:,1:]\n",
        "splits=np.split(idx, 5)\n",
        "# w_f=w_0\n",
        "val_f=np.ones(6)\n",
        "\n",
        "min3 = 1000\n",
        "\n",
        "for j in range(N):\n",
        "  \n",
        "  Y_err = 0\n",
        "\n",
        "  for i in range(k_f):\n",
        "    \n",
        "    X_test=X[splits[i]]\n",
        "    X_train=X[~np.isin(idx,splits[i])]\n",
        "    y_test=y[splits[i]]\n",
        "    y_train=y[~np.isin(idx,splits[i])]\n",
        "\n",
        "\n",
        "    # N = 100\n",
        "    # eta = np.linspace(0.1,0.34,N)\n",
        "    # # eta = [0.5]\n",
        "    # eta = [0.376]\n",
        "    # eta=[0.06]\n",
        "    # eta =0.04 constant 37 1\n",
        "    # eta 0.3 linear 2 41\n",
        "\n",
        "    ObjValBest = getObjValue(X,y,wAst)\n",
        "\n",
        "    # Tuning eta\n",
        "    # min1 = 1000\n",
        "    # min2 = 1000\n",
        "\n",
        "    (w,totTime,objValseries)=solver(X_train,y_train,0.1,10,eta[j])\n",
        "    # print (w)\n",
        "\n",
        "    # wsparse_idx = np.argsort( np.abs(w) )[::-1][:20]\n",
        "    # w2 = w[wsparse_idx]\n",
        "\n",
        "    wreduce_idx = np.argsort( np.abs(w) )[0:799]\n",
        "    w[wreduce_idx] = 0\n",
        "\n",
        "    ObjTest = getObjValue(X_test,y_test,w)\n",
        "    Y_err = Y_err + np.linalg.norm(X_test.dot(w)-y_test)\n",
        "\n",
        "\n",
        "\n",
        "  if Y_err < min3:\n",
        "    min3 = Y_err\n",
        "    eta_cr = eta[j]\n",
        "    Y_cr = Y_err\n",
        "  # ObjCal = getObjValue(X,y,w)\n",
        "  # removing the remaining indices from w\n",
        "  # w1 = w\n",
        "  # np.put(w1,wsparse_idx,np.zeros(20))\n",
        "  #\n",
        "  # plt.plot(objValseries)\n",
        "  # plt.show()\n",
        "  # wsparse = w - w1\n",
        "  print (j)\n",
        "\n",
        "print(eta_cr,min3)\n",
        "#   norm1 = np.linalg.norm(w,2)\n",
        "#   normBest = np.linalg.norm(wAst,2)\n",
        "\n",
        "#   if np.abs(ObjValBest-ObjCal) < min1:\n",
        "#     min1 =  np.abs(ObjValBest-ObjCal)\n",
        "#     eta_cr_o = eta[i]\n",
        "#     ObjCal1 = ObjCal\n",
        "\n",
        "#   if np.abs(norm1 - normBest) < min2:\n",
        "#     min2 = np.abs(norm1 - normBest)\n",
        "#     eta_cr = eta[i]\n",
        "\n",
        "#   idxAst = np.abs(wAst).argsort()[::-1][:k]\n",
        "#   idxHat = np.abs(w).argsort()[::-1][:k]\n",
        "#   a = np.zeros_like( wAst )\n",
        "#   a[idxAst] = 1\n",
        "#   b = np.zeros_like( wAst )\n",
        "#   b[idxHat] = 1\n",
        "#   min3 = np.linalg.norm( a - b, 1 )//2\n",
        "#   # print (normBest,norm1)\n",
        "#   # print (ObjValBest,objValseries[-1])\n",
        "#   print (i)\n",
        "\n",
        "# print (eta_cr,eta_cr_o,min1,min2,min3,ObjCal1)\n",
        "\n",
        "# # Plot the objective value function\n",
        "# plt.plot(objValseries)\n",
        "# plt.show()\n",
        "\n",
        "# bJw9dPi8bZPSCTM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "0.09000000000000001 10.146170730700945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_zTTXTxPTDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6000ebbd-d156-416f-f778-d435e0f6da40"
      },
      "source": [
        "print(np.linalg.norm(X.dot(wAst)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15.55549578433654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKUakDAmQ4BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}