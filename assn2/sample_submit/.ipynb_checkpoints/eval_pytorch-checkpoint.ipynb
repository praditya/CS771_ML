{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import predict\n",
    "import time as tm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.datasets import make_classification\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# from w2v import *\n",
    "# from embedding_layer import embedding_layer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.io as sio\n",
    "from scipy import sparse\n",
    "import argparse\n",
    "from visdom import Visdom\n",
    "from sklearn.externals import joblib \n",
    "# from futils import *\n",
    "# from loss import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Data\n",
    "dictSize = 225\n",
    "(X, y) = utils.loadData( \"train\", dictSize = dictSize )\n",
    "X = scipy.sparse.csr_matrix.toarray(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/multi-class-classification/47565\n",
    "# https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            outp = self.forward(x)\n",
    "            return F.softmax(outp)\n",
    "# add softmax layer: used for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model declared\n",
    "model = NeuralNet(225 , 1000, 51)  \n",
    "# earlier hidden layers- 1000 \n",
    "# 1 - poor, 2- ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "model_opt = optim.SGD(model.parameters(), lr = 0.02)\n",
    "\n",
    "train_set_X = Variable(torch.from_numpy(X_train)).float()\n",
    "train_set_y = Variable(torch.LongTensor(y_train)).long()\n",
    "test_set_X = Variable(torch.from_numpy(X_test)).float()\n",
    "test_set_y = Variable(torch.LongTensor(y_test)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "epochs = 50\n",
    "for epochs in range(epochs):\n",
    "    model_opt.zero_grad()\n",
    "    out = model(train_set_X)\n",
    "    loss = loss_function(out, train_set_y)\n",
    "    loss.backward()\n",
    "    model_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "# for i in range(3299):\n",
    "#     ans_max,ind = torch.max(ans[i],0)\n",
    "#     print (test_set_y[i].numpy() - ind.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  2  4  1  7]\n",
      " [ 2  1  3  4  9]\n",
      " [ 3  2  1  4 10]\n",
      " ...\n",
      " [ 2  1  3  4  9]\n",
      " [ 2  1  3  4  9]\n",
      " [ 3  2  1  4 10]]\n",
      "[3. 2. 3. ... 9. 4. 3.]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "print (y_pred)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.314 prec@3: 0.614 prec@5: 0.752\n",
      "mprec@1: 2.968e-02 mprec@3: 7.338e-02 mprec@5: 1.294e-01\n",
      "prec matrix [0.31393939 0.50333333 0.61363636 0.69363636 0.75151515]\n",
      "mprec matrix [0.02968053 0.05729217 0.07338063 0.08510638 0.12942324]\n"
     ]
    }
   ],
   "source": [
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 \n",
    "# same model diff train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_latent_X = data_utils.TensorDataset(train_set_X, train_set_y)\n",
    "te_latent_X = data_utils.TensorDataset(test_set_X,  test_set_y)\n",
    "train_loader_X = torch.utils.data.DataLoader(dataset=tr_latent_X)\n",
    "test_loader_X = torch.utils.data.DataLoader(dataset=te_latent_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data,label) in enumerate(train_loader_X):\n",
    "\n",
    "        model_opt.zero_grad()\n",
    "\n",
    "        out = model(data)\n",
    "        loss = loss_function(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        model_opt.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_X.dataset),\n",
    "                100. * batch_idx / len(train_loader_X), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader_X.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6700 (0%)]\tLoss: 2.854280\n",
      "Train Epoch: 1 [100/6700 (1%)]\tLoss: 2.127586\n",
      "Train Epoch: 1 [200/6700 (3%)]\tLoss: 0.779639\n",
      "Train Epoch: 1 [300/6700 (4%)]\tLoss: 4.261716\n",
      "Train Epoch: 1 [400/6700 (6%)]\tLoss: 3.735106\n",
      "Train Epoch: 1 [500/6700 (7%)]\tLoss: 1.373702\n",
      "Train Epoch: 1 [600/6700 (9%)]\tLoss: 1.796077\n",
      "Train Epoch: 1 [700/6700 (10%)]\tLoss: 0.799777\n",
      "Train Epoch: 1 [800/6700 (12%)]\tLoss: 2.275002\n",
      "Train Epoch: 1 [900/6700 (13%)]\tLoss: 0.553542\n",
      "Train Epoch: 1 [1000/6700 (15%)]\tLoss: 2.927905\n",
      "Train Epoch: 1 [1100/6700 (16%)]\tLoss: 0.007938\n",
      "Train Epoch: 1 [1200/6700 (18%)]\tLoss: 8.221107\n",
      "Train Epoch: 1 [1300/6700 (19%)]\tLoss: 0.170846\n",
      "Train Epoch: 1 [1400/6700 (21%)]\tLoss: 1.714790\n",
      "Train Epoch: 1 [1500/6700 (22%)]\tLoss: 0.666515\n",
      "Train Epoch: 1 [1600/6700 (24%)]\tLoss: 1.358858\n",
      "Train Epoch: 1 [1700/6700 (25%)]\tLoss: 0.041263\n",
      "Train Epoch: 1 [1800/6700 (27%)]\tLoss: 0.881191\n",
      "Train Epoch: 1 [1900/6700 (28%)]\tLoss: 1.189125\n",
      "Train Epoch: 1 [2000/6700 (30%)]\tLoss: 4.536890\n",
      "Train Epoch: 1 [2100/6700 (31%)]\tLoss: 0.840930\n",
      "Train Epoch: 1 [2200/6700 (33%)]\tLoss: 1.710115\n",
      "Train Epoch: 1 [2300/6700 (34%)]\tLoss: 0.062518\n",
      "Train Epoch: 1 [2400/6700 (36%)]\tLoss: 1.692596\n",
      "Train Epoch: 1 [2500/6700 (37%)]\tLoss: 0.126120\n",
      "Train Epoch: 1 [2600/6700 (39%)]\tLoss: 1.171261\n",
      "Train Epoch: 1 [2700/6700 (40%)]\tLoss: 5.115711\n",
      "Train Epoch: 1 [2800/6700 (42%)]\tLoss: 1.099595\n",
      "Train Epoch: 1 [2900/6700 (43%)]\tLoss: 0.871613\n",
      "Train Epoch: 1 [3000/6700 (45%)]\tLoss: 1.211437\n",
      "Train Epoch: 1 [3100/6700 (46%)]\tLoss: 1.369971\n",
      "Train Epoch: 1 [3200/6700 (48%)]\tLoss: 0.149597\n",
      "Train Epoch: 1 [3300/6700 (49%)]\tLoss: 4.014397\n",
      "Train Epoch: 1 [3400/6700 (51%)]\tLoss: 0.145292\n",
      "Train Epoch: 1 [3500/6700 (52%)]\tLoss: 0.663467\n",
      "Train Epoch: 1 [3600/6700 (54%)]\tLoss: 1.870785\n",
      "Train Epoch: 1 [3700/6700 (55%)]\tLoss: 0.545822\n",
      "Train Epoch: 1 [3800/6700 (57%)]\tLoss: 0.456351\n",
      "Train Epoch: 1 [3900/6700 (58%)]\tLoss: 0.330432\n",
      "Train Epoch: 1 [4000/6700 (60%)]\tLoss: 6.193199\n",
      "Train Epoch: 1 [4100/6700 (61%)]\tLoss: 0.213120\n",
      "Train Epoch: 1 [4200/6700 (63%)]\tLoss: 0.031421\n",
      "Train Epoch: 1 [4300/6700 (64%)]\tLoss: 0.968627\n",
      "Train Epoch: 1 [4400/6700 (66%)]\tLoss: 0.827891\n",
      "Train Epoch: 1 [4500/6700 (67%)]\tLoss: 2.089381\n",
      "Train Epoch: 1 [4600/6700 (69%)]\tLoss: 2.875101\n",
      "Train Epoch: 1 [4700/6700 (70%)]\tLoss: 0.702693\n",
      "Train Epoch: 1 [4800/6700 (72%)]\tLoss: 2.145113\n",
      "Train Epoch: 1 [4900/6700 (73%)]\tLoss: 3.427392\n",
      "Train Epoch: 1 [5000/6700 (75%)]\tLoss: 3.351680\n",
      "Train Epoch: 1 [5100/6700 (76%)]\tLoss: 0.699721\n",
      "Train Epoch: 1 [5200/6700 (78%)]\tLoss: 1.925920\n",
      "Train Epoch: 1 [5300/6700 (79%)]\tLoss: 0.919481\n",
      "Train Epoch: 1 [5400/6700 (81%)]\tLoss: 0.128469\n",
      "Train Epoch: 1 [5500/6700 (82%)]\tLoss: 3.952187\n",
      "Train Epoch: 1 [5600/6700 (84%)]\tLoss: 6.162556\n",
      "Train Epoch: 1 [5700/6700 (85%)]\tLoss: 3.337572\n",
      "Train Epoch: 1 [5800/6700 (87%)]\tLoss: 1.997642\n",
      "Train Epoch: 1 [5900/6700 (88%)]\tLoss: 0.510477\n",
      "Train Epoch: 1 [6000/6700 (90%)]\tLoss: 0.492505\n",
      "Train Epoch: 1 [6100/6700 (91%)]\tLoss: 0.069325\n",
      "Train Epoch: 1 [6200/6700 (93%)]\tLoss: 0.378018\n",
      "Train Epoch: 1 [6300/6700 (94%)]\tLoss: 0.082598\n",
      "Train Epoch: 1 [6400/6700 (96%)]\tLoss: 2.709408\n",
      "Train Epoch: 1 [6500/6700 (97%)]\tLoss: 0.242798\n",
      "Train Epoch: 1 [6600/6700 (99%)]\tLoss: 0.357947\n",
      "====> Epoch: 1 Average loss: 1.6501\n",
      "Train Epoch: 2 [0/6700 (0%)]\tLoss: 0.647992\n",
      "Train Epoch: 2 [100/6700 (1%)]\tLoss: 0.152965\n",
      "Train Epoch: 2 [200/6700 (3%)]\tLoss: 0.176920\n",
      "Train Epoch: 2 [300/6700 (4%)]\tLoss: 0.706737\n",
      "Train Epoch: 2 [400/6700 (6%)]\tLoss: 3.466714\n",
      "Train Epoch: 2 [500/6700 (7%)]\tLoss: 0.220941\n",
      "Train Epoch: 2 [600/6700 (9%)]\tLoss: 1.056107\n",
      "Train Epoch: 2 [700/6700 (10%)]\tLoss: 0.489006\n",
      "Train Epoch: 2 [800/6700 (12%)]\tLoss: 1.523707\n",
      "Train Epoch: 2 [900/6700 (13%)]\tLoss: 0.073501\n",
      "Train Epoch: 2 [1000/6700 (15%)]\tLoss: 1.719626\n",
      "Train Epoch: 2 [1100/6700 (16%)]\tLoss: 3.181440\n",
      "Train Epoch: 2 [1200/6700 (18%)]\tLoss: 7.117931\n",
      "Train Epoch: 2 [1300/6700 (19%)]\tLoss: 0.050894\n",
      "Train Epoch: 2 [1400/6700 (21%)]\tLoss: 0.099282\n",
      "Train Epoch: 2 [1500/6700 (22%)]\tLoss: 0.232893\n",
      "Train Epoch: 2 [1600/6700 (24%)]\tLoss: 0.270244\n",
      "Train Epoch: 2 [1700/6700 (25%)]\tLoss: 0.025209\n",
      "Train Epoch: 2 [1800/6700 (27%)]\tLoss: 0.561432\n",
      "Train Epoch: 2 [1900/6700 (28%)]\tLoss: 0.921224\n",
      "Train Epoch: 2 [2000/6700 (30%)]\tLoss: 5.511085\n",
      "Train Epoch: 2 [2100/6700 (31%)]\tLoss: 0.421144\n",
      "Train Epoch: 2 [2200/6700 (33%)]\tLoss: 1.779433\n",
      "Train Epoch: 2 [2300/6700 (34%)]\tLoss: 0.051312\n",
      "Train Epoch: 2 [2400/6700 (36%)]\tLoss: 0.237149\n",
      "Train Epoch: 2 [2500/6700 (37%)]\tLoss: 0.046263\n",
      "Train Epoch: 2 [2600/6700 (39%)]\tLoss: 0.821921\n",
      "Train Epoch: 2 [2700/6700 (40%)]\tLoss: 2.778877\n",
      "Train Epoch: 2 [2800/6700 (42%)]\tLoss: 0.333829\n",
      "Train Epoch: 2 [2900/6700 (43%)]\tLoss: 0.054054\n",
      "Train Epoch: 2 [3000/6700 (45%)]\tLoss: 0.668843\n",
      "Train Epoch: 2 [3100/6700 (46%)]\tLoss: 0.765051\n",
      "Train Epoch: 2 [3200/6700 (48%)]\tLoss: 0.127699\n",
      "Train Epoch: 2 [3300/6700 (49%)]\tLoss: 2.872908\n",
      "Train Epoch: 2 [3400/6700 (51%)]\tLoss: 0.032908\n",
      "Train Epoch: 2 [3500/6700 (52%)]\tLoss: 0.040209\n",
      "Train Epoch: 2 [3600/6700 (54%)]\tLoss: 1.700993\n",
      "Train Epoch: 2 [3700/6700 (55%)]\tLoss: 0.171540\n",
      "Train Epoch: 2 [3800/6700 (57%)]\tLoss: 0.149348\n",
      "Train Epoch: 2 [3900/6700 (58%)]\tLoss: 0.065281\n",
      "Train Epoch: 2 [4000/6700 (60%)]\tLoss: 6.634068\n",
      "Train Epoch: 2 [4100/6700 (61%)]\tLoss: 0.173996\n",
      "Train Epoch: 2 [4200/6700 (63%)]\tLoss: 0.010068\n",
      "Train Epoch: 2 [4300/6700 (64%)]\tLoss: 1.191321\n",
      "Train Epoch: 2 [4400/6700 (66%)]\tLoss: 0.014131\n",
      "Train Epoch: 2 [4500/6700 (67%)]\tLoss: 2.170988\n",
      "Train Epoch: 2 [4600/6700 (69%)]\tLoss: 2.397587\n",
      "Train Epoch: 2 [4700/6700 (70%)]\tLoss: 0.318486\n",
      "Train Epoch: 2 [4800/6700 (72%)]\tLoss: 2.147949\n",
      "Train Epoch: 2 [4900/6700 (73%)]\tLoss: 1.311871\n",
      "Train Epoch: 2 [5000/6700 (75%)]\tLoss: 2.477401\n",
      "Train Epoch: 2 [5100/6700 (76%)]\tLoss: 0.251169\n",
      "Train Epoch: 2 [5200/6700 (78%)]\tLoss: 1.842445\n",
      "Train Epoch: 2 [5300/6700 (79%)]\tLoss: 0.741384\n",
      "Train Epoch: 2 [5400/6700 (81%)]\tLoss: 0.077835\n",
      "Train Epoch: 2 [5500/6700 (82%)]\tLoss: 3.098050\n",
      "Train Epoch: 2 [5600/6700 (84%)]\tLoss: 4.557931\n",
      "Train Epoch: 2 [5700/6700 (85%)]\tLoss: 2.861485\n",
      "Train Epoch: 2 [5800/6700 (87%)]\tLoss: 1.494783\n",
      "Train Epoch: 2 [5900/6700 (88%)]\tLoss: 0.220343\n",
      "Train Epoch: 2 [6000/6700 (90%)]\tLoss: 0.183142\n",
      "Train Epoch: 2 [6100/6700 (91%)]\tLoss: 0.015163\n",
      "Train Epoch: 2 [6200/6700 (93%)]\tLoss: 0.135118\n",
      "Train Epoch: 2 [6300/6700 (94%)]\tLoss: 0.041607\n",
      "Train Epoch: 2 [6400/6700 (96%)]\tLoss: 0.597684\n",
      "Train Epoch: 2 [6500/6700 (97%)]\tLoss: 0.208127\n",
      "Train Epoch: 2 [6600/6700 (99%)]\tLoss: 0.101975\n",
      "====> Epoch: 2 Average loss: 1.1123\n",
      "Train Epoch: 3 [0/6700 (0%)]\tLoss: 0.404258\n",
      "Train Epoch: 3 [100/6700 (1%)]\tLoss: 0.061440\n",
      "Train Epoch: 3 [200/6700 (3%)]\tLoss: 0.142631\n",
      "Train Epoch: 3 [300/6700 (4%)]\tLoss: 0.309567\n",
      "Train Epoch: 3 [400/6700 (6%)]\tLoss: 3.520515\n",
      "Train Epoch: 3 [500/6700 (7%)]\tLoss: 0.125733\n",
      "Train Epoch: 3 [600/6700 (9%)]\tLoss: 0.498759\n",
      "Train Epoch: 3 [700/6700 (10%)]\tLoss: 0.434492\n",
      "Train Epoch: 3 [800/6700 (12%)]\tLoss: 1.473970\n",
      "Train Epoch: 3 [900/6700 (13%)]\tLoss: 0.047222\n",
      "Train Epoch: 3 [1000/6700 (15%)]\tLoss: 1.523413\n",
      "Train Epoch: 3 [1100/6700 (16%)]\tLoss: 0.231419\n",
      "Train Epoch: 3 [1200/6700 (18%)]\tLoss: 3.916740\n",
      "Train Epoch: 3 [1300/6700 (19%)]\tLoss: 0.048053\n",
      "Train Epoch: 3 [1400/6700 (21%)]\tLoss: 0.036708\n",
      "Train Epoch: 3 [1500/6700 (22%)]\tLoss: 0.173881\n",
      "Train Epoch: 3 [1600/6700 (24%)]\tLoss: 1.242796\n",
      "Train Epoch: 3 [1700/6700 (25%)]\tLoss: 0.004725\n",
      "Train Epoch: 3 [1800/6700 (27%)]\tLoss: 0.504806\n",
      "Train Epoch: 3 [1900/6700 (28%)]\tLoss: 1.192604\n",
      "Train Epoch: 3 [2000/6700 (30%)]\tLoss: 5.887111\n",
      "Train Epoch: 3 [2100/6700 (31%)]\tLoss: 0.145785\n",
      "Train Epoch: 3 [2200/6700 (33%)]\tLoss: 1.129056\n",
      "Train Epoch: 3 [2300/6700 (34%)]\tLoss: 0.029706\n",
      "Train Epoch: 3 [2400/6700 (36%)]\tLoss: 0.116819\n",
      "Train Epoch: 3 [2500/6700 (37%)]\tLoss: 0.054816\n",
      "Train Epoch: 3 [2600/6700 (39%)]\tLoss: 0.526635\n",
      "Train Epoch: 3 [2700/6700 (40%)]\tLoss: 1.416759\n",
      "Train Epoch: 3 [2800/6700 (42%)]\tLoss: 0.094073\n",
      "Train Epoch: 3 [2900/6700 (43%)]\tLoss: 0.005792\n",
      "Train Epoch: 3 [3000/6700 (45%)]\tLoss: 0.566755\n",
      "Train Epoch: 3 [3100/6700 (46%)]\tLoss: 0.297084\n",
      "Train Epoch: 3 [3200/6700 (48%)]\tLoss: 0.137428\n",
      "Train Epoch: 3 [3300/6700 (49%)]\tLoss: 2.739563\n",
      "Train Epoch: 3 [3400/6700 (51%)]\tLoss: 0.041479\n",
      "Train Epoch: 3 [3500/6700 (52%)]\tLoss: 1.564184\n",
      "Train Epoch: 3 [3600/6700 (54%)]\tLoss: 1.963746\n",
      "Train Epoch: 3 [3700/6700 (55%)]\tLoss: 0.113508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [3800/6700 (57%)]\tLoss: 0.042151\n",
      "Train Epoch: 3 [3900/6700 (58%)]\tLoss: 0.048629\n",
      "Train Epoch: 3 [4000/6700 (60%)]\tLoss: 4.288632\n",
      "Train Epoch: 3 [4100/6700 (61%)]\tLoss: 0.258256\n",
      "Train Epoch: 3 [4200/6700 (63%)]\tLoss: 0.007191\n",
      "Train Epoch: 3 [4300/6700 (64%)]\tLoss: 0.958228\n",
      "Train Epoch: 3 [4400/6700 (66%)]\tLoss: 0.000575\n",
      "Train Epoch: 3 [4500/6700 (67%)]\tLoss: 2.134486\n",
      "Train Epoch: 3 [4600/6700 (69%)]\tLoss: 2.114346\n",
      "Train Epoch: 3 [4700/6700 (70%)]\tLoss: 0.196387\n",
      "Train Epoch: 3 [4800/6700 (72%)]\tLoss: 2.319604\n",
      "Train Epoch: 3 [4900/6700 (73%)]\tLoss: 0.394407\n",
      "Train Epoch: 3 [5000/6700 (75%)]\tLoss: 1.637612\n",
      "Train Epoch: 3 [5100/6700 (76%)]\tLoss: 0.151898\n",
      "Train Epoch: 3 [5200/6700 (78%)]\tLoss: 1.353289\n",
      "Train Epoch: 3 [5300/6700 (79%)]\tLoss: 0.622690\n",
      "Train Epoch: 3 [5400/6700 (81%)]\tLoss: 0.124146\n",
      "Train Epoch: 3 [5500/6700 (82%)]\tLoss: 2.925913\n",
      "Train Epoch: 3 [5600/6700 (84%)]\tLoss: 2.762436\n",
      "Train Epoch: 3 [5700/6700 (85%)]\tLoss: 2.358912\n",
      "Train Epoch: 3 [5800/6700 (87%)]\tLoss: 1.407470\n",
      "Train Epoch: 3 [5900/6700 (88%)]\tLoss: 0.077015\n",
      "Train Epoch: 3 [6000/6700 (90%)]\tLoss: 0.108318\n",
      "Train Epoch: 3 [6100/6700 (91%)]\tLoss: 0.004597\n",
      "Train Epoch: 3 [6200/6700 (93%)]\tLoss: 0.067413\n",
      "Train Epoch: 3 [6300/6700 (94%)]\tLoss: 0.037800\n",
      "Train Epoch: 3 [6400/6700 (96%)]\tLoss: 0.192875\n",
      "Train Epoch: 3 [6500/6700 (97%)]\tLoss: 0.158225\n",
      "Train Epoch: 3 [6600/6700 (99%)]\tLoss: 0.040858\n",
      "====> Epoch: 3 Average loss: 0.9088\n",
      "Train Epoch: 4 [0/6700 (0%)]\tLoss: 0.192890\n",
      "Train Epoch: 4 [100/6700 (1%)]\tLoss: 0.033533\n",
      "Train Epoch: 4 [200/6700 (3%)]\tLoss: 0.168103\n",
      "Train Epoch: 4 [300/6700 (4%)]\tLoss: 0.211785\n",
      "Train Epoch: 4 [400/6700 (6%)]\tLoss: 3.312735\n",
      "Train Epoch: 4 [500/6700 (7%)]\tLoss: 0.145387\n",
      "Train Epoch: 4 [600/6700 (9%)]\tLoss: 0.302018\n",
      "Train Epoch: 4 [700/6700 (10%)]\tLoss: 0.518648\n",
      "Train Epoch: 4 [800/6700 (12%)]\tLoss: 1.229703\n",
      "Train Epoch: 4 [900/6700 (13%)]\tLoss: 0.078260\n",
      "Train Epoch: 4 [1000/6700 (15%)]\tLoss: 1.551551\n",
      "Train Epoch: 4 [1100/6700 (16%)]\tLoss: 0.024835\n",
      "Train Epoch: 4 [1200/6700 (18%)]\tLoss: 0.917445\n",
      "Train Epoch: 4 [1300/6700 (19%)]\tLoss: 0.027726\n",
      "Train Epoch: 4 [1400/6700 (21%)]\tLoss: 0.018283\n",
      "Train Epoch: 4 [1500/6700 (22%)]\tLoss: 0.150177\n",
      "Train Epoch: 4 [1600/6700 (24%)]\tLoss: 0.388994\n",
      "Train Epoch: 4 [1700/6700 (25%)]\tLoss: 0.010578\n",
      "Train Epoch: 4 [1800/6700 (27%)]\tLoss: 0.183034\n",
      "Train Epoch: 4 [1900/6700 (28%)]\tLoss: 0.692844\n",
      "Train Epoch: 4 [2000/6700 (30%)]\tLoss: 6.053277\n",
      "Train Epoch: 4 [2100/6700 (31%)]\tLoss: 0.073933\n",
      "Train Epoch: 4 [2200/6700 (33%)]\tLoss: 1.346615\n",
      "Train Epoch: 4 [2300/6700 (34%)]\tLoss: 0.021404\n",
      "Train Epoch: 4 [2400/6700 (36%)]\tLoss: 0.083119\n",
      "Train Epoch: 4 [2500/6700 (37%)]\tLoss: 0.067680\n",
      "Train Epoch: 4 [2600/6700 (39%)]\tLoss: 0.339100\n",
      "Train Epoch: 4 [2700/6700 (40%)]\tLoss: 0.928221\n",
      "Train Epoch: 4 [2800/6700 (42%)]\tLoss: 0.118837\n",
      "Train Epoch: 4 [2900/6700 (43%)]\tLoss: 0.002523\n",
      "Train Epoch: 4 [3000/6700 (45%)]\tLoss: 0.690234\n",
      "Train Epoch: 4 [3100/6700 (46%)]\tLoss: 0.193925\n",
      "Train Epoch: 4 [3200/6700 (48%)]\tLoss: 0.140073\n",
      "Train Epoch: 4 [3300/6700 (49%)]\tLoss: 2.360635\n",
      "Train Epoch: 4 [3400/6700 (51%)]\tLoss: 0.032455\n",
      "Train Epoch: 4 [3500/6700 (52%)]\tLoss: 1.244053\n",
      "Train Epoch: 4 [3600/6700 (54%)]\tLoss: 2.670191\n",
      "Train Epoch: 4 [3700/6700 (55%)]\tLoss: 0.106288\n",
      "Train Epoch: 4 [3800/6700 (57%)]\tLoss: 0.039373\n",
      "Train Epoch: 4 [3900/6700 (58%)]\tLoss: 0.028331\n",
      "Train Epoch: 4 [4000/6700 (60%)]\tLoss: 2.610952\n",
      "Train Epoch: 4 [4100/6700 (61%)]\tLoss: 0.320480\n",
      "Train Epoch: 4 [4200/6700 (63%)]\tLoss: 0.003424\n",
      "Train Epoch: 4 [4300/6700 (64%)]\tLoss: 0.580645\n",
      "Train Epoch: 4 [4400/6700 (66%)]\tLoss: 0.000688\n",
      "Train Epoch: 4 [4500/6700 (67%)]\tLoss: 1.660425\n",
      "Train Epoch: 4 [4600/6700 (69%)]\tLoss: 1.461280\n",
      "Train Epoch: 4 [4700/6700 (70%)]\tLoss: 0.101246\n",
      "Train Epoch: 4 [4800/6700 (72%)]\tLoss: 2.643058\n",
      "Train Epoch: 4 [4900/6700 (73%)]\tLoss: 0.090875\n",
      "Train Epoch: 4 [5000/6700 (75%)]\tLoss: 1.051537\n",
      "Train Epoch: 4 [5100/6700 (76%)]\tLoss: 0.091203\n",
      "Train Epoch: 4 [5200/6700 (78%)]\tLoss: 0.945413\n",
      "Train Epoch: 4 [5300/6700 (79%)]\tLoss: 0.520741\n",
      "Train Epoch: 4 [5400/6700 (81%)]\tLoss: 0.170167\n",
      "Train Epoch: 4 [5500/6700 (82%)]\tLoss: 3.023252\n",
      "Train Epoch: 4 [5600/6700 (84%)]\tLoss: 2.333809\n",
      "Train Epoch: 4 [5700/6700 (85%)]\tLoss: 2.523880\n",
      "Train Epoch: 4 [5800/6700 (87%)]\tLoss: 1.306579\n",
      "Train Epoch: 4 [5900/6700 (88%)]\tLoss: 0.098202\n",
      "Train Epoch: 4 [6000/6700 (90%)]\tLoss: 0.292739\n",
      "Train Epoch: 4 [6100/6700 (91%)]\tLoss: 0.002501\n",
      "Train Epoch: 4 [6200/6700 (93%)]\tLoss: 0.074760\n",
      "Train Epoch: 4 [6300/6700 (94%)]\tLoss: 0.023959\n",
      "Train Epoch: 4 [6400/6700 (96%)]\tLoss: 0.103951\n",
      "Train Epoch: 4 [6500/6700 (97%)]\tLoss: 0.171331\n",
      "Train Epoch: 4 [6600/6700 (99%)]\tLoss: 0.025752\n",
      "====> Epoch: 4 Average loss: 0.7857\n",
      "Train Epoch: 5 [0/6700 (0%)]\tLoss: 0.185654\n",
      "Train Epoch: 5 [100/6700 (1%)]\tLoss: 0.022279\n",
      "Train Epoch: 5 [200/6700 (3%)]\tLoss: 0.123099\n",
      "Train Epoch: 5 [300/6700 (4%)]\tLoss: 0.104231\n",
      "Train Epoch: 5 [400/6700 (6%)]\tLoss: 2.942341\n",
      "Train Epoch: 5 [500/6700 (7%)]\tLoss: 0.130807\n",
      "Train Epoch: 5 [600/6700 (9%)]\tLoss: 0.225232\n",
      "Train Epoch: 5 [700/6700 (10%)]\tLoss: 0.550464\n",
      "Train Epoch: 5 [800/6700 (12%)]\tLoss: 1.168722\n",
      "Train Epoch: 5 [900/6700 (13%)]\tLoss: 0.071716\n",
      "Train Epoch: 5 [1000/6700 (15%)]\tLoss: 1.799757\n",
      "Train Epoch: 5 [1100/6700 (16%)]\tLoss: 0.044298\n",
      "Train Epoch: 5 [1200/6700 (18%)]\tLoss: 0.154633\n",
      "Train Epoch: 5 [1300/6700 (19%)]\tLoss: 0.021421\n",
      "Train Epoch: 5 [1400/6700 (21%)]\tLoss: 0.013186\n",
      "Train Epoch: 5 [1500/6700 (22%)]\tLoss: 0.134767\n",
      "Train Epoch: 5 [1600/6700 (24%)]\tLoss: 0.608640\n",
      "Train Epoch: 5 [1700/6700 (25%)]\tLoss: 0.004848\n",
      "Train Epoch: 5 [1800/6700 (27%)]\tLoss: 0.270638\n",
      "Train Epoch: 5 [1900/6700 (28%)]\tLoss: 0.523855\n",
      "Train Epoch: 5 [2000/6700 (30%)]\tLoss: 6.523617\n",
      "Train Epoch: 5 [2100/6700 (31%)]\tLoss: 0.041076\n",
      "Train Epoch: 5 [2200/6700 (33%)]\tLoss: 0.808733\n",
      "Train Epoch: 5 [2300/6700 (34%)]\tLoss: 0.009055\n",
      "Train Epoch: 5 [2400/6700 (36%)]\tLoss: 0.086675\n",
      "Train Epoch: 5 [2500/6700 (37%)]\tLoss: 0.056598\n",
      "Train Epoch: 5 [2600/6700 (39%)]\tLoss: 0.186490\n",
      "Train Epoch: 5 [2700/6700 (40%)]\tLoss: 0.567520\n",
      "Train Epoch: 5 [2800/6700 (42%)]\tLoss: 0.075035\n",
      "Train Epoch: 5 [2900/6700 (43%)]\tLoss: 0.001103\n",
      "Train Epoch: 5 [3000/6700 (45%)]\tLoss: 1.058182\n",
      "Train Epoch: 5 [3100/6700 (46%)]\tLoss: 0.103788\n",
      "Train Epoch: 5 [3200/6700 (48%)]\tLoss: 0.141888\n",
      "Train Epoch: 5 [3300/6700 (49%)]\tLoss: 2.224971\n",
      "Train Epoch: 5 [3400/6700 (51%)]\tLoss: 0.020900\n",
      "Train Epoch: 5 [3500/6700 (52%)]\tLoss: 2.759136\n",
      "Train Epoch: 5 [3600/6700 (54%)]\tLoss: 4.139990\n",
      "Train Epoch: 5 [3700/6700 (55%)]\tLoss: 0.072429\n",
      "Train Epoch: 5 [3800/6700 (57%)]\tLoss: 0.064473\n",
      "Train Epoch: 5 [3900/6700 (58%)]\tLoss: 0.018126\n",
      "Train Epoch: 5 [4000/6700 (60%)]\tLoss: 1.097134\n",
      "Train Epoch: 5 [4100/6700 (61%)]\tLoss: 0.489731\n",
      "Train Epoch: 5 [4200/6700 (63%)]\tLoss: 0.003293\n",
      "Train Epoch: 5 [4300/6700 (64%)]\tLoss: 0.435208\n",
      "Train Epoch: 5 [4400/6700 (66%)]\tLoss: 0.000558\n",
      "Train Epoch: 5 [4500/6700 (67%)]\tLoss: 1.469581\n",
      "Train Epoch: 5 [4600/6700 (69%)]\tLoss: 1.259868\n",
      "Train Epoch: 5 [4700/6700 (70%)]\tLoss: 0.095061\n",
      "Train Epoch: 5 [4800/6700 (72%)]\tLoss: 2.807036\n",
      "Train Epoch: 5 [4900/6700 (73%)]\tLoss: 0.040749\n",
      "Train Epoch: 5 [5000/6700 (75%)]\tLoss: 0.914633\n",
      "Train Epoch: 5 [5100/6700 (76%)]\tLoss: 0.072785\n",
      "Train Epoch: 5 [5200/6700 (78%)]\tLoss: 0.610034\n",
      "Train Epoch: 5 [5300/6700 (79%)]\tLoss: 0.407180\n",
      "Train Epoch: 5 [5400/6700 (81%)]\tLoss: 0.160953\n",
      "Train Epoch: 5 [5500/6700 (82%)]\tLoss: 2.520026\n",
      "Train Epoch: 5 [5600/6700 (84%)]\tLoss: 1.606850\n",
      "Train Epoch: 5 [5700/6700 (85%)]\tLoss: 3.339835\n",
      "Train Epoch: 5 [5800/6700 (87%)]\tLoss: 1.190986\n",
      "Train Epoch: 5 [5900/6700 (88%)]\tLoss: 0.270691\n",
      "Train Epoch: 5 [6000/6700 (90%)]\tLoss: 0.052192\n",
      "Train Epoch: 5 [6100/6700 (91%)]\tLoss: 0.001327\n",
      "Train Epoch: 5 [6200/6700 (93%)]\tLoss: 0.028944\n",
      "Train Epoch: 5 [6300/6700 (94%)]\tLoss: 0.017265\n",
      "Train Epoch: 5 [6400/6700 (96%)]\tLoss: 0.071452\n",
      "Train Epoch: 5 [6500/6700 (97%)]\tLoss: 0.185245\n",
      "Train Epoch: 5 [6600/6700 (99%)]\tLoss: 0.019263\n",
      "====> Epoch: 5 Average loss: 0.7121\n",
      "Train Epoch: 6 [0/6700 (0%)]\tLoss: 0.240052\n",
      "Train Epoch: 6 [100/6700 (1%)]\tLoss: 0.017702\n",
      "Train Epoch: 6 [200/6700 (3%)]\tLoss: 0.126298\n",
      "Train Epoch: 6 [300/6700 (4%)]\tLoss: 0.059399\n",
      "Train Epoch: 6 [400/6700 (6%)]\tLoss: 2.796957\n",
      "Train Epoch: 6 [500/6700 (7%)]\tLoss: 0.182358\n",
      "Train Epoch: 6 [600/6700 (9%)]\tLoss: 0.126697\n",
      "Train Epoch: 6 [700/6700 (10%)]\tLoss: 0.418689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [800/6700 (12%)]\tLoss: 1.106590\n",
      "Train Epoch: 6 [900/6700 (13%)]\tLoss: 0.081521\n",
      "Train Epoch: 6 [1000/6700 (15%)]\tLoss: 1.554601\n",
      "Train Epoch: 6 [1100/6700 (16%)]\tLoss: 0.081904\n",
      "Train Epoch: 6 [1200/6700 (18%)]\tLoss: 0.135601\n",
      "Train Epoch: 6 [1300/6700 (19%)]\tLoss: 0.025907\n",
      "Train Epoch: 6 [1400/6700 (21%)]\tLoss: 0.005191\n",
      "Train Epoch: 6 [1500/6700 (22%)]\tLoss: 0.109704\n",
      "Train Epoch: 6 [1600/6700 (24%)]\tLoss: 0.081467\n",
      "Train Epoch: 6 [1700/6700 (25%)]\tLoss: 0.002404\n",
      "Train Epoch: 6 [1800/6700 (27%)]\tLoss: 0.009346\n",
      "Train Epoch: 6 [1900/6700 (28%)]\tLoss: 0.407837\n",
      "Train Epoch: 6 [2000/6700 (30%)]\tLoss: 6.647480\n",
      "Train Epoch: 6 [2100/6700 (31%)]\tLoss: 0.030649\n",
      "Train Epoch: 6 [2200/6700 (33%)]\tLoss: 0.561600\n",
      "Train Epoch: 6 [2300/6700 (34%)]\tLoss: 0.005816\n",
      "Train Epoch: 6 [2400/6700 (36%)]\tLoss: 0.084271\n",
      "Train Epoch: 6 [2500/6700 (37%)]\tLoss: 0.051288\n",
      "Train Epoch: 6 [2600/6700 (39%)]\tLoss: 0.188711\n",
      "Train Epoch: 6 [2700/6700 (40%)]\tLoss: 0.426144\n",
      "Train Epoch: 6 [2800/6700 (42%)]\tLoss: 0.075147\n",
      "Train Epoch: 6 [2900/6700 (43%)]\tLoss: 0.000289\n",
      "Train Epoch: 6 [3000/6700 (45%)]\tLoss: 0.724287\n",
      "Train Epoch: 6 [3100/6700 (46%)]\tLoss: 0.059838\n",
      "Train Epoch: 6 [3200/6700 (48%)]\tLoss: 0.139235\n",
      "Train Epoch: 6 [3300/6700 (49%)]\tLoss: 2.049669\n",
      "Train Epoch: 6 [3400/6700 (51%)]\tLoss: 0.030679\n",
      "Train Epoch: 6 [3500/6700 (52%)]\tLoss: 0.007188\n",
      "Train Epoch: 6 [3600/6700 (54%)]\tLoss: 1.904114\n",
      "Train Epoch: 6 [3700/6700 (55%)]\tLoss: 0.103085\n",
      "Train Epoch: 6 [3800/6700 (57%)]\tLoss: 0.054893\n",
      "Train Epoch: 6 [3900/6700 (58%)]\tLoss: 0.007149\n",
      "Train Epoch: 6 [4000/6700 (60%)]\tLoss: 0.545804\n",
      "Train Epoch: 6 [4100/6700 (61%)]\tLoss: 0.452286\n",
      "Train Epoch: 6 [4200/6700 (63%)]\tLoss: 0.000441\n",
      "Train Epoch: 6 [4300/6700 (64%)]\tLoss: 0.463240\n",
      "Train Epoch: 6 [4400/6700 (66%)]\tLoss: 0.000234\n",
      "Train Epoch: 6 [4500/6700 (67%)]\tLoss: 1.028421\n",
      "Train Epoch: 6 [4600/6700 (69%)]\tLoss: 0.918309\n",
      "Train Epoch: 6 [4700/6700 (70%)]\tLoss: 0.078408\n",
      "Train Epoch: 6 [4800/6700 (72%)]\tLoss: 2.677818\n",
      "Train Epoch: 6 [4900/6700 (73%)]\tLoss: 0.019500\n",
      "Train Epoch: 6 [5000/6700 (75%)]\tLoss: 0.778666\n",
      "Train Epoch: 6 [5100/6700 (76%)]\tLoss: 0.030922\n",
      "Train Epoch: 6 [5200/6700 (78%)]\tLoss: 0.509334\n",
      "Train Epoch: 6 [5300/6700 (79%)]\tLoss: 0.452216\n",
      "Train Epoch: 6 [5400/6700 (81%)]\tLoss: 0.004872\n",
      "Train Epoch: 6 [5500/6700 (82%)]\tLoss: 8.292712\n",
      "Train Epoch: 6 [5600/6700 (84%)]\tLoss: 1.445010\n",
      "Train Epoch: 6 [5700/6700 (85%)]\tLoss: 2.428874\n",
      "Train Epoch: 6 [5800/6700 (87%)]\tLoss: 1.335945\n",
      "Train Epoch: 6 [5900/6700 (88%)]\tLoss: 0.168161\n",
      "Train Epoch: 6 [6000/6700 (90%)]\tLoss: 0.192753\n",
      "Train Epoch: 6 [6100/6700 (91%)]\tLoss: 0.000591\n",
      "Train Epoch: 6 [6200/6700 (93%)]\tLoss: 0.020194\n",
      "Train Epoch: 6 [6300/6700 (94%)]\tLoss: 0.020916\n",
      "Train Epoch: 6 [6400/6700 (96%)]\tLoss: 0.074266\n",
      "Train Epoch: 6 [6500/6700 (97%)]\tLoss: 0.218687\n",
      "Train Epoch: 6 [6600/6700 (99%)]\tLoss: 0.011033\n",
      "====> Epoch: 6 Average loss: 0.6430\n",
      "Train Epoch: 7 [0/6700 (0%)]\tLoss: 0.376162\n",
      "Train Epoch: 7 [100/6700 (1%)]\tLoss: 0.011820\n",
      "Train Epoch: 7 [200/6700 (3%)]\tLoss: 0.128788\n",
      "Train Epoch: 7 [300/6700 (4%)]\tLoss: 0.025632\n",
      "Train Epoch: 7 [400/6700 (6%)]\tLoss: 3.475104\n",
      "Train Epoch: 7 [500/6700 (7%)]\tLoss: 0.241664\n",
      "Train Epoch: 7 [600/6700 (9%)]\tLoss: 0.066195\n",
      "Train Epoch: 7 [700/6700 (10%)]\tLoss: 0.363759\n",
      "Train Epoch: 7 [800/6700 (12%)]\tLoss: 0.851059\n",
      "Train Epoch: 7 [900/6700 (13%)]\tLoss: 0.089892\n",
      "Train Epoch: 7 [1000/6700 (15%)]\tLoss: 0.612548\n",
      "Train Epoch: 7 [1100/6700 (16%)]\tLoss: 0.040348\n",
      "Train Epoch: 7 [1200/6700 (18%)]\tLoss: 0.043567\n",
      "Train Epoch: 7 [1300/6700 (19%)]\tLoss: 0.012250\n",
      "Train Epoch: 7 [1400/6700 (21%)]\tLoss: 0.005032\n",
      "Train Epoch: 7 [1500/6700 (22%)]\tLoss: 0.103831\n",
      "Train Epoch: 7 [1600/6700 (24%)]\tLoss: 0.142563\n",
      "Train Epoch: 7 [1700/6700 (25%)]\tLoss: 0.001496\n",
      "Train Epoch: 7 [1800/6700 (27%)]\tLoss: 0.000128\n",
      "Train Epoch: 7 [1900/6700 (28%)]\tLoss: 0.376949\n",
      "Train Epoch: 7 [2000/6700 (30%)]\tLoss: 7.118601\n",
      "Train Epoch: 7 [2100/6700 (31%)]\tLoss: 0.034418\n",
      "Train Epoch: 7 [2200/6700 (33%)]\tLoss: 0.497524\n",
      "Train Epoch: 7 [2300/6700 (34%)]\tLoss: 0.003520\n",
      "Train Epoch: 7 [2400/6700 (36%)]\tLoss: 0.099387\n",
      "Train Epoch: 7 [2500/6700 (37%)]\tLoss: 0.052574\n",
      "Train Epoch: 7 [2600/6700 (39%)]\tLoss: 0.111300\n",
      "Train Epoch: 7 [2700/6700 (40%)]\tLoss: 0.293218\n",
      "Train Epoch: 7 [2800/6700 (42%)]\tLoss: 0.052340\n",
      "Train Epoch: 7 [2900/6700 (43%)]\tLoss: 0.000132\n",
      "Train Epoch: 7 [3000/6700 (45%)]\tLoss: 1.029349\n",
      "Train Epoch: 7 [3100/6700 (46%)]\tLoss: 0.052188\n",
      "Train Epoch: 7 [3200/6700 (48%)]\tLoss: 0.163604\n",
      "Train Epoch: 7 [3300/6700 (49%)]\tLoss: 2.500309\n",
      "Train Epoch: 7 [3400/6700 (51%)]\tLoss: 0.037082\n",
      "Train Epoch: 7 [3500/6700 (52%)]\tLoss: 0.019791\n",
      "Train Epoch: 7 [3600/6700 (54%)]\tLoss: 2.012262\n",
      "Train Epoch: 7 [3700/6700 (55%)]\tLoss: 0.095790\n",
      "Train Epoch: 7 [3800/6700 (57%)]\tLoss: 0.036760\n",
      "Train Epoch: 7 [3900/6700 (58%)]\tLoss: 0.006728\n",
      "Train Epoch: 7 [4000/6700 (60%)]\tLoss: 0.916215\n",
      "Train Epoch: 7 [4100/6700 (61%)]\tLoss: 0.405308\n",
      "Train Epoch: 7 [4200/6700 (63%)]\tLoss: 0.002239\n",
      "Train Epoch: 7 [4300/6700 (64%)]\tLoss: 0.293051\n",
      "Train Epoch: 7 [4400/6700 (66%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [4500/6700 (67%)]\tLoss: 0.820005\n",
      "Train Epoch: 7 [4600/6700 (69%)]\tLoss: 0.968172\n",
      "Train Epoch: 7 [4700/6700 (70%)]\tLoss: 0.041429\n",
      "Train Epoch: 7 [4800/6700 (72%)]\tLoss: 2.604939\n",
      "Train Epoch: 7 [4900/6700 (73%)]\tLoss: 0.014327\n",
      "Train Epoch: 7 [5000/6700 (75%)]\tLoss: 0.468093\n",
      "Train Epoch: 7 [5100/6700 (76%)]\tLoss: 0.041676\n",
      "Train Epoch: 7 [5200/6700 (78%)]\tLoss: 0.283490\n",
      "Train Epoch: 7 [5300/6700 (79%)]\tLoss: 0.460736\n",
      "Train Epoch: 7 [5400/6700 (81%)]\tLoss: 0.132360\n",
      "Train Epoch: 7 [5500/6700 (82%)]\tLoss: 0.881247\n",
      "Train Epoch: 7 [5600/6700 (84%)]\tLoss: 0.756328\n",
      "Train Epoch: 7 [5700/6700 (85%)]\tLoss: 3.396205\n",
      "Train Epoch: 7 [5800/6700 (87%)]\tLoss: 1.353782\n",
      "Train Epoch: 7 [5900/6700 (88%)]\tLoss: 0.237582\n",
      "Train Epoch: 7 [6000/6700 (90%)]\tLoss: 0.139829\n",
      "Train Epoch: 7 [6100/6700 (91%)]\tLoss: 0.000578\n",
      "Train Epoch: 7 [6200/6700 (93%)]\tLoss: 0.006944\n",
      "Train Epoch: 7 [6300/6700 (94%)]\tLoss: 0.011708\n",
      "Train Epoch: 7 [6400/6700 (96%)]\tLoss: 0.050951\n",
      "Train Epoch: 7 [6500/6700 (97%)]\tLoss: 0.110622\n",
      "Train Epoch: 7 [6600/6700 (99%)]\tLoss: 0.011714\n",
      "====> Epoch: 7 Average loss: 0.5778\n",
      "Train Epoch: 8 [0/6700 (0%)]\tLoss: 0.126027\n",
      "Train Epoch: 8 [100/6700 (1%)]\tLoss: 0.008041\n",
      "Train Epoch: 8 [200/6700 (3%)]\tLoss: 0.159953\n",
      "Train Epoch: 8 [300/6700 (4%)]\tLoss: 0.018915\n",
      "Train Epoch: 8 [400/6700 (6%)]\tLoss: 2.009325\n",
      "Train Epoch: 8 [500/6700 (7%)]\tLoss: 0.301938\n",
      "Train Epoch: 8 [600/6700 (9%)]\tLoss: 0.076796\n",
      "Train Epoch: 8 [700/6700 (10%)]\tLoss: 0.448102\n",
      "Train Epoch: 8 [800/6700 (12%)]\tLoss: 0.934588\n",
      "Train Epoch: 8 [900/6700 (13%)]\tLoss: 0.085956\n",
      "Train Epoch: 8 [1000/6700 (15%)]\tLoss: 0.361926\n",
      "Train Epoch: 8 [1100/6700 (16%)]\tLoss: 0.448744\n",
      "Train Epoch: 8 [1200/6700 (18%)]\tLoss: 0.383359\n",
      "Train Epoch: 8 [1300/6700 (19%)]\tLoss: 0.020592\n",
      "Train Epoch: 8 [1400/6700 (21%)]\tLoss: 0.005263\n",
      "Train Epoch: 8 [1500/6700 (22%)]\tLoss: 0.095154\n",
      "Train Epoch: 8 [1600/6700 (24%)]\tLoss: 0.005735\n",
      "Train Epoch: 8 [1700/6700 (25%)]\tLoss: 0.000295\n",
      "Train Epoch: 8 [1800/6700 (27%)]\tLoss: 0.000530\n",
      "Train Epoch: 8 [1900/6700 (28%)]\tLoss: 0.408612\n",
      "Train Epoch: 8 [2000/6700 (30%)]\tLoss: 6.329455\n",
      "Train Epoch: 8 [2100/6700 (31%)]\tLoss: 0.043555\n",
      "Train Epoch: 8 [2200/6700 (33%)]\tLoss: 0.214138\n",
      "Train Epoch: 8 [2300/6700 (34%)]\tLoss: 0.002429\n",
      "Train Epoch: 8 [2400/6700 (36%)]\tLoss: 0.087528\n",
      "Train Epoch: 8 [2500/6700 (37%)]\tLoss: 0.035845\n",
      "Train Epoch: 8 [2600/6700 (39%)]\tLoss: 0.059674\n",
      "Train Epoch: 8 [2700/6700 (40%)]\tLoss: 0.165826\n",
      "Train Epoch: 8 [2800/6700 (42%)]\tLoss: 0.066385\n",
      "Train Epoch: 8 [2900/6700 (43%)]\tLoss: 0.000055\n",
      "Train Epoch: 8 [3000/6700 (45%)]\tLoss: 0.863150\n",
      "Train Epoch: 8 [3100/6700 (46%)]\tLoss: 0.065019\n",
      "Train Epoch: 8 [3200/6700 (48%)]\tLoss: 0.191942\n",
      "Train Epoch: 8 [3300/6700 (49%)]\tLoss: 1.860560\n",
      "Train Epoch: 8 [3400/6700 (51%)]\tLoss: 0.030629\n",
      "Train Epoch: 8 [3500/6700 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 8 [3600/6700 (54%)]\tLoss: 2.411574\n",
      "Train Epoch: 8 [3700/6700 (55%)]\tLoss: 0.105019\n",
      "Train Epoch: 8 [3800/6700 (57%)]\tLoss: 0.044699\n",
      "Train Epoch: 8 [3900/6700 (58%)]\tLoss: 0.003857\n",
      "Train Epoch: 8 [4000/6700 (60%)]\tLoss: 1.560280\n",
      "Train Epoch: 8 [4100/6700 (61%)]\tLoss: 0.467245\n",
      "Train Epoch: 8 [4200/6700 (63%)]\tLoss: 0.001534\n",
      "Train Epoch: 8 [4300/6700 (64%)]\tLoss: 0.079361\n",
      "Train Epoch: 8 [4400/6700 (66%)]\tLoss: 0.000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [4500/6700 (67%)]\tLoss: 1.098346\n",
      "Train Epoch: 8 [4600/6700 (69%)]\tLoss: 0.378441\n",
      "Train Epoch: 8 [4700/6700 (70%)]\tLoss: 0.073670\n",
      "Train Epoch: 8 [4800/6700 (72%)]\tLoss: 2.694206\n",
      "Train Epoch: 8 [4900/6700 (73%)]\tLoss: 0.014123\n",
      "Train Epoch: 8 [5000/6700 (75%)]\tLoss: 0.558752\n",
      "Train Epoch: 8 [5100/6700 (76%)]\tLoss: 0.023359\n",
      "Train Epoch: 8 [5200/6700 (78%)]\tLoss: 0.283003\n",
      "Train Epoch: 8 [5300/6700 (79%)]\tLoss: 0.380264\n",
      "Train Epoch: 8 [5400/6700 (81%)]\tLoss: 0.117547\n",
      "Train Epoch: 8 [5500/6700 (82%)]\tLoss: 1.217327\n",
      "Train Epoch: 8 [5600/6700 (84%)]\tLoss: 0.971036\n",
      "Train Epoch: 8 [5700/6700 (85%)]\tLoss: 3.140064\n",
      "Train Epoch: 8 [5800/6700 (87%)]\tLoss: 1.176880\n",
      "Train Epoch: 8 [5900/6700 (88%)]\tLoss: 0.240503\n",
      "Train Epoch: 8 [6000/6700 (90%)]\tLoss: 0.178324\n",
      "Train Epoch: 8 [6100/6700 (91%)]\tLoss: 0.000245\n",
      "Train Epoch: 8 [6200/6700 (93%)]\tLoss: 0.005501\n",
      "Train Epoch: 8 [6300/6700 (94%)]\tLoss: 0.010676\n",
      "Train Epoch: 8 [6400/6700 (96%)]\tLoss: 0.037490\n",
      "Train Epoch: 8 [6500/6700 (97%)]\tLoss: 0.143106\n",
      "Train Epoch: 8 [6600/6700 (99%)]\tLoss: 0.008183\n",
      "====> Epoch: 8 Average loss: 0.5563\n",
      "Train Epoch: 9 [0/6700 (0%)]\tLoss: 0.186964\n",
      "Train Epoch: 9 [100/6700 (1%)]\tLoss: 0.007678\n",
      "Train Epoch: 9 [200/6700 (3%)]\tLoss: 0.152159\n",
      "Train Epoch: 9 [300/6700 (4%)]\tLoss: 0.006618\n",
      "Train Epoch: 9 [400/6700 (6%)]\tLoss: 1.544414\n",
      "Train Epoch: 9 [500/6700 (7%)]\tLoss: 0.165631\n",
      "Train Epoch: 9 [600/6700 (9%)]\tLoss: 0.058329\n",
      "Train Epoch: 9 [700/6700 (10%)]\tLoss: 0.683219\n",
      "Train Epoch: 9 [800/6700 (12%)]\tLoss: 0.716567\n",
      "Train Epoch: 9 [900/6700 (13%)]\tLoss: 0.102853\n",
      "Train Epoch: 9 [1000/6700 (15%)]\tLoss: 0.268313\n",
      "Train Epoch: 9 [1100/6700 (16%)]\tLoss: 0.000003\n",
      "Train Epoch: 9 [1200/6700 (18%)]\tLoss: 0.000054\n",
      "Train Epoch: 9 [1300/6700 (19%)]\tLoss: 0.029190\n",
      "Train Epoch: 9 [1400/6700 (21%)]\tLoss: 0.002261\n",
      "Train Epoch: 9 [1500/6700 (22%)]\tLoss: 0.077055\n",
      "Train Epoch: 9 [1600/6700 (24%)]\tLoss: 0.717051\n",
      "Train Epoch: 9 [1700/6700 (25%)]\tLoss: 0.000037\n",
      "Train Epoch: 9 [1800/6700 (27%)]\tLoss: 0.001826\n",
      "Train Epoch: 9 [1900/6700 (28%)]\tLoss: 0.374147\n",
      "Train Epoch: 9 [2000/6700 (30%)]\tLoss: 5.503875\n",
      "Train Epoch: 9 [2100/6700 (31%)]\tLoss: 0.020891\n",
      "Train Epoch: 9 [2200/6700 (33%)]\tLoss: 0.117875\n",
      "Train Epoch: 9 [2300/6700 (34%)]\tLoss: 0.001888\n",
      "Train Epoch: 9 [2400/6700 (36%)]\tLoss: 0.075825\n",
      "Train Epoch: 9 [2500/6700 (37%)]\tLoss: 0.043716\n",
      "Train Epoch: 9 [2600/6700 (39%)]\tLoss: 0.027152\n",
      "Train Epoch: 9 [2700/6700 (40%)]\tLoss: 0.312261\n",
      "Train Epoch: 9 [2800/6700 (42%)]\tLoss: 0.111837\n",
      "Train Epoch: 9 [2900/6700 (43%)]\tLoss: 0.000025\n",
      "Train Epoch: 9 [3000/6700 (45%)]\tLoss: 1.034220\n",
      "Train Epoch: 9 [3100/6700 (46%)]\tLoss: 0.030339\n",
      "Train Epoch: 9 [3200/6700 (48%)]\tLoss: 0.105245\n",
      "Train Epoch: 9 [3300/6700 (49%)]\tLoss: 2.059276\n",
      "Train Epoch: 9 [3400/6700 (51%)]\tLoss: 0.050341\n",
      "Train Epoch: 9 [3500/6700 (52%)]\tLoss: 0.005662\n",
      "Train Epoch: 9 [3600/6700 (54%)]\tLoss: 2.232668\n",
      "Train Epoch: 9 [3700/6700 (55%)]\tLoss: 0.114137\n",
      "Train Epoch: 9 [3800/6700 (57%)]\tLoss: 0.007587\n",
      "Train Epoch: 9 [3900/6700 (58%)]\tLoss: 0.010191\n",
      "Train Epoch: 9 [4000/6700 (60%)]\tLoss: 1.573350\n",
      "Train Epoch: 9 [4100/6700 (61%)]\tLoss: 0.567551\n",
      "Train Epoch: 9 [4200/6700 (63%)]\tLoss: 0.001758\n",
      "Train Epoch: 9 [4300/6700 (64%)]\tLoss: 0.279286\n",
      "Train Epoch: 9 [4400/6700 (66%)]\tLoss: 0.000309\n",
      "Train Epoch: 9 [4500/6700 (67%)]\tLoss: 0.705679\n",
      "Train Epoch: 9 [4600/6700 (69%)]\tLoss: 0.576370\n",
      "Train Epoch: 9 [4700/6700 (70%)]\tLoss: 0.029909\n",
      "Train Epoch: 9 [4800/6700 (72%)]\tLoss: 3.411132\n",
      "Train Epoch: 9 [4900/6700 (73%)]\tLoss: 0.007802\n",
      "Train Epoch: 9 [5000/6700 (75%)]\tLoss: 0.450413\n",
      "Train Epoch: 9 [5100/6700 (76%)]\tLoss: 0.010007\n",
      "Train Epoch: 9 [5200/6700 (78%)]\tLoss: 0.170791\n",
      "Train Epoch: 9 [5300/6700 (79%)]\tLoss: 0.480717\n",
      "Train Epoch: 9 [5400/6700 (81%)]\tLoss: 0.030901\n",
      "Train Epoch: 9 [5500/6700 (82%)]\tLoss: 0.224475\n",
      "Train Epoch: 9 [5600/6700 (84%)]\tLoss: 0.665429\n",
      "Train Epoch: 9 [5700/6700 (85%)]\tLoss: 3.322302\n",
      "Train Epoch: 9 [5800/6700 (87%)]\tLoss: 0.778795\n",
      "Train Epoch: 9 [5900/6700 (88%)]\tLoss: 0.232396\n",
      "Train Epoch: 9 [6000/6700 (90%)]\tLoss: 0.048789\n",
      "Train Epoch: 9 [6100/6700 (91%)]\tLoss: 0.000229\n",
      "Train Epoch: 9 [6200/6700 (93%)]\tLoss: 0.006411\n",
      "Train Epoch: 9 [6300/6700 (94%)]\tLoss: 0.011216\n",
      "Train Epoch: 9 [6400/6700 (96%)]\tLoss: 0.038039\n",
      "Train Epoch: 9 [6500/6700 (97%)]\tLoss: 0.122797\n",
      "Train Epoch: 9 [6600/6700 (99%)]\tLoss: 0.006290\n",
      "====> Epoch: 9 Average loss: 0.5125\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 12 22  4  7]\n",
      " [ 2  1  9  4 15]\n",
      " [ 3 12  4 22 39]\n",
      " ...\n",
      " [ 9 45  1 15 16]\n",
      " [ 4 37  5 16 18]\n",
      " [ 3 12 22 37  4]]\n",
      "[3. 2. 3. ... 9. 4. 3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "print (y_pred)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.774 prec@3: 0.923 prec@5: 0.958\n",
      "mprec@1: 5.077e-01 mprec@3: 7.707e-01 mprec@5: 8.564e-01\n",
      "prec matrix [0.77363636 0.88878788 0.92272727 0.94363636 0.95787879]\n",
      "mprec matrix [0.50767473 0.70322354 0.77065845 0.81476752 0.85638644]\n"
     ]
    }
   ],
   "source": [
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve nn \n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "        torch.nn.init.xavier_uniform_(self.layer1.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            outp = self.forward(x)\n",
    "            return F.softmax(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model declared\n",
    "model = NeuralNet(225 , 2000, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "# loss_function = nn.BCELoss()\n",
    "model_opt = optim.SGD(model.parameters(), lr = 2e-2)\n",
    "\n",
    "train_set_X = Variable(torch.from_numpy(X_train)).float()\n",
    "train_set_y = Variable(torch.LongTensor(y_train)).long()\n",
    "test_set_X = Variable(torch.from_numpy(X_test)).float()\n",
    "test_set_y = Variable(torch.LongTensor(y_test)).long()\n",
    "\n",
    "tr_latent_X = data_utils.TensorDataset(train_set_X, train_set_y)\n",
    "te_latent_X = data_utils.TensorDataset(test_set_X,  test_set_y)\n",
    "train_loader_X = torch.utils.data.DataLoader(dataset=tr_latent_X)\n",
    "test_loader_X = torch.utils.data.DataLoader(dataset=te_latent_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data,label) in enumerate(train_loader_X):\n",
    "\n",
    "        model_opt.zero_grad()\n",
    "\n",
    "        out = model(data)\n",
    "        loss = loss_function(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        model_opt.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_X.dataset),\n",
    "                100. * batch_idx / len(train_loader_X), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader_X.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6700 (0%)]\tLoss: 0.997812\n",
      "Train Epoch: 1 [100/6700 (1%)]\tLoss: 0.391580\n",
      "Train Epoch: 1 [200/6700 (3%)]\tLoss: 0.292221\n",
      "Train Epoch: 1 [300/6700 (4%)]\tLoss: 2.110940\n",
      "Train Epoch: 1 [400/6700 (6%)]\tLoss: 3.587517\n",
      "Train Epoch: 1 [500/6700 (7%)]\tLoss: 0.435281\n",
      "Train Epoch: 1 [600/6700 (9%)]\tLoss: 1.144310\n",
      "Train Epoch: 1 [700/6700 (10%)]\tLoss: 0.836711\n",
      "Train Epoch: 1 [800/6700 (12%)]\tLoss: 1.336656\n",
      "Train Epoch: 1 [900/6700 (13%)]\tLoss: 0.168676\n",
      "Train Epoch: 1 [1000/6700 (15%)]\tLoss: 2.091824\n",
      "Train Epoch: 1 [1100/6700 (16%)]\tLoss: 0.440215\n",
      "Train Epoch: 1 [1200/6700 (18%)]\tLoss: 3.739551\n",
      "Train Epoch: 1 [1300/6700 (19%)]\tLoss: 0.223060\n",
      "Train Epoch: 1 [1400/6700 (21%)]\tLoss: 1.694005\n",
      "Train Epoch: 1 [1500/6700 (22%)]\tLoss: 0.515216\n",
      "Train Epoch: 1 [1600/6700 (24%)]\tLoss: 0.791302\n",
      "Train Epoch: 1 [1700/6700 (25%)]\tLoss: 0.209391\n",
      "Train Epoch: 1 [1800/6700 (27%)]\tLoss: 0.281927\n",
      "Train Epoch: 1 [1900/6700 (28%)]\tLoss: 0.298227\n",
      "Train Epoch: 1 [2000/6700 (30%)]\tLoss: 3.423648\n",
      "Train Epoch: 1 [2100/6700 (31%)]\tLoss: 1.167423\n",
      "Train Epoch: 1 [2200/6700 (33%)]\tLoss: 2.332241\n",
      "Train Epoch: 1 [2300/6700 (34%)]\tLoss: 0.066772\n",
      "Train Epoch: 1 [2400/6700 (36%)]\tLoss: 2.587700\n",
      "Train Epoch: 1 [2500/6700 (37%)]\tLoss: 0.257553\n",
      "Train Epoch: 1 [2600/6700 (39%)]\tLoss: 0.614398\n",
      "Train Epoch: 1 [2700/6700 (40%)]\tLoss: 4.473333\n",
      "Train Epoch: 1 [2800/6700 (42%)]\tLoss: 1.202335\n",
      "Train Epoch: 1 [2900/6700 (43%)]\tLoss: 1.743528\n",
      "Train Epoch: 1 [3000/6700 (45%)]\tLoss: 2.569933\n",
      "Train Epoch: 1 [3100/6700 (46%)]\tLoss: 1.427051\n",
      "Train Epoch: 1 [3200/6700 (48%)]\tLoss: 0.163603\n",
      "Train Epoch: 1 [3300/6700 (49%)]\tLoss: 4.000513\n",
      "Train Epoch: 1 [3400/6700 (51%)]\tLoss: 0.459244\n",
      "Train Epoch: 1 [3500/6700 (52%)]\tLoss: 0.341933\n",
      "Train Epoch: 1 [3600/6700 (54%)]\tLoss: 1.436514\n",
      "Train Epoch: 1 [3700/6700 (55%)]\tLoss: 0.803114\n",
      "Train Epoch: 1 [3800/6700 (57%)]\tLoss: 0.482064\n",
      "Train Epoch: 1 [3900/6700 (58%)]\tLoss: 0.894216\n",
      "Train Epoch: 1 [4000/6700 (60%)]\tLoss: 1.718708\n",
      "Train Epoch: 1 [4100/6700 (61%)]\tLoss: 0.278347\n",
      "Train Epoch: 1 [4200/6700 (63%)]\tLoss: 0.214856\n",
      "Train Epoch: 1 [4300/6700 (64%)]\tLoss: 0.846186\n",
      "Train Epoch: 1 [4400/6700 (66%)]\tLoss: 1.098767\n",
      "Train Epoch: 1 [4500/6700 (67%)]\tLoss: 2.774893\n",
      "Train Epoch: 1 [4600/6700 (69%)]\tLoss: 2.809950\n",
      "Train Epoch: 1 [4700/6700 (70%)]\tLoss: 0.997027\n",
      "Train Epoch: 1 [4800/6700 (72%)]\tLoss: 1.860177\n",
      "Train Epoch: 1 [4900/6700 (73%)]\tLoss: 4.098203\n",
      "Train Epoch: 1 [5000/6700 (75%)]\tLoss: 4.045757\n",
      "Train Epoch: 1 [5100/6700 (76%)]\tLoss: 1.040363\n",
      "Train Epoch: 1 [5200/6700 (78%)]\tLoss: 1.633801\n",
      "Train Epoch: 1 [5300/6700 (79%)]\tLoss: 0.944336\n",
      "Train Epoch: 1 [5400/6700 (81%)]\tLoss: 0.099393\n",
      "Train Epoch: 1 [5500/6700 (82%)]\tLoss: 1.342067\n",
      "Train Epoch: 1 [5600/6700 (84%)]\tLoss: 5.565536\n",
      "Train Epoch: 1 [5700/6700 (85%)]\tLoss: 3.602725\n",
      "Train Epoch: 1 [5800/6700 (87%)]\tLoss: 2.699875\n",
      "Train Epoch: 1 [5900/6700 (88%)]\tLoss: 1.662568\n",
      "Train Epoch: 1 [6000/6700 (90%)]\tLoss: 0.679594\n",
      "Train Epoch: 1 [6100/6700 (91%)]\tLoss: 0.318960\n",
      "Train Epoch: 1 [6200/6700 (93%)]\tLoss: 0.442782\n",
      "Train Epoch: 1 [6300/6700 (94%)]\tLoss: 0.169972\n",
      "Train Epoch: 1 [6400/6700 (96%)]\tLoss: 4.321680\n",
      "Train Epoch: 1 [6500/6700 (97%)]\tLoss: 0.231338\n",
      "Train Epoch: 1 [6600/6700 (99%)]\tLoss: 1.956292\n",
      "====> Epoch: 1 Average loss: 1.5889\n",
      "Train Epoch: 2 [0/6700 (0%)]\tLoss: 0.964935\n",
      "Train Epoch: 2 [100/6700 (1%)]\tLoss: 0.347305\n",
      "Train Epoch: 2 [200/6700 (3%)]\tLoss: 0.258910\n",
      "Train Epoch: 2 [300/6700 (4%)]\tLoss: 1.866731\n",
      "Train Epoch: 2 [400/6700 (6%)]\tLoss: 3.471988\n",
      "Train Epoch: 2 [500/6700 (7%)]\tLoss: 0.400551\n",
      "Train Epoch: 2 [600/6700 (9%)]\tLoss: 0.959887\n",
      "Train Epoch: 2 [700/6700 (10%)]\tLoss: 0.796623\n",
      "Train Epoch: 2 [800/6700 (12%)]\tLoss: 1.249825\n",
      "Train Epoch: 2 [900/6700 (13%)]\tLoss: 0.125891\n",
      "Train Epoch: 2 [1000/6700 (15%)]\tLoss: 1.901871\n",
      "Train Epoch: 2 [1100/6700 (16%)]\tLoss: 1.370198\n",
      "Train Epoch: 2 [1200/6700 (18%)]\tLoss: 1.528285\n",
      "Train Epoch: 2 [1300/6700 (19%)]\tLoss: 0.145548\n",
      "Train Epoch: 2 [1400/6700 (21%)]\tLoss: 1.413782\n",
      "Train Epoch: 2 [1500/6700 (22%)]\tLoss: 0.431402\n",
      "Train Epoch: 2 [1600/6700 (24%)]\tLoss: 0.949840\n",
      "Train Epoch: 2 [1700/6700 (25%)]\tLoss: 0.224120\n",
      "Train Epoch: 2 [1800/6700 (27%)]\tLoss: 0.148621\n",
      "Train Epoch: 2 [1900/6700 (28%)]\tLoss: 0.253667\n",
      "Train Epoch: 2 [2000/6700 (30%)]\tLoss: 3.574246\n",
      "Train Epoch: 2 [2100/6700 (31%)]\tLoss: 1.005900\n",
      "Train Epoch: 2 [2200/6700 (33%)]\tLoss: 2.104204\n",
      "Train Epoch: 2 [2300/6700 (34%)]\tLoss: 0.041838\n",
      "Train Epoch: 2 [2400/6700 (36%)]\tLoss: 2.149331\n",
      "Train Epoch: 2 [2500/6700 (37%)]\tLoss: 0.230806\n",
      "Train Epoch: 2 [2600/6700 (39%)]\tLoss: 0.566467\n",
      "Train Epoch: 2 [2700/6700 (40%)]\tLoss: 4.229522\n",
      "Train Epoch: 2 [2800/6700 (42%)]\tLoss: 1.141282\n",
      "Train Epoch: 2 [2900/6700 (43%)]\tLoss: 1.464777\n",
      "Train Epoch: 2 [3000/6700 (45%)]\tLoss: 2.370595\n",
      "Train Epoch: 2 [3100/6700 (46%)]\tLoss: 1.284174\n",
      "Train Epoch: 2 [3200/6700 (48%)]\tLoss: 0.133005\n",
      "Train Epoch: 2 [3300/6700 (49%)]\tLoss: 3.995924\n",
      "Train Epoch: 2 [3400/6700 (51%)]\tLoss: 0.359951\n",
      "Train Epoch: 2 [3500/6700 (52%)]\tLoss: 0.113122\n",
      "Train Epoch: 2 [3600/6700 (54%)]\tLoss: 1.468772\n",
      "Train Epoch: 2 [3700/6700 (55%)]\tLoss: 0.712029\n",
      "Train Epoch: 2 [3800/6700 (57%)]\tLoss: 0.429733\n",
      "Train Epoch: 2 [3900/6700 (58%)]\tLoss: 0.717997\n",
      "Train Epoch: 2 [4000/6700 (60%)]\tLoss: 1.682488\n",
      "Train Epoch: 2 [4100/6700 (61%)]\tLoss: 0.256716\n",
      "Train Epoch: 2 [4200/6700 (63%)]\tLoss: 0.169401\n",
      "Train Epoch: 2 [4300/6700 (64%)]\tLoss: 0.901964\n",
      "Train Epoch: 2 [4400/6700 (66%)]\tLoss: 0.770375\n",
      "Train Epoch: 2 [4500/6700 (67%)]\tLoss: 2.352626\n",
      "Train Epoch: 2 [4600/6700 (69%)]\tLoss: 2.797594\n",
      "Train Epoch: 2 [4700/6700 (70%)]\tLoss: 0.912869\n",
      "Train Epoch: 2 [4800/6700 (72%)]\tLoss: 1.917715\n",
      "Train Epoch: 2 [4900/6700 (73%)]\tLoss: 3.764583\n",
      "Train Epoch: 2 [5000/6700 (75%)]\tLoss: 3.847668\n",
      "Train Epoch: 2 [5100/6700 (76%)]\tLoss: 0.782899\n",
      "Train Epoch: 2 [5200/6700 (78%)]\tLoss: 1.501246\n",
      "Train Epoch: 2 [5300/6700 (79%)]\tLoss: 0.857763\n",
      "Train Epoch: 2 [5400/6700 (81%)]\tLoss: 0.078086\n",
      "Train Epoch: 2 [5500/6700 (82%)]\tLoss: 1.264362\n",
      "Train Epoch: 2 [5600/6700 (84%)]\tLoss: 5.538833\n",
      "Train Epoch: 2 [5700/6700 (85%)]\tLoss: 3.202114\n",
      "Train Epoch: 2 [5800/6700 (87%)]\tLoss: 2.534708\n",
      "Train Epoch: 2 [5900/6700 (88%)]\tLoss: 1.440962\n",
      "Train Epoch: 2 [6000/6700 (90%)]\tLoss: 0.719679\n",
      "Train Epoch: 2 [6100/6700 (91%)]\tLoss: 0.237719\n",
      "Train Epoch: 2 [6200/6700 (93%)]\tLoss: 0.389115\n",
      "Train Epoch: 2 [6300/6700 (94%)]\tLoss: 0.126436\n",
      "Train Epoch: 2 [6400/6700 (96%)]\tLoss: 4.115267\n",
      "Train Epoch: 2 [6500/6700 (97%)]\tLoss: 0.208261\n",
      "Train Epoch: 2 [6600/6700 (99%)]\tLoss: 1.540944\n",
      "====> Epoch: 2 Average loss: 1.4798\n",
      "Train Epoch: 3 [0/6700 (0%)]\tLoss: 0.860512\n",
      "Train Epoch: 3 [100/6700 (1%)]\tLoss: 0.304316\n",
      "Train Epoch: 3 [200/6700 (3%)]\tLoss: 0.243989\n",
      "Train Epoch: 3 [300/6700 (4%)]\tLoss: 1.604761\n",
      "Train Epoch: 3 [400/6700 (6%)]\tLoss: 3.507475\n",
      "Train Epoch: 3 [500/6700 (7%)]\tLoss: 0.362504\n",
      "Train Epoch: 3 [600/6700 (9%)]\tLoss: 0.860777\n",
      "Train Epoch: 3 [700/6700 (10%)]\tLoss: 0.722366\n",
      "Train Epoch: 3 [800/6700 (12%)]\tLoss: 1.205618\n",
      "Train Epoch: 3 [900/6700 (13%)]\tLoss: 0.103620\n",
      "Train Epoch: 3 [1000/6700 (15%)]\tLoss: 1.740940\n",
      "Train Epoch: 3 [1100/6700 (16%)]\tLoss: 1.505422\n",
      "Train Epoch: 3 [1200/6700 (18%)]\tLoss: 0.635908\n",
      "Train Epoch: 3 [1300/6700 (19%)]\tLoss: 0.113220\n",
      "Train Epoch: 3 [1400/6700 (21%)]\tLoss: 1.162209\n",
      "Train Epoch: 3 [1500/6700 (22%)]\tLoss: 0.390755\n",
      "Train Epoch: 3 [1600/6700 (24%)]\tLoss: 1.075212\n",
      "Train Epoch: 3 [1700/6700 (25%)]\tLoss: 0.223205\n",
      "Train Epoch: 3 [1800/6700 (27%)]\tLoss: 0.099505\n",
      "Train Epoch: 3 [1900/6700 (28%)]\tLoss: 0.228661\n",
      "Train Epoch: 3 [2000/6700 (30%)]\tLoss: 3.727792\n",
      "Train Epoch: 3 [2100/6700 (31%)]\tLoss: 0.906798\n",
      "Train Epoch: 3 [2200/6700 (33%)]\tLoss: 1.899552\n",
      "Train Epoch: 3 [2300/6700 (34%)]\tLoss: 0.031953\n",
      "Train Epoch: 3 [2400/6700 (36%)]\tLoss: 1.761174\n",
      "Train Epoch: 3 [2500/6700 (37%)]\tLoss: 0.200776\n",
      "Train Epoch: 3 [2600/6700 (39%)]\tLoss: 0.547881\n",
      "Train Epoch: 3 [2700/6700 (40%)]\tLoss: 3.965570\n",
      "Train Epoch: 3 [2800/6700 (42%)]\tLoss: 1.101888\n",
      "Train Epoch: 3 [2900/6700 (43%)]\tLoss: 1.255034\n",
      "Train Epoch: 3 [3000/6700 (45%)]\tLoss: 2.181250\n",
      "Train Epoch: 3 [3100/6700 (46%)]\tLoss: 1.158443\n",
      "Train Epoch: 3 [3200/6700 (48%)]\tLoss: 0.116793\n",
      "Train Epoch: 3 [3300/6700 (49%)]\tLoss: 3.988363\n",
      "Train Epoch: 3 [3400/6700 (51%)]\tLoss: 0.300894\n",
      "Train Epoch: 3 [3500/6700 (52%)]\tLoss: 0.056751\n",
      "Train Epoch: 3 [3600/6700 (54%)]\tLoss: 1.402579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [3700/6700 (55%)]\tLoss: 0.644787\n",
      "Train Epoch: 3 [3800/6700 (57%)]\tLoss: 0.402450\n",
      "Train Epoch: 3 [3900/6700 (58%)]\tLoss: 0.578019\n",
      "Train Epoch: 3 [4000/6700 (60%)]\tLoss: 1.633059\n",
      "Train Epoch: 3 [4100/6700 (61%)]\tLoss: 0.237288\n",
      "Train Epoch: 3 [4200/6700 (63%)]\tLoss: 0.140292\n",
      "Train Epoch: 3 [4300/6700 (64%)]\tLoss: 0.936665\n",
      "Train Epoch: 3 [4400/6700 (66%)]\tLoss: 0.508655\n",
      "Train Epoch: 3 [4500/6700 (67%)]\tLoss: 2.087046\n",
      "Train Epoch: 3 [4600/6700 (69%)]\tLoss: 2.792710\n",
      "Train Epoch: 3 [4700/6700 (70%)]\tLoss: 0.843279\n",
      "Train Epoch: 3 [4800/6700 (72%)]\tLoss: 1.957003\n",
      "Train Epoch: 3 [4900/6700 (73%)]\tLoss: 3.461727\n",
      "Train Epoch: 3 [5000/6700 (75%)]\tLoss: 3.719390\n",
      "Train Epoch: 3 [5100/6700 (76%)]\tLoss: 0.565472\n",
      "Train Epoch: 3 [5200/6700 (78%)]\tLoss: 1.392919\n",
      "Train Epoch: 3 [5300/6700 (79%)]\tLoss: 0.805445\n",
      "Train Epoch: 3 [5400/6700 (81%)]\tLoss: 0.070606\n",
      "Train Epoch: 3 [5500/6700 (82%)]\tLoss: 1.204242\n",
      "Train Epoch: 3 [5600/6700 (84%)]\tLoss: 5.490761\n",
      "Train Epoch: 3 [5700/6700 (85%)]\tLoss: 2.896226\n",
      "Train Epoch: 3 [5800/6700 (87%)]\tLoss: 2.379970\n",
      "Train Epoch: 3 [5900/6700 (88%)]\tLoss: 1.243615\n",
      "Train Epoch: 3 [6000/6700 (90%)]\tLoss: 0.748166\n",
      "Train Epoch: 3 [6100/6700 (91%)]\tLoss: 0.186791\n",
      "Train Epoch: 3 [6200/6700 (93%)]\tLoss: 0.357275\n",
      "Train Epoch: 3 [6300/6700 (94%)]\tLoss: 0.102589\n",
      "Train Epoch: 3 [6400/6700 (96%)]\tLoss: 3.917083\n",
      "Train Epoch: 3 [6500/6700 (97%)]\tLoss: 0.193893\n",
      "Train Epoch: 3 [6600/6700 (99%)]\tLoss: 1.213996\n",
      "====> Epoch: 3 Average loss: 1.3924\n",
      "Train Epoch: 4 [0/6700 (0%)]\tLoss: 0.790213\n",
      "Train Epoch: 4 [100/6700 (1%)]\tLoss: 0.278624\n",
      "Train Epoch: 4 [200/6700 (3%)]\tLoss: 0.232361\n",
      "Train Epoch: 4 [300/6700 (4%)]\tLoss: 1.385992\n",
      "Train Epoch: 4 [400/6700 (6%)]\tLoss: 3.533331\n",
      "Train Epoch: 4 [500/6700 (7%)]\tLoss: 0.331793\n",
      "Train Epoch: 4 [600/6700 (9%)]\tLoss: 0.774242\n",
      "Train Epoch: 4 [700/6700 (10%)]\tLoss: 0.657214\n",
      "Train Epoch: 4 [800/6700 (12%)]\tLoss: 1.188415\n",
      "Train Epoch: 4 [900/6700 (13%)]\tLoss: 0.089638\n",
      "Train Epoch: 4 [1000/6700 (15%)]\tLoss: 1.582026\n",
      "Train Epoch: 4 [1100/6700 (16%)]\tLoss: 1.712567\n",
      "Train Epoch: 4 [1200/6700 (18%)]\tLoss: 0.285738\n",
      "Train Epoch: 4 [1300/6700 (19%)]\tLoss: 0.092463\n",
      "Train Epoch: 4 [1400/6700 (21%)]\tLoss: 0.975109\n",
      "Train Epoch: 4 [1500/6700 (22%)]\tLoss: 0.364315\n",
      "Train Epoch: 4 [1600/6700 (24%)]\tLoss: 1.143030\n",
      "Train Epoch: 4 [1700/6700 (25%)]\tLoss: 0.216341\n",
      "Train Epoch: 4 [1800/6700 (27%)]\tLoss: 0.076131\n",
      "Train Epoch: 4 [1900/6700 (28%)]\tLoss: 0.209959\n",
      "Train Epoch: 4 [2000/6700 (30%)]\tLoss: 3.858097\n",
      "Train Epoch: 4 [2100/6700 (31%)]\tLoss: 0.843277\n",
      "Train Epoch: 4 [2200/6700 (33%)]\tLoss: 1.710727\n",
      "Train Epoch: 4 [2300/6700 (34%)]\tLoss: 0.027739\n",
      "Train Epoch: 4 [2400/6700 (36%)]\tLoss: 1.440519\n",
      "Train Epoch: 4 [2500/6700 (37%)]\tLoss: 0.174761\n",
      "Train Epoch: 4 [2600/6700 (39%)]\tLoss: 0.538403\n",
      "Train Epoch: 4 [2700/6700 (40%)]\tLoss: 3.709435\n",
      "Train Epoch: 4 [2800/6700 (42%)]\tLoss: 1.063707\n",
      "Train Epoch: 4 [2900/6700 (43%)]\tLoss: 1.084631\n",
      "Train Epoch: 4 [3000/6700 (45%)]\tLoss: 2.018506\n",
      "Train Epoch: 4 [3100/6700 (46%)]\tLoss: 1.032542\n",
      "Train Epoch: 4 [3200/6700 (48%)]\tLoss: 0.106534\n",
      "Train Epoch: 4 [3300/6700 (49%)]\tLoss: 3.975003\n",
      "Train Epoch: 4 [3400/6700 (51%)]\tLoss: 0.259439\n",
      "Train Epoch: 4 [3500/6700 (52%)]\tLoss: 0.039032\n",
      "Train Epoch: 4 [3600/6700 (54%)]\tLoss: 1.339542\n",
      "Train Epoch: 4 [3700/6700 (55%)]\tLoss: 0.589206\n",
      "Train Epoch: 4 [3800/6700 (57%)]\tLoss: 0.384220\n",
      "Train Epoch: 4 [3900/6700 (58%)]\tLoss: 0.479578\n",
      "Train Epoch: 4 [4000/6700 (60%)]\tLoss: 1.523730\n",
      "Train Epoch: 4 [4100/6700 (61%)]\tLoss: 0.222822\n",
      "Train Epoch: 4 [4200/6700 (63%)]\tLoss: 0.120748\n",
      "Train Epoch: 4 [4300/6700 (64%)]\tLoss: 0.948366\n",
      "Train Epoch: 4 [4400/6700 (66%)]\tLoss: 0.333813\n",
      "Train Epoch: 4 [4500/6700 (67%)]\tLoss: 1.919024\n",
      "Train Epoch: 4 [4600/6700 (69%)]\tLoss: 2.804451\n",
      "Train Epoch: 4 [4700/6700 (70%)]\tLoss: 0.780454\n",
      "Train Epoch: 4 [4800/6700 (72%)]\tLoss: 1.974563\n",
      "Train Epoch: 4 [4900/6700 (73%)]\tLoss: 3.180066\n",
      "Train Epoch: 4 [5000/6700 (75%)]\tLoss: 3.608691\n",
      "Train Epoch: 4 [5100/6700 (76%)]\tLoss: 0.407358\n",
      "Train Epoch: 4 [5200/6700 (78%)]\tLoss: 1.303650\n",
      "Train Epoch: 4 [5300/6700 (79%)]\tLoss: 0.771945\n",
      "Train Epoch: 4 [5400/6700 (81%)]\tLoss: 0.070333\n",
      "Train Epoch: 4 [5500/6700 (82%)]\tLoss: 1.160261\n",
      "Train Epoch: 4 [5600/6700 (84%)]\tLoss: 5.431095\n",
      "Train Epoch: 4 [5700/6700 (85%)]\tLoss: 2.659563\n",
      "Train Epoch: 4 [5800/6700 (87%)]\tLoss: 2.237987\n",
      "Train Epoch: 4 [5900/6700 (88%)]\tLoss: 1.077427\n",
      "Train Epoch: 4 [6000/6700 (90%)]\tLoss: 0.764832\n",
      "Train Epoch: 4 [6100/6700 (91%)]\tLoss: 0.152692\n",
      "Train Epoch: 4 [6200/6700 (93%)]\tLoss: 0.334485\n",
      "Train Epoch: 4 [6300/6700 (94%)]\tLoss: 0.087146\n",
      "Train Epoch: 4 [6400/6700 (96%)]\tLoss: 3.720915\n",
      "Train Epoch: 4 [6500/6700 (97%)]\tLoss: 0.183118\n",
      "Train Epoch: 4 [6600/6700 (99%)]\tLoss: 0.971063\n",
      "====> Epoch: 4 Average loss: 1.3188\n",
      "Train Epoch: 5 [0/6700 (0%)]\tLoss: 0.737538\n",
      "Train Epoch: 5 [100/6700 (1%)]\tLoss: 0.260095\n",
      "Train Epoch: 5 [200/6700 (3%)]\tLoss: 0.223999\n",
      "Train Epoch: 5 [300/6700 (4%)]\tLoss: 1.206057\n",
      "Train Epoch: 5 [400/6700 (6%)]\tLoss: 3.547079\n",
      "Train Epoch: 5 [500/6700 (7%)]\tLoss: 0.303805\n",
      "Train Epoch: 5 [600/6700 (9%)]\tLoss: 0.691988\n",
      "Train Epoch: 5 [700/6700 (10%)]\tLoss: 0.598105\n",
      "Train Epoch: 5 [800/6700 (12%)]\tLoss: 1.174395\n",
      "Train Epoch: 5 [900/6700 (13%)]\tLoss: 0.079952\n",
      "Train Epoch: 5 [1000/6700 (15%)]\tLoss: 1.438801\n",
      "Train Epoch: 5 [1100/6700 (16%)]\tLoss: 1.928450\n",
      "Train Epoch: 5 [1200/6700 (18%)]\tLoss: 0.162788\n",
      "Train Epoch: 5 [1300/6700 (19%)]\tLoss: 0.077726\n",
      "Train Epoch: 5 [1400/6700 (21%)]\tLoss: 0.835124\n",
      "Train Epoch: 5 [1500/6700 (22%)]\tLoss: 0.343138\n",
      "Train Epoch: 5 [1600/6700 (24%)]\tLoss: 1.115175\n",
      "Train Epoch: 5 [1700/6700 (25%)]\tLoss: 0.204920\n",
      "Train Epoch: 5 [1800/6700 (27%)]\tLoss: 0.064017\n",
      "Train Epoch: 5 [1900/6700 (28%)]\tLoss: 0.194057\n",
      "Train Epoch: 5 [2000/6700 (30%)]\tLoss: 3.964391\n",
      "Train Epoch: 5 [2100/6700 (31%)]\tLoss: 0.794093\n",
      "Train Epoch: 5 [2200/6700 (33%)]\tLoss: 1.548572\n",
      "Train Epoch: 5 [2300/6700 (34%)]\tLoss: 0.026384\n",
      "Train Epoch: 5 [2400/6700 (36%)]\tLoss: 1.187818\n",
      "Train Epoch: 5 [2500/6700 (37%)]\tLoss: 0.153773\n",
      "Train Epoch: 5 [2600/6700 (39%)]\tLoss: 0.529371\n",
      "Train Epoch: 5 [2700/6700 (40%)]\tLoss: 3.487338\n",
      "Train Epoch: 5 [2800/6700 (42%)]\tLoss: 1.021228\n",
      "Train Epoch: 5 [2900/6700 (43%)]\tLoss: 0.935948\n",
      "Train Epoch: 5 [3000/6700 (45%)]\tLoss: 1.887816\n",
      "Train Epoch: 5 [3100/6700 (46%)]\tLoss: 0.909813\n",
      "Train Epoch: 5 [3200/6700 (48%)]\tLoss: 0.099000\n",
      "Train Epoch: 5 [3300/6700 (49%)]\tLoss: 3.943082\n",
      "Train Epoch: 5 [3400/6700 (51%)]\tLoss: 0.227970\n",
      "Train Epoch: 5 [3500/6700 (52%)]\tLoss: 0.033444\n",
      "Train Epoch: 5 [3600/6700 (54%)]\tLoss: 1.292293\n",
      "Train Epoch: 5 [3700/6700 (55%)]\tLoss: 0.544166\n",
      "Train Epoch: 5 [3800/6700 (57%)]\tLoss: 0.367351\n",
      "Train Epoch: 5 [3900/6700 (58%)]\tLoss: 0.401959\n",
      "Train Epoch: 5 [4000/6700 (60%)]\tLoss: 1.397413\n",
      "Train Epoch: 5 [4100/6700 (61%)]\tLoss: 0.212306\n",
      "Train Epoch: 5 [4200/6700 (63%)]\tLoss: 0.105963\n",
      "Train Epoch: 5 [4300/6700 (64%)]\tLoss: 0.946422\n",
      "Train Epoch: 5 [4400/6700 (66%)]\tLoss: 0.218812\n",
      "Train Epoch: 5 [4500/6700 (67%)]\tLoss: 1.807378\n",
      "Train Epoch: 5 [4600/6700 (69%)]\tLoss: 2.828270\n",
      "Train Epoch: 5 [4700/6700 (70%)]\tLoss: 0.722135\n",
      "Train Epoch: 5 [4800/6700 (72%)]\tLoss: 1.973002\n",
      "Train Epoch: 5 [4900/6700 (73%)]\tLoss: 2.920562\n",
      "Train Epoch: 5 [5000/6700 (75%)]\tLoss: 3.507118\n",
      "Train Epoch: 5 [5100/6700 (76%)]\tLoss: 0.295827\n",
      "Train Epoch: 5 [5200/6700 (78%)]\tLoss: 1.231386\n",
      "Train Epoch: 5 [5300/6700 (79%)]\tLoss: 0.747772\n",
      "Train Epoch: 5 [5400/6700 (81%)]\tLoss: 0.074583\n",
      "Train Epoch: 5 [5500/6700 (82%)]\tLoss: 1.113813\n",
      "Train Epoch: 5 [5600/6700 (84%)]\tLoss: 5.367677\n",
      "Train Epoch: 5 [5700/6700 (85%)]\tLoss: 2.464916\n",
      "Train Epoch: 5 [5800/6700 (87%)]\tLoss: 2.107858\n",
      "Train Epoch: 5 [5900/6700 (88%)]\tLoss: 0.935180\n",
      "Train Epoch: 5 [6000/6700 (90%)]\tLoss: 0.771371\n",
      "Train Epoch: 5 [6100/6700 (91%)]\tLoss: 0.128463\n",
      "Train Epoch: 5 [6200/6700 (93%)]\tLoss: 0.316034\n",
      "Train Epoch: 5 [6300/6700 (94%)]\tLoss: 0.075695\n",
      "Train Epoch: 5 [6400/6700 (96%)]\tLoss: 3.525624\n",
      "Train Epoch: 5 [6500/6700 (97%)]\tLoss: 0.173990\n",
      "Train Epoch: 5 [6600/6700 (99%)]\tLoss: 0.794825\n",
      "====> Epoch: 5 Average loss: 1.2553\n",
      "Train Epoch: 6 [0/6700 (0%)]\tLoss: 0.694087\n",
      "Train Epoch: 6 [100/6700 (1%)]\tLoss: 0.244715\n",
      "Train Epoch: 6 [200/6700 (3%)]\tLoss: 0.218449\n",
      "Train Epoch: 6 [300/6700 (4%)]\tLoss: 1.058128\n",
      "Train Epoch: 6 [400/6700 (6%)]\tLoss: 3.548389\n",
      "Train Epoch: 6 [500/6700 (7%)]\tLoss: 0.278196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [600/6700 (9%)]\tLoss: 0.616655\n",
      "Train Epoch: 6 [700/6700 (10%)]\tLoss: 0.544162\n",
      "Train Epoch: 6 [800/6700 (12%)]\tLoss: 1.157858\n",
      "Train Epoch: 6 [900/6700 (13%)]\tLoss: 0.073176\n",
      "Train Epoch: 6 [1000/6700 (15%)]\tLoss: 1.306798\n",
      "Train Epoch: 6 [1100/6700 (16%)]\tLoss: 2.112992\n",
      "Train Epoch: 6 [1200/6700 (18%)]\tLoss: 0.110443\n",
      "Train Epoch: 6 [1300/6700 (19%)]\tLoss: 0.066171\n",
      "Train Epoch: 6 [1400/6700 (21%)]\tLoss: 0.728813\n",
      "Train Epoch: 6 [1500/6700 (22%)]\tLoss: 0.325391\n",
      "Train Epoch: 6 [1600/6700 (24%)]\tLoss: 1.031511\n",
      "Train Epoch: 6 [1700/6700 (25%)]\tLoss: 0.192525\n",
      "Train Epoch: 6 [1800/6700 (27%)]\tLoss: 0.055483\n",
      "Train Epoch: 6 [1900/6700 (28%)]\tLoss: 0.179637\n",
      "Train Epoch: 6 [2000/6700 (30%)]\tLoss: 4.051596\n",
      "Train Epoch: 6 [2100/6700 (31%)]\tLoss: 0.754219\n",
      "Train Epoch: 6 [2200/6700 (33%)]\tLoss: 1.419675\n",
      "Train Epoch: 6 [2300/6700 (34%)]\tLoss: 0.026184\n",
      "Train Epoch: 6 [2400/6700 (36%)]\tLoss: 0.996778\n",
      "Train Epoch: 6 [2500/6700 (37%)]\tLoss: 0.138013\n",
      "Train Epoch: 6 [2600/6700 (39%)]\tLoss: 0.520562\n",
      "Train Epoch: 6 [2700/6700 (40%)]\tLoss: 3.314273\n",
      "Train Epoch: 6 [2800/6700 (42%)]\tLoss: 0.976380\n",
      "Train Epoch: 6 [2900/6700 (43%)]\tLoss: 0.801292\n",
      "Train Epoch: 6 [3000/6700 (45%)]\tLoss: 1.787365\n",
      "Train Epoch: 6 [3100/6700 (46%)]\tLoss: 0.796086\n",
      "Train Epoch: 6 [3200/6700 (48%)]\tLoss: 0.093017\n",
      "Train Epoch: 6 [3300/6700 (49%)]\tLoss: 3.898241\n",
      "Train Epoch: 6 [3400/6700 (51%)]\tLoss: 0.203480\n",
      "Train Epoch: 6 [3500/6700 (52%)]\tLoss: 0.034302\n",
      "Train Epoch: 6 [3600/6700 (54%)]\tLoss: 1.263260\n",
      "Train Epoch: 6 [3700/6700 (55%)]\tLoss: 0.502538\n",
      "Train Epoch: 6 [3800/6700 (57%)]\tLoss: 0.352187\n",
      "Train Epoch: 6 [3900/6700 (58%)]\tLoss: 0.340564\n",
      "Train Epoch: 6 [4000/6700 (60%)]\tLoss: 1.263578\n",
      "Train Epoch: 6 [4100/6700 (61%)]\tLoss: 0.205108\n",
      "Train Epoch: 6 [4200/6700 (63%)]\tLoss: 0.095022\n",
      "Train Epoch: 6 [4300/6700 (64%)]\tLoss: 0.925735\n",
      "Train Epoch: 6 [4400/6700 (66%)]\tLoss: 0.144951\n",
      "Train Epoch: 6 [4500/6700 (67%)]\tLoss: 1.731623\n",
      "Train Epoch: 6 [4600/6700 (69%)]\tLoss: 2.857695\n",
      "Train Epoch: 6 [4700/6700 (70%)]\tLoss: 0.668442\n",
      "Train Epoch: 6 [4800/6700 (72%)]\tLoss: 1.963609\n",
      "Train Epoch: 6 [4900/6700 (73%)]\tLoss: 2.683365\n",
      "Train Epoch: 6 [5000/6700 (75%)]\tLoss: 3.412356\n",
      "Train Epoch: 6 [5100/6700 (76%)]\tLoss: 0.220456\n",
      "Train Epoch: 6 [5200/6700 (78%)]\tLoss: 1.173654\n",
      "Train Epoch: 6 [5300/6700 (79%)]\tLoss: 0.728357\n",
      "Train Epoch: 6 [5400/6700 (81%)]\tLoss: 0.081736\n",
      "Train Epoch: 6 [5500/6700 (82%)]\tLoss: 1.058984\n",
      "Train Epoch: 6 [5600/6700 (84%)]\tLoss: 5.295569\n",
      "Train Epoch: 6 [5700/6700 (85%)]\tLoss: 2.300629\n",
      "Train Epoch: 6 [5800/6700 (87%)]\tLoss: 1.990176\n",
      "Train Epoch: 6 [5900/6700 (88%)]\tLoss: 0.817445\n",
      "Train Epoch: 6 [6000/6700 (90%)]\tLoss: 0.766384\n",
      "Train Epoch: 6 [6100/6700 (91%)]\tLoss: 0.110356\n",
      "Train Epoch: 6 [6200/6700 (93%)]\tLoss: 0.299484\n",
      "Train Epoch: 6 [6300/6700 (94%)]\tLoss: 0.066538\n",
      "Train Epoch: 6 [6400/6700 (96%)]\tLoss: 3.332226\n",
      "Train Epoch: 6 [6500/6700 (97%)]\tLoss: 0.166342\n",
      "Train Epoch: 6 [6600/6700 (99%)]\tLoss: 0.666466\n",
      "====> Epoch: 6 Average loss: 1.1996\n",
      "Train Epoch: 7 [0/6700 (0%)]\tLoss: 0.655235\n",
      "Train Epoch: 7 [100/6700 (1%)]\tLoss: 0.230495\n",
      "Train Epoch: 7 [200/6700 (3%)]\tLoss: 0.214737\n",
      "Train Epoch: 7 [300/6700 (4%)]\tLoss: 0.935422\n",
      "Train Epoch: 7 [400/6700 (6%)]\tLoss: 3.539013\n",
      "Train Epoch: 7 [500/6700 (7%)]\tLoss: 0.254811\n",
      "Train Epoch: 7 [600/6700 (9%)]\tLoss: 0.547713\n",
      "Train Epoch: 7 [700/6700 (10%)]\tLoss: 0.497614\n",
      "Train Epoch: 7 [800/6700 (12%)]\tLoss: 1.140645\n",
      "Train Epoch: 7 [900/6700 (13%)]\tLoss: 0.068430\n",
      "Train Epoch: 7 [1000/6700 (15%)]\tLoss: 1.189474\n",
      "Train Epoch: 7 [1100/6700 (16%)]\tLoss: 2.233063\n",
      "Train Epoch: 7 [1200/6700 (18%)]\tLoss: 0.081742\n",
      "Train Epoch: 7 [1300/6700 (19%)]\tLoss: 0.057278\n",
      "Train Epoch: 7 [1400/6700 (21%)]\tLoss: 0.645832\n",
      "Train Epoch: 7 [1500/6700 (22%)]\tLoss: 0.308782\n",
      "Train Epoch: 7 [1600/6700 (24%)]\tLoss: 0.929332\n",
      "Train Epoch: 7 [1700/6700 (25%)]\tLoss: 0.184586\n",
      "Train Epoch: 7 [1800/6700 (27%)]\tLoss: 0.047381\n",
      "Train Epoch: 7 [1900/6700 (28%)]\tLoss: 0.163454\n",
      "Train Epoch: 7 [2000/6700 (30%)]\tLoss: 4.124972\n",
      "Train Epoch: 7 [2100/6700 (31%)]\tLoss: 0.717073\n",
      "Train Epoch: 7 [2200/6700 (33%)]\tLoss: 1.320675\n",
      "Train Epoch: 7 [2300/6700 (34%)]\tLoss: 0.025643\n",
      "Train Epoch: 7 [2400/6700 (36%)]\tLoss: 0.852242\n",
      "Train Epoch: 7 [2500/6700 (37%)]\tLoss: 0.126521\n",
      "Train Epoch: 7 [2600/6700 (39%)]\tLoss: 0.510581\n",
      "Train Epoch: 7 [2700/6700 (40%)]\tLoss: 3.187353\n",
      "Train Epoch: 7 [2800/6700 (42%)]\tLoss: 0.927231\n",
      "Train Epoch: 7 [2900/6700 (43%)]\tLoss: 0.678244\n",
      "Train Epoch: 7 [3000/6700 (45%)]\tLoss: 1.715830\n",
      "Train Epoch: 7 [3100/6700 (46%)]\tLoss: 0.695067\n",
      "Train Epoch: 7 [3200/6700 (48%)]\tLoss: 0.088377\n",
      "Train Epoch: 7 [3300/6700 (49%)]\tLoss: 3.843818\n",
      "Train Epoch: 7 [3400/6700 (51%)]\tLoss: 0.183372\n",
      "Train Epoch: 7 [3500/6700 (52%)]\tLoss: 0.038371\n",
      "Train Epoch: 7 [3600/6700 (54%)]\tLoss: 1.242468\n",
      "Train Epoch: 7 [3700/6700 (55%)]\tLoss: 0.466533\n",
      "Train Epoch: 7 [3800/6700 (57%)]\tLoss: 0.337979\n",
      "Train Epoch: 7 [3900/6700 (58%)]\tLoss: 0.295030\n",
      "Train Epoch: 7 [4000/6700 (60%)]\tLoss: 1.155883\n",
      "Train Epoch: 7 [4100/6700 (61%)]\tLoss: 0.199305\n",
      "Train Epoch: 7 [4200/6700 (63%)]\tLoss: 0.085946\n",
      "Train Epoch: 7 [4300/6700 (64%)]\tLoss: 0.889040\n",
      "Train Epoch: 7 [4400/6700 (66%)]\tLoss: 0.097295\n",
      "Train Epoch: 7 [4500/6700 (67%)]\tLoss: 1.678268\n",
      "Train Epoch: 7 [4600/6700 (69%)]\tLoss: 2.882696\n",
      "Train Epoch: 7 [4700/6700 (70%)]\tLoss: 0.618237\n",
      "Train Epoch: 7 [4800/6700 (72%)]\tLoss: 1.954332\n",
      "Train Epoch: 7 [4900/6700 (73%)]\tLoss: 2.467110\n",
      "Train Epoch: 7 [5000/6700 (75%)]\tLoss: 3.319740\n",
      "Train Epoch: 7 [5100/6700 (76%)]\tLoss: 0.170243\n",
      "Train Epoch: 7 [5200/6700 (78%)]\tLoss: 1.122708\n",
      "Train Epoch: 7 [5300/6700 (79%)]\tLoss: 0.712270\n",
      "Train Epoch: 7 [5400/6700 (81%)]\tLoss: 0.089518\n",
      "Train Epoch: 7 [5500/6700 (82%)]\tLoss: 0.990648\n",
      "Train Epoch: 7 [5600/6700 (84%)]\tLoss: 5.214963\n",
      "Train Epoch: 7 [5700/6700 (85%)]\tLoss: 2.156175\n",
      "Train Epoch: 7 [5800/6700 (87%)]\tLoss: 1.884401\n",
      "Train Epoch: 7 [5900/6700 (88%)]\tLoss: 0.720596\n",
      "Train Epoch: 7 [6000/6700 (90%)]\tLoss: 0.755401\n",
      "Train Epoch: 7 [6100/6700 (91%)]\tLoss: 0.096565\n",
      "Train Epoch: 7 [6200/6700 (93%)]\tLoss: 0.284191\n",
      "Train Epoch: 7 [6300/6700 (94%)]\tLoss: 0.059458\n",
      "Train Epoch: 7 [6400/6700 (96%)]\tLoss: 3.138944\n",
      "Train Epoch: 7 [6500/6700 (97%)]\tLoss: 0.160234\n",
      "Train Epoch: 7 [6600/6700 (99%)]\tLoss: 0.571211\n",
      "====> Epoch: 7 Average loss: 1.1503\n",
      "Train Epoch: 8 [0/6700 (0%)]\tLoss: 0.621507\n",
      "Train Epoch: 8 [100/6700 (1%)]\tLoss: 0.217104\n",
      "Train Epoch: 8 [200/6700 (3%)]\tLoss: 0.212251\n",
      "Train Epoch: 8 [300/6700 (4%)]\tLoss: 0.830071\n",
      "Train Epoch: 8 [400/6700 (6%)]\tLoss: 3.519362\n",
      "Train Epoch: 8 [500/6700 (7%)]\tLoss: 0.234158\n",
      "Train Epoch: 8 [600/6700 (9%)]\tLoss: 0.486597\n",
      "Train Epoch: 8 [700/6700 (10%)]\tLoss: 0.458105\n",
      "Train Epoch: 8 [800/6700 (12%)]\tLoss: 1.121608\n",
      "Train Epoch: 8 [900/6700 (13%)]\tLoss: 0.065687\n",
      "Train Epoch: 8 [1000/6700 (15%)]\tLoss: 1.083988\n",
      "Train Epoch: 8 [1100/6700 (16%)]\tLoss: 2.239618\n",
      "Train Epoch: 8 [1200/6700 (18%)]\tLoss: 0.064488\n",
      "Train Epoch: 8 [1300/6700 (19%)]\tLoss: 0.050358\n",
      "Train Epoch: 8 [1400/6700 (21%)]\tLoss: 0.579975\n",
      "Train Epoch: 8 [1500/6700 (22%)]\tLoss: 0.292252\n",
      "Train Epoch: 8 [1600/6700 (24%)]\tLoss: 0.825043\n",
      "Train Epoch: 8 [1700/6700 (25%)]\tLoss: 0.174770\n",
      "Train Epoch: 8 [1800/6700 (27%)]\tLoss: 0.040493\n",
      "Train Epoch: 8 [1900/6700 (28%)]\tLoss: 0.147654\n",
      "Train Epoch: 8 [2000/6700 (30%)]\tLoss: 4.194985\n",
      "Train Epoch: 8 [2100/6700 (31%)]\tLoss: 0.684541\n",
      "Train Epoch: 8 [2200/6700 (33%)]\tLoss: 1.245857\n",
      "Train Epoch: 8 [2300/6700 (34%)]\tLoss: 0.024999\n",
      "Train Epoch: 8 [2400/6700 (36%)]\tLoss: 0.742579\n",
      "Train Epoch: 8 [2500/6700 (37%)]\tLoss: 0.118158\n",
      "Train Epoch: 8 [2600/6700 (39%)]\tLoss: 0.498658\n",
      "Train Epoch: 8 [2700/6700 (40%)]\tLoss: 3.084997\n",
      "Train Epoch: 8 [2800/6700 (42%)]\tLoss: 0.877691\n",
      "Train Epoch: 8 [2900/6700 (43%)]\tLoss: 0.569034\n",
      "Train Epoch: 8 [3000/6700 (45%)]\tLoss: 1.669800\n",
      "Train Epoch: 8 [3100/6700 (46%)]\tLoss: 0.612267\n",
      "Train Epoch: 8 [3200/6700 (48%)]\tLoss: 0.084365\n",
      "Train Epoch: 8 [3300/6700 (49%)]\tLoss: 3.779536\n",
      "Train Epoch: 8 [3400/6700 (51%)]\tLoss: 0.167724\n",
      "Train Epoch: 8 [3500/6700 (52%)]\tLoss: 0.050576\n",
      "Train Epoch: 8 [3600/6700 (54%)]\tLoss: 1.228341\n",
      "Train Epoch: 8 [3700/6700 (55%)]\tLoss: 0.436328\n",
      "Train Epoch: 8 [3800/6700 (57%)]\tLoss: 0.323407\n",
      "Train Epoch: 8 [3900/6700 (58%)]\tLoss: 0.259950\n",
      "Train Epoch: 8 [4000/6700 (60%)]\tLoss: 1.075768\n",
      "Train Epoch: 8 [4100/6700 (61%)]\tLoss: 0.194834\n",
      "Train Epoch: 8 [4200/6700 (63%)]\tLoss: 0.078146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [4300/6700 (64%)]\tLoss: 0.846640\n",
      "Train Epoch: 8 [4400/6700 (66%)]\tLoss: 0.066467\n",
      "Train Epoch: 8 [4500/6700 (67%)]\tLoss: 1.638287\n",
      "Train Epoch: 8 [4600/6700 (69%)]\tLoss: 2.904034\n",
      "Train Epoch: 8 [4700/6700 (70%)]\tLoss: 0.571833\n",
      "Train Epoch: 8 [4800/6700 (72%)]\tLoss: 1.944088\n",
      "Train Epoch: 8 [4900/6700 (73%)]\tLoss: 2.272075\n",
      "Train Epoch: 8 [5000/6700 (75%)]\tLoss: 3.230488\n",
      "Train Epoch: 8 [5100/6700 (76%)]\tLoss: 0.135769\n",
      "Train Epoch: 8 [5200/6700 (78%)]\tLoss: 1.077089\n",
      "Train Epoch: 8 [5300/6700 (79%)]\tLoss: 0.698750\n",
      "Train Epoch: 8 [5400/6700 (81%)]\tLoss: 0.096895\n",
      "Train Epoch: 8 [5500/6700 (82%)]\tLoss: 0.923131\n",
      "Train Epoch: 8 [5600/6700 (84%)]\tLoss: 5.123428\n",
      "Train Epoch: 8 [5700/6700 (85%)]\tLoss: 2.029255\n",
      "Train Epoch: 8 [5800/6700 (87%)]\tLoss: 1.791243\n",
      "Train Epoch: 8 [5900/6700 (88%)]\tLoss: 0.642229\n",
      "Train Epoch: 8 [6000/6700 (90%)]\tLoss: 0.735334\n",
      "Train Epoch: 8 [6100/6700 (91%)]\tLoss: 0.085548\n",
      "Train Epoch: 8 [6200/6700 (93%)]\tLoss: 0.269062\n",
      "Train Epoch: 8 [6300/6700 (94%)]\tLoss: 0.053506\n",
      "Train Epoch: 8 [6400/6700 (96%)]\tLoss: 2.946730\n",
      "Train Epoch: 8 [6500/6700 (97%)]\tLoss: 0.154933\n",
      "Train Epoch: 8 [6600/6700 (99%)]\tLoss: 0.498314\n",
      "====> Epoch: 8 Average loss: 1.1060\n",
      "Train Epoch: 9 [0/6700 (0%)]\tLoss: 0.590363\n",
      "Train Epoch: 9 [100/6700 (1%)]\tLoss: 0.203992\n",
      "Train Epoch: 9 [200/6700 (3%)]\tLoss: 0.210250\n",
      "Train Epoch: 9 [300/6700 (4%)]\tLoss: 0.740144\n",
      "Train Epoch: 9 [400/6700 (6%)]\tLoss: 3.486441\n",
      "Train Epoch: 9 [500/6700 (7%)]\tLoss: 0.216270\n",
      "Train Epoch: 9 [600/6700 (9%)]\tLoss: 0.432264\n",
      "Train Epoch: 9 [700/6700 (10%)]\tLoss: 0.424614\n",
      "Train Epoch: 9 [800/6700 (12%)]\tLoss: 1.101490\n",
      "Train Epoch: 9 [900/6700 (13%)]\tLoss: 0.063815\n",
      "Train Epoch: 9 [1000/6700 (15%)]\tLoss: 0.997535\n",
      "Train Epoch: 9 [1100/6700 (16%)]\tLoss: 2.152035\n",
      "Train Epoch: 9 [1200/6700 (18%)]\tLoss: 0.055523\n",
      "Train Epoch: 9 [1300/6700 (19%)]\tLoss: 0.044698\n",
      "Train Epoch: 9 [1400/6700 (21%)]\tLoss: 0.528374\n",
      "Train Epoch: 9 [1500/6700 (22%)]\tLoss: 0.275993\n",
      "Train Epoch: 9 [1600/6700 (24%)]\tLoss: 0.741355\n",
      "Train Epoch: 9 [1700/6700 (25%)]\tLoss: 0.162769\n",
      "Train Epoch: 9 [1800/6700 (27%)]\tLoss: 0.034592\n",
      "Train Epoch: 9 [1900/6700 (28%)]\tLoss: 0.136344\n",
      "Train Epoch: 9 [2000/6700 (30%)]\tLoss: 4.255645\n",
      "Train Epoch: 9 [2100/6700 (31%)]\tLoss: 0.656112\n",
      "Train Epoch: 9 [2200/6700 (33%)]\tLoss: 1.189094\n",
      "Train Epoch: 9 [2300/6700 (34%)]\tLoss: 0.025095\n",
      "Train Epoch: 9 [2400/6700 (36%)]\tLoss: 0.658913\n",
      "Train Epoch: 9 [2500/6700 (37%)]\tLoss: 0.112110\n",
      "Train Epoch: 9 [2600/6700 (39%)]\tLoss: 0.484511\n",
      "Train Epoch: 9 [2700/6700 (40%)]\tLoss: 2.997139\n",
      "Train Epoch: 9 [2800/6700 (42%)]\tLoss: 0.828065\n",
      "Train Epoch: 9 [2900/6700 (43%)]\tLoss: 0.472475\n",
      "Train Epoch: 9 [3000/6700 (45%)]\tLoss: 1.638806\n",
      "Train Epoch: 9 [3100/6700 (46%)]\tLoss: 0.544631\n",
      "Train Epoch: 9 [3200/6700 (48%)]\tLoss: 0.080766\n",
      "Train Epoch: 9 [3300/6700 (49%)]\tLoss: 3.709692\n",
      "Train Epoch: 9 [3400/6700 (51%)]\tLoss: 0.156456\n",
      "Train Epoch: 9 [3500/6700 (52%)]\tLoss: 0.071147\n",
      "Train Epoch: 9 [3600/6700 (54%)]\tLoss: 1.213544\n",
      "Train Epoch: 9 [3700/6700 (55%)]\tLoss: 0.411840\n",
      "Train Epoch: 9 [3800/6700 (57%)]\tLoss: 0.308163\n",
      "Train Epoch: 9 [3900/6700 (58%)]\tLoss: 0.232198\n",
      "Train Epoch: 9 [4000/6700 (60%)]\tLoss: 0.996332\n",
      "Train Epoch: 9 [4100/6700 (61%)]\tLoss: 0.191266\n",
      "Train Epoch: 9 [4200/6700 (63%)]\tLoss: 0.071210\n",
      "Train Epoch: 9 [4300/6700 (64%)]\tLoss: 0.803889\n",
      "Train Epoch: 9 [4400/6700 (66%)]\tLoss: 0.046018\n",
      "Train Epoch: 9 [4500/6700 (67%)]\tLoss: 1.608880\n",
      "Train Epoch: 9 [4600/6700 (69%)]\tLoss: 2.917405\n",
      "Train Epoch: 9 [4700/6700 (70%)]\tLoss: 0.528965\n",
      "Train Epoch: 9 [4800/6700 (72%)]\tLoss: 1.933609\n",
      "Train Epoch: 9 [4900/6700 (73%)]\tLoss: 2.095729\n",
      "Train Epoch: 9 [5000/6700 (75%)]\tLoss: 3.140082\n",
      "Train Epoch: 9 [5100/6700 (76%)]\tLoss: 0.111673\n",
      "Train Epoch: 9 [5200/6700 (78%)]\tLoss: 1.035388\n",
      "Train Epoch: 9 [5300/6700 (79%)]\tLoss: 0.686162\n",
      "Train Epoch: 9 [5400/6700 (81%)]\tLoss: 0.104206\n",
      "Train Epoch: 9 [5500/6700 (82%)]\tLoss: 0.852012\n",
      "Train Epoch: 9 [5600/6700 (84%)]\tLoss: 5.019945\n",
      "Train Epoch: 9 [5700/6700 (85%)]\tLoss: 1.911420\n",
      "Train Epoch: 9 [5800/6700 (87%)]\tLoss: 1.709754\n",
      "Train Epoch: 9 [5900/6700 (88%)]\tLoss: 0.576721\n",
      "Train Epoch: 9 [6000/6700 (90%)]\tLoss: 0.712969\n",
      "Train Epoch: 9 [6100/6700 (91%)]\tLoss: 0.076650\n",
      "Train Epoch: 9 [6200/6700 (93%)]\tLoss: 0.254576\n",
      "Train Epoch: 9 [6300/6700 (94%)]\tLoss: 0.048211\n",
      "Train Epoch: 9 [6400/6700 (96%)]\tLoss: 2.755136\n",
      "Train Epoch: 9 [6500/6700 (97%)]\tLoss: 0.150231\n",
      "Train Epoch: 9 [6600/6700 (99%)]\tLoss: 0.439738\n",
      "====> Epoch: 9 Average loss: 1.0658\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.706 prec@3: 0.868 prec@5: 0.919\n",
      "mprec@1: 1.938e-01 mprec@3: 3.923e-01 mprec@5: 5.231e-01\n",
      "prec matrix [0.70636364 0.8169697  0.86787879 0.90151515 0.91909091]\n",
      "mprec matrix [0.19383779 0.29895435 0.39226517 0.47736268 0.52310066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
