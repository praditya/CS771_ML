{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import predict\n",
    "import time as tm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.datasets import make_classification\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Data\n",
    "dictSize = 225\n",
    "(X, y) = utils.loadData( \"train\", dictSize = dictSize )\n",
    "X = scipy.sparse.csr_matrix.toarray(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/multi-class-classification/47565\n",
    "# https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            outp = self.forward(x)\n",
    "            return F.softmax(outp)\n",
    "# add softmax layer: used for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model declared\n",
    "model = NeuralNet(225 , 1000, 51)  \n",
    "# earlier hidden layers- 1000 \n",
    "# 1 - poor, 2- ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "model_opt = optim.SGD(model.parameters(), lr = 0.02)\n",
    "\n",
    "train_set_X = Variable(torch.from_numpy(X_train)).float()\n",
    "train_set_y = Variable(torch.LongTensor(y_train)).long()\n",
    "test_set_X = Variable(torch.from_numpy(X_test)).float()\n",
    "test_set_y = Variable(torch.LongTensor(y_test)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "epochs = 50\n",
    "for epochs in range(epochs):\n",
    "    model_opt.zero_grad()\n",
    "    out = model(train_set_X)\n",
    "    loss = loss_function(out, train_set_y)\n",
    "    loss.backward()\n",
    "    model_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "# for i in range(3299):\n",
    "#     ans_max,ind = torch.max(ans[i],0)\n",
    "#     print (test_set_y[i].numpy() - ind.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 4 1 7]\n",
      " [2 1 3 4 9]\n",
      " [2 3 1 4 7]\n",
      " ...\n",
      " [2 1 3 4 9]\n",
      " [2 1 4 3 9]\n",
      " [2 3 1 4 7]]\n",
      "[3. 2. 3. ... 9. 4. 3.]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "print (y_pred)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.314 prec@3: 0.624 prec@5: 0.755\n",
      "mprec@1: 2.944e-02 mprec@3: 7.486e-02 mprec@5: 1.340e-01\n",
      "prec matrix [0.31363636 0.49878788 0.62363636 0.69363636 0.75515152]\n",
      "mprec matrix [0.02943633 0.05661567 0.07486278 0.08510638 0.13399919]\n"
     ]
    }
   ],
   "source": [
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 \n",
    "# same model diff train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_latent_X = data_utils.TensorDataset(train_set_X, train_set_y)\n",
    "te_latent_X = data_utils.TensorDataset(test_set_X,  test_set_y)\n",
    "train_loader_X = torch.utils.data.DataLoader(dataset=tr_latent_X)\n",
    "test_loader_X = torch.utils.data.DataLoader(dataset=te_latent_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data,label) in enumerate(train_loader_X):\n",
    "\n",
    "        model_opt.zero_grad()\n",
    "\n",
    "        out = model(data)\n",
    "        loss = loss_function(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        model_opt.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_X.dataset),\n",
    "                100. * batch_idx / len(train_loader_X), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader_X.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6700 (0%)]\tLoss: 2.895860\n",
      "Train Epoch: 1 [100/6700 (1%)]\tLoss: 2.147893\n",
      "Train Epoch: 1 [200/6700 (3%)]\tLoss: 0.775469\n",
      "Train Epoch: 1 [300/6700 (4%)]\tLoss: 4.259040\n",
      "Train Epoch: 1 [400/6700 (6%)]\tLoss: 3.802916\n",
      "Train Epoch: 1 [500/6700 (7%)]\tLoss: 1.437111\n",
      "Train Epoch: 1 [600/6700 (9%)]\tLoss: 1.776183\n",
      "Train Epoch: 1 [700/6700 (10%)]\tLoss: 0.854372\n",
      "Train Epoch: 1 [800/6700 (12%)]\tLoss: 2.214782\n",
      "Train Epoch: 1 [900/6700 (13%)]\tLoss: 0.539796\n",
      "Train Epoch: 1 [1000/6700 (15%)]\tLoss: 2.787828\n",
      "Train Epoch: 1 [1100/6700 (16%)]\tLoss: 0.022516\n",
      "Train Epoch: 1 [1200/6700 (18%)]\tLoss: 7.694416\n",
      "Train Epoch: 1 [1300/6700 (19%)]\tLoss: 0.167059\n",
      "Train Epoch: 1 [1400/6700 (21%)]\tLoss: 1.684062\n",
      "Train Epoch: 1 [1500/6700 (22%)]\tLoss: 0.702131\n",
      "Train Epoch: 1 [1600/6700 (24%)]\tLoss: 1.926263\n",
      "Train Epoch: 1 [1700/6700 (25%)]\tLoss: 0.049595\n",
      "Train Epoch: 1 [1800/6700 (27%)]\tLoss: 0.755877\n",
      "Train Epoch: 1 [1900/6700 (28%)]\tLoss: 1.157644\n",
      "Train Epoch: 1 [2000/6700 (30%)]\tLoss: 4.557193\n",
      "Train Epoch: 1 [2100/6700 (31%)]\tLoss: 0.874256\n",
      "Train Epoch: 1 [2200/6700 (33%)]\tLoss: 1.751944\n",
      "Train Epoch: 1 [2300/6700 (34%)]\tLoss: 0.078205\n",
      "Train Epoch: 1 [2400/6700 (36%)]\tLoss: 1.602966\n",
      "Train Epoch: 1 [2500/6700 (37%)]\tLoss: 0.096401\n",
      "Train Epoch: 1 [2600/6700 (39%)]\tLoss: 1.297558\n",
      "Train Epoch: 1 [2700/6700 (40%)]\tLoss: 5.047125\n",
      "Train Epoch: 1 [2800/6700 (42%)]\tLoss: 1.184317\n",
      "Train Epoch: 1 [2900/6700 (43%)]\tLoss: 0.826107\n",
      "Train Epoch: 1 [3000/6700 (45%)]\tLoss: 1.149251\n",
      "Train Epoch: 1 [3100/6700 (46%)]\tLoss: 1.310625\n",
      "Train Epoch: 1 [3200/6700 (48%)]\tLoss: 0.173652\n",
      "Train Epoch: 1 [3300/6700 (49%)]\tLoss: 3.957499\n",
      "Train Epoch: 1 [3400/6700 (51%)]\tLoss: 0.157926\n",
      "Train Epoch: 1 [3500/6700 (52%)]\tLoss: 0.903040\n",
      "Train Epoch: 1 [3600/6700 (54%)]\tLoss: 1.921303\n",
      "Train Epoch: 1 [3700/6700 (55%)]\tLoss: 0.525944\n",
      "Train Epoch: 1 [3800/6700 (57%)]\tLoss: 0.453394\n",
      "Train Epoch: 1 [3900/6700 (58%)]\tLoss: 0.359042\n",
      "Train Epoch: 1 [4000/6700 (60%)]\tLoss: 6.504522\n",
      "Train Epoch: 1 [4100/6700 (61%)]\tLoss: 0.200966\n",
      "Train Epoch: 1 [4200/6700 (63%)]\tLoss: 0.035623\n",
      "Train Epoch: 1 [4300/6700 (64%)]\tLoss: 1.061505\n",
      "Train Epoch: 1 [4400/6700 (66%)]\tLoss: 0.726149\n",
      "Train Epoch: 1 [4500/6700 (67%)]\tLoss: 1.912193\n",
      "Train Epoch: 1 [4600/6700 (69%)]\tLoss: 2.974767\n",
      "Train Epoch: 1 [4700/6700 (70%)]\tLoss: 0.727829\n",
      "Train Epoch: 1 [4800/6700 (72%)]\tLoss: 1.957394\n",
      "Train Epoch: 1 [4900/6700 (73%)]\tLoss: 3.538319\n",
      "Train Epoch: 1 [5000/6700 (75%)]\tLoss: 3.342629\n",
      "Train Epoch: 1 [5100/6700 (76%)]\tLoss: 0.812330\n",
      "Train Epoch: 1 [5200/6700 (78%)]\tLoss: 1.845411\n",
      "Train Epoch: 1 [5300/6700 (79%)]\tLoss: 0.865807\n",
      "Train Epoch: 1 [5400/6700 (81%)]\tLoss: 0.132884\n",
      "Train Epoch: 1 [5500/6700 (82%)]\tLoss: 4.155717\n",
      "Train Epoch: 1 [5600/6700 (84%)]\tLoss: 6.161463\n",
      "Train Epoch: 1 [5700/6700 (85%)]\tLoss: 3.073822\n",
      "Train Epoch: 1 [5800/6700 (87%)]\tLoss: 2.060724\n",
      "Train Epoch: 1 [5900/6700 (88%)]\tLoss: 0.714117\n",
      "Train Epoch: 1 [6000/6700 (90%)]\tLoss: 0.524457\n",
      "Train Epoch: 1 [6100/6700 (91%)]\tLoss: 0.070376\n",
      "Train Epoch: 1 [6200/6700 (93%)]\tLoss: 0.384317\n",
      "Train Epoch: 1 [6300/6700 (94%)]\tLoss: 0.091940\n",
      "Train Epoch: 1 [6400/6700 (96%)]\tLoss: 2.589685\n",
      "Train Epoch: 1 [6500/6700 (97%)]\tLoss: 0.242819\n",
      "Train Epoch: 1 [6600/6700 (99%)]\tLoss: 0.360949\n",
      "====> Epoch: 1 Average loss: 1.6506\n",
      "Train Epoch: 2 [0/6700 (0%)]\tLoss: 0.645476\n",
      "Train Epoch: 2 [100/6700 (1%)]\tLoss: 0.152541\n",
      "Train Epoch: 2 [200/6700 (3%)]\tLoss: 0.177874\n",
      "Train Epoch: 2 [300/6700 (4%)]\tLoss: 0.696853\n",
      "Train Epoch: 2 [400/6700 (6%)]\tLoss: 3.718613\n",
      "Train Epoch: 2 [500/6700 (7%)]\tLoss: 0.174627\n",
      "Train Epoch: 2 [600/6700 (9%)]\tLoss: 0.983176\n",
      "Train Epoch: 2 [700/6700 (10%)]\tLoss: 0.549557\n",
      "Train Epoch: 2 [800/6700 (12%)]\tLoss: 1.501505\n",
      "Train Epoch: 2 [900/6700 (13%)]\tLoss: 0.070637\n",
      "Train Epoch: 2 [1000/6700 (15%)]\tLoss: 1.641090\n",
      "Train Epoch: 2 [1100/6700 (16%)]\tLoss: 2.622354\n",
      "Train Epoch: 2 [1200/6700 (18%)]\tLoss: 5.794456\n",
      "Train Epoch: 2 [1300/6700 (19%)]\tLoss: 0.051403\n",
      "Train Epoch: 2 [1400/6700 (21%)]\tLoss: 0.124386\n",
      "Train Epoch: 2 [1500/6700 (22%)]\tLoss: 0.227391\n",
      "Train Epoch: 2 [1600/6700 (24%)]\tLoss: 1.147489\n",
      "Train Epoch: 2 [1700/6700 (25%)]\tLoss: 0.025740\n",
      "Train Epoch: 2 [1800/6700 (27%)]\tLoss: 0.770172\n",
      "Train Epoch: 2 [1900/6700 (28%)]\tLoss: 1.108945\n",
      "Train Epoch: 2 [2000/6700 (30%)]\tLoss: 5.876327\n",
      "Train Epoch: 2 [2100/6700 (31%)]\tLoss: 0.373742\n",
      "Train Epoch: 2 [2200/6700 (33%)]\tLoss: 1.354240\n",
      "Train Epoch: 2 [2300/6700 (34%)]\tLoss: 0.050596\n",
      "Train Epoch: 2 [2400/6700 (36%)]\tLoss: 0.171073\n",
      "Train Epoch: 2 [2500/6700 (37%)]\tLoss: 0.044213\n",
      "Train Epoch: 2 [2600/6700 (39%)]\tLoss: 0.838583\n",
      "Train Epoch: 2 [2700/6700 (40%)]\tLoss: 2.747556\n",
      "Train Epoch: 2 [2800/6700 (42%)]\tLoss: 0.415020\n",
      "Train Epoch: 2 [2900/6700 (43%)]\tLoss: 0.053813\n",
      "Train Epoch: 2 [3000/6700 (45%)]\tLoss: 0.620950\n",
      "Train Epoch: 2 [3100/6700 (46%)]\tLoss: 0.708546\n",
      "Train Epoch: 2 [3200/6700 (48%)]\tLoss: 0.110147\n",
      "Train Epoch: 2 [3300/6700 (49%)]\tLoss: 3.173510\n",
      "Train Epoch: 2 [3400/6700 (51%)]\tLoss: 0.029486\n",
      "Train Epoch: 2 [3500/6700 (52%)]\tLoss: 0.025431\n",
      "Train Epoch: 2 [3600/6700 (54%)]\tLoss: 1.370930\n",
      "Train Epoch: 2 [3700/6700 (55%)]\tLoss: 0.161701\n",
      "Train Epoch: 2 [3800/6700 (57%)]\tLoss: 0.134090\n",
      "Train Epoch: 2 [3900/6700 (58%)]\tLoss: 0.058585\n",
      "Train Epoch: 2 [4000/6700 (60%)]\tLoss: 6.642554\n",
      "Train Epoch: 2 [4100/6700 (61%)]\tLoss: 0.153666\n",
      "Train Epoch: 2 [4200/6700 (63%)]\tLoss: 0.017634\n",
      "Train Epoch: 2 [4300/6700 (64%)]\tLoss: 1.009863\n",
      "Train Epoch: 2 [4400/6700 (66%)]\tLoss: 0.014052\n",
      "Train Epoch: 2 [4500/6700 (67%)]\tLoss: 2.023932\n",
      "Train Epoch: 2 [4600/6700 (69%)]\tLoss: 2.632453\n",
      "Train Epoch: 2 [4700/6700 (70%)]\tLoss: 0.309989\n",
      "Train Epoch: 2 [4800/6700 (72%)]\tLoss: 1.977530\n",
      "Train Epoch: 2 [4900/6700 (73%)]\tLoss: 1.379002\n",
      "Train Epoch: 2 [5000/6700 (75%)]\tLoss: 2.724860\n",
      "Train Epoch: 2 [5100/6700 (76%)]\tLoss: 0.269745\n",
      "Train Epoch: 2 [5200/6700 (78%)]\tLoss: 1.725191\n",
      "Train Epoch: 2 [5300/6700 (79%)]\tLoss: 0.592078\n",
      "Train Epoch: 2 [5400/6700 (81%)]\tLoss: 0.100268\n",
      "Train Epoch: 2 [5500/6700 (82%)]\tLoss: 2.658681\n",
      "Train Epoch: 2 [5600/6700 (84%)]\tLoss: 4.726761\n",
      "Train Epoch: 2 [5700/6700 (85%)]\tLoss: 2.604758\n",
      "Train Epoch: 2 [5800/6700 (87%)]\tLoss: 1.661640\n",
      "Train Epoch: 2 [5900/6700 (88%)]\tLoss: 0.226076\n",
      "Train Epoch: 2 [6000/6700 (90%)]\tLoss: 0.478271\n",
      "Train Epoch: 2 [6100/6700 (91%)]\tLoss: 0.017145\n",
      "Train Epoch: 2 [6200/6700 (93%)]\tLoss: 0.152615\n",
      "Train Epoch: 2 [6300/6700 (94%)]\tLoss: 0.041163\n",
      "Train Epoch: 2 [6400/6700 (96%)]\tLoss: 0.592416\n",
      "Train Epoch: 2 [6500/6700 (97%)]\tLoss: 0.145057\n",
      "Train Epoch: 2 [6600/6700 (99%)]\tLoss: 0.073893\n",
      "====> Epoch: 2 Average loss: 1.1143\n",
      "Train Epoch: 3 [0/6700 (0%)]\tLoss: 0.285886\n",
      "Train Epoch: 3 [100/6700 (1%)]\tLoss: 0.068072\n",
      "Train Epoch: 3 [200/6700 (3%)]\tLoss: 0.122815\n",
      "Train Epoch: 3 [300/6700 (4%)]\tLoss: 0.400373\n",
      "Train Epoch: 3 [400/6700 (6%)]\tLoss: 3.664876\n",
      "Train Epoch: 3 [500/6700 (7%)]\tLoss: 0.118068\n",
      "Train Epoch: 3 [600/6700 (9%)]\tLoss: 0.543719\n",
      "Train Epoch: 3 [700/6700 (10%)]\tLoss: 0.481399\n",
      "Train Epoch: 3 [800/6700 (12%)]\tLoss: 1.477552\n",
      "Train Epoch: 3 [900/6700 (13%)]\tLoss: 0.054200\n",
      "Train Epoch: 3 [1000/6700 (15%)]\tLoss: 2.063396\n",
      "Train Epoch: 3 [1100/6700 (16%)]\tLoss: 0.038954\n",
      "Train Epoch: 3 [1200/6700 (18%)]\tLoss: 3.810589\n",
      "Train Epoch: 3 [1300/6700 (19%)]\tLoss: 0.033848\n",
      "Train Epoch: 3 [1400/6700 (21%)]\tLoss: 0.034283\n",
      "Train Epoch: 3 [1500/6700 (22%)]\tLoss: 0.175108\n",
      "Train Epoch: 3 [1600/6700 (24%)]\tLoss: 0.235004\n",
      "Train Epoch: 3 [1700/6700 (25%)]\tLoss: 0.009449\n",
      "Train Epoch: 3 [1800/6700 (27%)]\tLoss: 0.151266\n",
      "Train Epoch: 3 [1900/6700 (28%)]\tLoss: 1.051881\n",
      "Train Epoch: 3 [2000/6700 (30%)]\tLoss: 5.806187\n",
      "Train Epoch: 3 [2100/6700 (31%)]\tLoss: 0.128256\n",
      "Train Epoch: 3 [2200/6700 (33%)]\tLoss: 1.252764\n",
      "Train Epoch: 3 [2300/6700 (34%)]\tLoss: 0.038253\n",
      "Train Epoch: 3 [2400/6700 (36%)]\tLoss: 0.072677\n",
      "Train Epoch: 3 [2500/6700 (37%)]\tLoss: 0.048492\n",
      "Train Epoch: 3 [2600/6700 (39%)]\tLoss: 0.770170\n",
      "Train Epoch: 3 [2700/6700 (40%)]\tLoss: 1.866445\n",
      "Train Epoch: 3 [2800/6700 (42%)]\tLoss: 0.137653\n",
      "Train Epoch: 3 [2900/6700 (43%)]\tLoss: 0.005867\n",
      "Train Epoch: 3 [3000/6700 (45%)]\tLoss: 0.490961\n",
      "Train Epoch: 3 [3100/6700 (46%)]\tLoss: 0.267090\n",
      "Train Epoch: 3 [3200/6700 (48%)]\tLoss: 0.124201\n",
      "Train Epoch: 3 [3300/6700 (49%)]\tLoss: 2.682988\n",
      "Train Epoch: 3 [3400/6700 (51%)]\tLoss: 0.030297\n",
      "Train Epoch: 3 [3500/6700 (52%)]\tLoss: 0.000486\n",
      "Train Epoch: 3 [3600/6700 (54%)]\tLoss: 1.864916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [3700/6700 (55%)]\tLoss: 0.093891\n",
      "Train Epoch: 3 [3800/6700 (57%)]\tLoss: 0.056728\n",
      "Train Epoch: 3 [3900/6700 (58%)]\tLoss: 0.032450\n",
      "Train Epoch: 3 [4000/6700 (60%)]\tLoss: 2.632067\n",
      "Train Epoch: 3 [4100/6700 (61%)]\tLoss: 0.240265\n",
      "Train Epoch: 3 [4200/6700 (63%)]\tLoss: 0.009124\n",
      "Train Epoch: 3 [4300/6700 (64%)]\tLoss: 1.147588\n",
      "Train Epoch: 3 [4400/6700 (66%)]\tLoss: 0.001979\n",
      "Train Epoch: 3 [4500/6700 (67%)]\tLoss: 1.951003\n",
      "Train Epoch: 3 [4600/6700 (69%)]\tLoss: 2.078163\n",
      "Train Epoch: 3 [4700/6700 (70%)]\tLoss: 0.197971\n",
      "Train Epoch: 3 [4800/6700 (72%)]\tLoss: 2.389737\n",
      "Train Epoch: 3 [4900/6700 (73%)]\tLoss: 0.310630\n",
      "Train Epoch: 3 [5000/6700 (75%)]\tLoss: 1.668003\n",
      "Train Epoch: 3 [5100/6700 (76%)]\tLoss: 0.100045\n",
      "Train Epoch: 3 [5200/6700 (78%)]\tLoss: 1.417741\n",
      "Train Epoch: 3 [5300/6700 (79%)]\tLoss: 0.544871\n",
      "Train Epoch: 3 [5400/6700 (81%)]\tLoss: 0.141199\n",
      "Train Epoch: 3 [5500/6700 (82%)]\tLoss: 2.359682\n",
      "Train Epoch: 3 [5600/6700 (84%)]\tLoss: 2.878024\n",
      "Train Epoch: 3 [5700/6700 (85%)]\tLoss: 2.406954\n",
      "Train Epoch: 3 [5800/6700 (87%)]\tLoss: 1.464425\n",
      "Train Epoch: 3 [5900/6700 (88%)]\tLoss: 0.114727\n",
      "Train Epoch: 3 [6000/6700 (90%)]\tLoss: 0.398057\n",
      "Train Epoch: 3 [6100/6700 (91%)]\tLoss: 0.006665\n",
      "Train Epoch: 3 [6200/6700 (93%)]\tLoss: 0.075447\n",
      "Train Epoch: 3 [6300/6700 (94%)]\tLoss: 0.018642\n",
      "Train Epoch: 3 [6400/6700 (96%)]\tLoss: 0.170160\n",
      "Train Epoch: 3 [6500/6700 (97%)]\tLoss: 0.104063\n",
      "Train Epoch: 3 [6600/6700 (99%)]\tLoss: 0.031501\n",
      "====> Epoch: 3 Average loss: 0.9125\n",
      "Train Epoch: 4 [0/6700 (0%)]\tLoss: 0.183389\n",
      "Train Epoch: 4 [100/6700 (1%)]\tLoss: 0.035132\n",
      "Train Epoch: 4 [200/6700 (3%)]\tLoss: 0.100039\n",
      "Train Epoch: 4 [300/6700 (4%)]\tLoss: 0.198566\n",
      "Train Epoch: 4 [400/6700 (6%)]\tLoss: 4.039320\n",
      "Train Epoch: 4 [500/6700 (7%)]\tLoss: 0.113426\n",
      "Train Epoch: 4 [600/6700 (9%)]\tLoss: 0.321830\n",
      "Train Epoch: 4 [700/6700 (10%)]\tLoss: 0.448950\n",
      "Train Epoch: 4 [800/6700 (12%)]\tLoss: 1.170111\n",
      "Train Epoch: 4 [900/6700 (13%)]\tLoss: 0.053068\n",
      "Train Epoch: 4 [1000/6700 (15%)]\tLoss: 1.286985\n",
      "Train Epoch: 4 [1100/6700 (16%)]\tLoss: 1.512944\n",
      "Train Epoch: 4 [1200/6700 (18%)]\tLoss: 0.895692\n",
      "Train Epoch: 4 [1300/6700 (19%)]\tLoss: 0.015786\n",
      "Train Epoch: 4 [1400/6700 (21%)]\tLoss: 0.025457\n",
      "Train Epoch: 4 [1500/6700 (22%)]\tLoss: 0.174097\n",
      "Train Epoch: 4 [1600/6700 (24%)]\tLoss: 0.201620\n",
      "Train Epoch: 4 [1700/6700 (25%)]\tLoss: 0.001981\n",
      "Train Epoch: 4 [1800/6700 (27%)]\tLoss: 0.520645\n",
      "Train Epoch: 4 [1900/6700 (28%)]\tLoss: 0.826800\n",
      "Train Epoch: 4 [2000/6700 (30%)]\tLoss: 6.238355\n",
      "Train Epoch: 4 [2100/6700 (31%)]\tLoss: 0.073362\n",
      "Train Epoch: 4 [2200/6700 (33%)]\tLoss: 0.824729\n",
      "Train Epoch: 4 [2300/6700 (34%)]\tLoss: 0.021875\n",
      "Train Epoch: 4 [2400/6700 (36%)]\tLoss: 0.068553\n",
      "Train Epoch: 4 [2500/6700 (37%)]\tLoss: 0.045778\n",
      "Train Epoch: 4 [2600/6700 (39%)]\tLoss: 0.378160\n",
      "Train Epoch: 4 [2700/6700 (40%)]\tLoss: 1.119591\n",
      "Train Epoch: 4 [2800/6700 (42%)]\tLoss: 0.086348\n",
      "Train Epoch: 4 [2900/6700 (43%)]\tLoss: 0.001745\n",
      "Train Epoch: 4 [3000/6700 (45%)]\tLoss: 0.540208\n",
      "Train Epoch: 4 [3100/6700 (46%)]\tLoss: 0.174106\n",
      "Train Epoch: 4 [3200/6700 (48%)]\tLoss: 0.117238\n",
      "Train Epoch: 4 [3300/6700 (49%)]\tLoss: 2.758280\n",
      "Train Epoch: 4 [3400/6700 (51%)]\tLoss: 0.031631\n",
      "Train Epoch: 4 [3500/6700 (52%)]\tLoss: 1.480083\n",
      "Train Epoch: 4 [3600/6700 (54%)]\tLoss: 2.248147\n",
      "Train Epoch: 4 [3700/6700 (55%)]\tLoss: 0.093749\n",
      "Train Epoch: 4 [3800/6700 (57%)]\tLoss: 0.046078\n",
      "Train Epoch: 4 [3900/6700 (58%)]\tLoss: 0.018026\n",
      "Train Epoch: 4 [4000/6700 (60%)]\tLoss: 3.054267\n",
      "Train Epoch: 4 [4100/6700 (61%)]\tLoss: 0.416953\n",
      "Train Epoch: 4 [4200/6700 (63%)]\tLoss: 0.006361\n",
      "Train Epoch: 4 [4300/6700 (64%)]\tLoss: 1.399461\n",
      "Train Epoch: 4 [4400/6700 (66%)]\tLoss: 0.001262\n",
      "Train Epoch: 4 [4500/6700 (67%)]\tLoss: 1.583965\n",
      "Train Epoch: 4 [4600/6700 (69%)]\tLoss: 1.471850\n",
      "Train Epoch: 4 [4700/6700 (70%)]\tLoss: 0.192162\n",
      "Train Epoch: 4 [4800/6700 (72%)]\tLoss: 2.665370\n",
      "Train Epoch: 4 [4900/6700 (73%)]\tLoss: 0.131768\n",
      "Train Epoch: 4 [5000/6700 (75%)]\tLoss: 1.375010\n",
      "Train Epoch: 4 [5100/6700 (76%)]\tLoss: 0.061717\n",
      "Train Epoch: 4 [5200/6700 (78%)]\tLoss: 0.872833\n",
      "Train Epoch: 4 [5300/6700 (79%)]\tLoss: 0.436195\n",
      "Train Epoch: 4 [5400/6700 (81%)]\tLoss: 0.146312\n",
      "Train Epoch: 4 [5500/6700 (82%)]\tLoss: 1.321696\n",
      "Train Epoch: 4 [5600/6700 (84%)]\tLoss: 2.604700\n",
      "Train Epoch: 4 [5700/6700 (85%)]\tLoss: 2.468684\n",
      "Train Epoch: 4 [5800/6700 (87%)]\tLoss: 1.443168\n",
      "Train Epoch: 4 [5900/6700 (88%)]\tLoss: 0.148664\n",
      "Train Epoch: 4 [6000/6700 (90%)]\tLoss: 0.206686\n",
      "Train Epoch: 4 [6100/6700 (91%)]\tLoss: 0.003464\n",
      "Train Epoch: 4 [6200/6700 (93%)]\tLoss: 0.033849\n",
      "Train Epoch: 4 [6300/6700 (94%)]\tLoss: 0.023790\n",
      "Train Epoch: 4 [6400/6700 (96%)]\tLoss: 0.072352\n",
      "Train Epoch: 4 [6500/6700 (97%)]\tLoss: 0.132565\n",
      "Train Epoch: 4 [6600/6700 (99%)]\tLoss: 0.027889\n",
      "====> Epoch: 4 Average loss: 0.7976\n",
      "Train Epoch: 5 [0/6700 (0%)]\tLoss: 0.229162\n",
      "Train Epoch: 5 [100/6700 (1%)]\tLoss: 0.028325\n",
      "Train Epoch: 5 [200/6700 (3%)]\tLoss: 0.118867\n",
      "Train Epoch: 5 [300/6700 (4%)]\tLoss: 0.196804\n",
      "Train Epoch: 5 [400/6700 (6%)]\tLoss: 3.698696\n",
      "Train Epoch: 5 [500/6700 (7%)]\tLoss: 0.197908\n",
      "Train Epoch: 5 [600/6700 (9%)]\tLoss: 0.153961\n",
      "Train Epoch: 5 [700/6700 (10%)]\tLoss: 0.545195\n",
      "Train Epoch: 5 [800/6700 (12%)]\tLoss: 1.162963\n",
      "Train Epoch: 5 [900/6700 (13%)]\tLoss: 0.088152\n",
      "Train Epoch: 5 [1000/6700 (15%)]\tLoss: 1.444929\n",
      "Train Epoch: 5 [1100/6700 (16%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [1200/6700 (18%)]\tLoss: 2.556828\n",
      "Train Epoch: 5 [1300/6700 (19%)]\tLoss: 0.018509\n",
      "Train Epoch: 5 [1400/6700 (21%)]\tLoss: 0.016731\n",
      "Train Epoch: 5 [1500/6700 (22%)]\tLoss: 0.121529\n",
      "Train Epoch: 5 [1600/6700 (24%)]\tLoss: 0.001151\n",
      "Train Epoch: 5 [1700/6700 (25%)]\tLoss: 0.002353\n",
      "Train Epoch: 5 [1800/6700 (27%)]\tLoss: 0.243750\n",
      "Train Epoch: 5 [1900/6700 (28%)]\tLoss: 0.725983\n",
      "Train Epoch: 5 [2000/6700 (30%)]\tLoss: 6.249377\n",
      "Train Epoch: 5 [2100/6700 (31%)]\tLoss: 0.040786\n",
      "Train Epoch: 5 [2200/6700 (33%)]\tLoss: 0.801594\n",
      "Train Epoch: 5 [2300/6700 (34%)]\tLoss: 0.005747\n",
      "Train Epoch: 5 [2400/6700 (36%)]\tLoss: 0.055434\n",
      "Train Epoch: 5 [2500/6700 (37%)]\tLoss: 0.051850\n",
      "Train Epoch: 5 [2600/6700 (39%)]\tLoss: 0.401139\n",
      "Train Epoch: 5 [2700/6700 (40%)]\tLoss: 0.674777\n",
      "Train Epoch: 5 [2800/6700 (42%)]\tLoss: 0.080591\n",
      "Train Epoch: 5 [2900/6700 (43%)]\tLoss: 0.000820\n",
      "Train Epoch: 5 [3000/6700 (45%)]\tLoss: 0.582374\n",
      "Train Epoch: 5 [3100/6700 (46%)]\tLoss: 0.087262\n",
      "Train Epoch: 5 [3200/6700 (48%)]\tLoss: 0.115695\n",
      "Train Epoch: 5 [3300/6700 (49%)]\tLoss: 2.475127\n",
      "Train Epoch: 5 [3400/6700 (51%)]\tLoss: 0.027011\n",
      "Train Epoch: 5 [3500/6700 (52%)]\tLoss: 1.305477\n",
      "Train Epoch: 5 [3600/6700 (54%)]\tLoss: 2.821061\n",
      "Train Epoch: 5 [3700/6700 (55%)]\tLoss: 0.090478\n",
      "Train Epoch: 5 [3800/6700 (57%)]\tLoss: 0.033867\n",
      "Train Epoch: 5 [3900/6700 (58%)]\tLoss: 0.010077\n",
      "Train Epoch: 5 [4000/6700 (60%)]\tLoss: 1.354590\n",
      "Train Epoch: 5 [4100/6700 (61%)]\tLoss: 0.450619\n",
      "Train Epoch: 5 [4200/6700 (63%)]\tLoss: 0.002182\n",
      "Train Epoch: 5 [4300/6700 (64%)]\tLoss: 1.028710\n",
      "Train Epoch: 5 [4400/6700 (66%)]\tLoss: 0.001979\n",
      "Train Epoch: 5 [4500/6700 (67%)]\tLoss: 1.132978\n",
      "Train Epoch: 5 [4600/6700 (69%)]\tLoss: 1.089215\n",
      "Train Epoch: 5 [4700/6700 (70%)]\tLoss: 0.100623\n",
      "Train Epoch: 5 [4800/6700 (72%)]\tLoss: 3.214579\n",
      "Train Epoch: 5 [4900/6700 (73%)]\tLoss: 0.049318\n",
      "Train Epoch: 5 [5000/6700 (75%)]\tLoss: 0.932001\n",
      "Train Epoch: 5 [5100/6700 (76%)]\tLoss: 0.056974\n",
      "Train Epoch: 5 [5200/6700 (78%)]\tLoss: 0.655351\n",
      "Train Epoch: 5 [5300/6700 (79%)]\tLoss: 0.425308\n",
      "Train Epoch: 5 [5400/6700 (81%)]\tLoss: 0.172943\n",
      "Train Epoch: 5 [5500/6700 (82%)]\tLoss: 1.085511\n",
      "Train Epoch: 5 [5600/6700 (84%)]\tLoss: 1.719280\n",
      "Train Epoch: 5 [5700/6700 (85%)]\tLoss: 2.482799\n",
      "Train Epoch: 5 [5800/6700 (87%)]\tLoss: 1.441697\n",
      "Train Epoch: 5 [5900/6700 (88%)]\tLoss: 0.115362\n",
      "Train Epoch: 5 [6000/6700 (90%)]\tLoss: 0.415833\n",
      "Train Epoch: 5 [6100/6700 (91%)]\tLoss: 0.000970\n",
      "Train Epoch: 5 [6200/6700 (93%)]\tLoss: 0.036950\n",
      "Train Epoch: 5 [6300/6700 (94%)]\tLoss: 0.023440\n",
      "Train Epoch: 5 [6400/6700 (96%)]\tLoss: 0.076049\n",
      "Train Epoch: 5 [6500/6700 (97%)]\tLoss: 0.136080\n",
      "Train Epoch: 5 [6600/6700 (99%)]\tLoss: 0.015578\n",
      "====> Epoch: 5 Average loss: 0.7064\n",
      "Train Epoch: 6 [0/6700 (0%)]\tLoss: 0.287996\n",
      "Train Epoch: 6 [100/6700 (1%)]\tLoss: 0.019832\n",
      "Train Epoch: 6 [200/6700 (3%)]\tLoss: 0.125524\n",
      "Train Epoch: 6 [300/6700 (4%)]\tLoss: 0.065093\n",
      "Train Epoch: 6 [400/6700 (6%)]\tLoss: 3.477044\n",
      "Train Epoch: 6 [500/6700 (7%)]\tLoss: 0.161343\n",
      "Train Epoch: 6 [600/6700 (9%)]\tLoss: 0.088292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [700/6700 (10%)]\tLoss: 0.413284\n",
      "Train Epoch: 6 [800/6700 (12%)]\tLoss: 0.959520\n",
      "Train Epoch: 6 [900/6700 (13%)]\tLoss: 0.073325\n",
      "Train Epoch: 6 [1000/6700 (15%)]\tLoss: 1.739574\n",
      "Train Epoch: 6 [1100/6700 (16%)]\tLoss: 0.000003\n",
      "Train Epoch: 6 [1200/6700 (18%)]\tLoss: 3.785931\n",
      "Train Epoch: 6 [1300/6700 (19%)]\tLoss: 0.011897\n",
      "Train Epoch: 6 [1400/6700 (21%)]\tLoss: 0.020853\n",
      "Train Epoch: 6 [1500/6700 (22%)]\tLoss: 0.159387\n",
      "Train Epoch: 6 [1600/6700 (24%)]\tLoss: 0.011934\n",
      "Train Epoch: 6 [1700/6700 (25%)]\tLoss: 0.001540\n",
      "Train Epoch: 6 [1800/6700 (27%)]\tLoss: 0.034458\n",
      "Train Epoch: 6 [1900/6700 (28%)]\tLoss: 0.427896\n",
      "Train Epoch: 6 [2000/6700 (30%)]\tLoss: 6.960698\n",
      "Train Epoch: 6 [2100/6700 (31%)]\tLoss: 0.025643\n",
      "Train Epoch: 6 [2200/6700 (33%)]\tLoss: 0.666192\n",
      "Train Epoch: 6 [2300/6700 (34%)]\tLoss: 0.007638\n",
      "Train Epoch: 6 [2400/6700 (36%)]\tLoss: 0.067081\n",
      "Train Epoch: 6 [2500/6700 (37%)]\tLoss: 0.044136\n",
      "Train Epoch: 6 [2600/6700 (39%)]\tLoss: 0.244827\n",
      "Train Epoch: 6 [2700/6700 (40%)]\tLoss: 0.480928\n",
      "Train Epoch: 6 [2800/6700 (42%)]\tLoss: 0.071065\n",
      "Train Epoch: 6 [2900/6700 (43%)]\tLoss: 0.000447\n",
      "Train Epoch: 6 [3000/6700 (45%)]\tLoss: 0.500604\n",
      "Train Epoch: 6 [3100/6700 (46%)]\tLoss: 0.068193\n",
      "Train Epoch: 6 [3200/6700 (48%)]\tLoss: 0.115801\n",
      "Train Epoch: 6 [3300/6700 (49%)]\tLoss: 3.139745\n",
      "Train Epoch: 6 [3400/6700 (51%)]\tLoss: 0.033615\n",
      "Train Epoch: 6 [3500/6700 (52%)]\tLoss: 3.618706\n",
      "Train Epoch: 6 [3600/6700 (54%)]\tLoss: 2.197622\n",
      "Train Epoch: 6 [3700/6700 (55%)]\tLoss: 0.076725\n",
      "Train Epoch: 6 [3800/6700 (57%)]\tLoss: 0.044121\n",
      "Train Epoch: 6 [3900/6700 (58%)]\tLoss: 0.006990\n",
      "Train Epoch: 6 [4000/6700 (60%)]\tLoss: 1.658916\n",
      "Train Epoch: 6 [4100/6700 (61%)]\tLoss: 0.535135\n",
      "Train Epoch: 6 [4200/6700 (63%)]\tLoss: 0.002178\n",
      "Train Epoch: 6 [4300/6700 (64%)]\tLoss: 0.442448\n",
      "Train Epoch: 6 [4400/6700 (66%)]\tLoss: 0.000203\n",
      "Train Epoch: 6 [4500/6700 (67%)]\tLoss: 1.136711\n",
      "Train Epoch: 6 [4600/6700 (69%)]\tLoss: 0.960997\n",
      "Train Epoch: 6 [4700/6700 (70%)]\tLoss: 0.077287\n",
      "Train Epoch: 6 [4800/6700 (72%)]\tLoss: 2.651751\n",
      "Train Epoch: 6 [4900/6700 (73%)]\tLoss: 0.022265\n",
      "Train Epoch: 6 [5000/6700 (75%)]\tLoss: 0.673416\n",
      "Train Epoch: 6 [5100/6700 (76%)]\tLoss: 0.018257\n",
      "Train Epoch: 6 [5200/6700 (78%)]\tLoss: 0.379210\n",
      "Train Epoch: 6 [5300/6700 (79%)]\tLoss: 0.383144\n",
      "Train Epoch: 6 [5400/6700 (81%)]\tLoss: 0.082396\n",
      "Train Epoch: 6 [5500/6700 (82%)]\tLoss: 1.085408\n",
      "Train Epoch: 6 [5600/6700 (84%)]\tLoss: 1.398739\n",
      "Train Epoch: 6 [5700/6700 (85%)]\tLoss: 2.826426\n",
      "Train Epoch: 6 [5800/6700 (87%)]\tLoss: 1.085473\n",
      "Train Epoch: 6 [5900/6700 (88%)]\tLoss: 0.116996\n",
      "Train Epoch: 6 [6000/6700 (90%)]\tLoss: 0.094930\n",
      "Train Epoch: 6 [6100/6700 (91%)]\tLoss: 0.001032\n",
      "Train Epoch: 6 [6200/6700 (93%)]\tLoss: 0.034092\n",
      "Train Epoch: 6 [6300/6700 (94%)]\tLoss: 0.011194\n",
      "Train Epoch: 6 [6400/6700 (96%)]\tLoss: 0.030258\n",
      "Train Epoch: 6 [6500/6700 (97%)]\tLoss: 0.181197\n",
      "Train Epoch: 6 [6600/6700 (99%)]\tLoss: 0.014530\n",
      "====> Epoch: 6 Average loss: 0.6491\n",
      "Train Epoch: 7 [0/6700 (0%)]\tLoss: 0.185438\n",
      "Train Epoch: 7 [100/6700 (1%)]\tLoss: 0.014238\n",
      "Train Epoch: 7 [200/6700 (3%)]\tLoss: 0.110029\n",
      "Train Epoch: 7 [300/6700 (4%)]\tLoss: 0.053358\n",
      "Train Epoch: 7 [400/6700 (6%)]\tLoss: 1.803599\n",
      "Train Epoch: 7 [500/6700 (7%)]\tLoss: 0.204036\n",
      "Train Epoch: 7 [600/6700 (9%)]\tLoss: 0.093771\n",
      "Train Epoch: 7 [700/6700 (10%)]\tLoss: 0.451205\n",
      "Train Epoch: 7 [800/6700 (12%)]\tLoss: 0.837811\n",
      "Train Epoch: 7 [900/6700 (13%)]\tLoss: 0.088998\n",
      "Train Epoch: 7 [1000/6700 (15%)]\tLoss: 0.195950\n",
      "Train Epoch: 7 [1100/6700 (16%)]\tLoss: 0.000103\n",
      "Train Epoch: 7 [1200/6700 (18%)]\tLoss: 0.001127\n",
      "Train Epoch: 7 [1300/6700 (19%)]\tLoss: 0.019553\n",
      "Train Epoch: 7 [1400/6700 (21%)]\tLoss: 0.018575\n",
      "Train Epoch: 7 [1500/6700 (22%)]\tLoss: 0.119237\n",
      "Train Epoch: 7 [1600/6700 (24%)]\tLoss: 1.670057\n",
      "Train Epoch: 7 [1700/6700 (25%)]\tLoss: 0.000606\n",
      "Train Epoch: 7 [1800/6700 (27%)]\tLoss: 0.005822\n",
      "Train Epoch: 7 [1900/6700 (28%)]\tLoss: 0.373071\n",
      "Train Epoch: 7 [2000/6700 (30%)]\tLoss: 5.921773\n",
      "Train Epoch: 7 [2100/6700 (31%)]\tLoss: 0.025953\n",
      "Train Epoch: 7 [2200/6700 (33%)]\tLoss: 0.363911\n",
      "Train Epoch: 7 [2300/6700 (34%)]\tLoss: 0.004803\n",
      "Train Epoch: 7 [2400/6700 (36%)]\tLoss: 0.042463\n",
      "Train Epoch: 7 [2500/6700 (37%)]\tLoss: 0.043314\n",
      "Train Epoch: 7 [2600/6700 (39%)]\tLoss: 0.106660\n",
      "Train Epoch: 7 [2700/6700 (40%)]\tLoss: 0.330511\n",
      "Train Epoch: 7 [2800/6700 (42%)]\tLoss: 0.061167\n",
      "Train Epoch: 7 [2900/6700 (43%)]\tLoss: 0.000117\n",
      "Train Epoch: 7 [3000/6700 (45%)]\tLoss: 1.027074\n",
      "Train Epoch: 7 [3100/6700 (46%)]\tLoss: 0.157292\n",
      "Train Epoch: 7 [3200/6700 (48%)]\tLoss: 0.094938\n",
      "Train Epoch: 7 [3300/6700 (49%)]\tLoss: 3.060100\n",
      "Train Epoch: 7 [3400/6700 (51%)]\tLoss: 0.036717\n",
      "Train Epoch: 7 [3500/6700 (52%)]\tLoss: 0.000001\n",
      "Train Epoch: 7 [3600/6700 (54%)]\tLoss: 2.372783\n",
      "Train Epoch: 7 [3700/6700 (55%)]\tLoss: 0.113202\n",
      "Train Epoch: 7 [3800/6700 (57%)]\tLoss: 0.011522\n",
      "Train Epoch: 7 [3900/6700 (58%)]\tLoss: 0.010790\n",
      "Train Epoch: 7 [4000/6700 (60%)]\tLoss: 0.948470\n",
      "Train Epoch: 7 [4100/6700 (61%)]\tLoss: 0.444386\n",
      "Train Epoch: 7 [4200/6700 (63%)]\tLoss: 0.001370\n",
      "Train Epoch: 7 [4300/6700 (64%)]\tLoss: 1.416857\n",
      "Train Epoch: 7 [4400/6700 (66%)]\tLoss: 0.000392\n",
      "Train Epoch: 7 [4500/6700 (67%)]\tLoss: 0.780646\n",
      "Train Epoch: 7 [4600/6700 (69%)]\tLoss: 0.528683\n",
      "Train Epoch: 7 [4700/6700 (70%)]\tLoss: 0.062890\n",
      "Train Epoch: 7 [4800/6700 (72%)]\tLoss: 2.687428\n",
      "Train Epoch: 7 [4900/6700 (73%)]\tLoss: 0.026223\n",
      "Train Epoch: 7 [5000/6700 (75%)]\tLoss: 0.597040\n",
      "Train Epoch: 7 [5100/6700 (76%)]\tLoss: 0.010261\n",
      "Train Epoch: 7 [5200/6700 (78%)]\tLoss: 0.311001\n",
      "Train Epoch: 7 [5300/6700 (79%)]\tLoss: 0.350307\n",
      "Train Epoch: 7 [5400/6700 (81%)]\tLoss: 0.113411\n",
      "Train Epoch: 7 [5500/6700 (82%)]\tLoss: 6.184730\n",
      "Train Epoch: 7 [5600/6700 (84%)]\tLoss: 1.249377\n",
      "Train Epoch: 7 [5700/6700 (85%)]\tLoss: 2.187356\n",
      "Train Epoch: 7 [5800/6700 (87%)]\tLoss: 1.694128\n",
      "Train Epoch: 7 [5900/6700 (88%)]\tLoss: 0.316468\n",
      "Train Epoch: 7 [6000/6700 (90%)]\tLoss: 0.136767\n",
      "Train Epoch: 7 [6100/6700 (91%)]\tLoss: 0.000581\n",
      "Train Epoch: 7 [6200/6700 (93%)]\tLoss: 0.021752\n",
      "Train Epoch: 7 [6300/6700 (94%)]\tLoss: 0.012761\n",
      "Train Epoch: 7 [6400/6700 (96%)]\tLoss: 0.034870\n",
      "Train Epoch: 7 [6500/6700 (97%)]\tLoss: 0.139815\n",
      "Train Epoch: 7 [6600/6700 (99%)]\tLoss: 0.010222\n",
      "====> Epoch: 7 Average loss: 0.6148\n",
      "Train Epoch: 8 [0/6700 (0%)]\tLoss: 0.166513\n",
      "Train Epoch: 8 [100/6700 (1%)]\tLoss: 0.012209\n",
      "Train Epoch: 8 [200/6700 (3%)]\tLoss: 0.086379\n",
      "Train Epoch: 8 [300/6700 (4%)]\tLoss: 0.038532\n",
      "Train Epoch: 8 [400/6700 (6%)]\tLoss: 2.223783\n",
      "Train Epoch: 8 [500/6700 (7%)]\tLoss: 0.203901\n",
      "Train Epoch: 8 [600/6700 (9%)]\tLoss: 0.055898\n",
      "Train Epoch: 8 [700/6700 (10%)]\tLoss: 0.440760\n",
      "Train Epoch: 8 [800/6700 (12%)]\tLoss: 0.636058\n",
      "Train Epoch: 8 [900/6700 (13%)]\tLoss: 0.078116\n",
      "Train Epoch: 8 [1000/6700 (15%)]\tLoss: 2.203116\n",
      "Train Epoch: 8 [1100/6700 (16%)]\tLoss: 0.049680\n",
      "Train Epoch: 8 [1200/6700 (18%)]\tLoss: 0.144680\n",
      "Train Epoch: 8 [1300/6700 (19%)]\tLoss: 0.011277\n",
      "Train Epoch: 8 [1400/6700 (21%)]\tLoss: 0.004459\n",
      "Train Epoch: 8 [1500/6700 (22%)]\tLoss: 0.131546\n",
      "Train Epoch: 8 [1600/6700 (24%)]\tLoss: 0.007754\n",
      "Train Epoch: 8 [1700/6700 (25%)]\tLoss: 0.000029\n",
      "Train Epoch: 8 [1800/6700 (27%)]\tLoss: 0.350043\n",
      "Train Epoch: 8 [1900/6700 (28%)]\tLoss: 0.387142\n",
      "Train Epoch: 8 [2000/6700 (30%)]\tLoss: 8.010052\n",
      "Train Epoch: 8 [2100/6700 (31%)]\tLoss: 0.025803\n",
      "Train Epoch: 8 [2200/6700 (33%)]\tLoss: 0.394306\n",
      "Train Epoch: 8 [2300/6700 (34%)]\tLoss: 0.004182\n",
      "Train Epoch: 8 [2400/6700 (36%)]\tLoss: 0.063026\n",
      "Train Epoch: 8 [2500/6700 (37%)]\tLoss: 0.072516\n",
      "Train Epoch: 8 [2600/6700 (39%)]\tLoss: 0.159795\n",
      "Train Epoch: 8 [2700/6700 (40%)]\tLoss: 0.423566\n",
      "Train Epoch: 8 [2800/6700 (42%)]\tLoss: 0.107520\n",
      "Train Epoch: 8 [2900/6700 (43%)]\tLoss: 0.000087\n",
      "Train Epoch: 8 [3000/6700 (45%)]\tLoss: 0.873810\n",
      "Train Epoch: 8 [3100/6700 (46%)]\tLoss: 0.025802\n",
      "Train Epoch: 8 [3200/6700 (48%)]\tLoss: 0.154242\n",
      "Train Epoch: 8 [3300/6700 (49%)]\tLoss: 3.068238\n",
      "Train Epoch: 8 [3400/6700 (51%)]\tLoss: 0.041893\n",
      "Train Epoch: 8 [3500/6700 (52%)]\tLoss: 2.443210\n",
      "Train Epoch: 8 [3600/6700 (54%)]\tLoss: 2.905303\n",
      "Train Epoch: 8 [3700/6700 (55%)]\tLoss: 0.103568\n",
      "Train Epoch: 8 [3800/6700 (57%)]\tLoss: 0.024215\n",
      "Train Epoch: 8 [3900/6700 (58%)]\tLoss: 0.003912\n",
      "Train Epoch: 8 [4000/6700 (60%)]\tLoss: 1.084524\n",
      "Train Epoch: 8 [4100/6700 (61%)]\tLoss: 0.612597\n",
      "Train Epoch: 8 [4200/6700 (63%)]\tLoss: 0.000539\n",
      "Train Epoch: 8 [4300/6700 (64%)]\tLoss: 0.775409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [4400/6700 (66%)]\tLoss: 0.000009\n",
      "Train Epoch: 8 [4500/6700 (67%)]\tLoss: 0.855413\n",
      "Train Epoch: 8 [4600/6700 (69%)]\tLoss: 0.878460\n",
      "Train Epoch: 8 [4700/6700 (70%)]\tLoss: 0.020851\n",
      "Train Epoch: 8 [4800/6700 (72%)]\tLoss: 2.986957\n",
      "Train Epoch: 8 [4900/6700 (73%)]\tLoss: 0.011705\n",
      "Train Epoch: 8 [5000/6700 (75%)]\tLoss: 0.390906\n",
      "Train Epoch: 8 [5100/6700 (76%)]\tLoss: 0.015311\n",
      "Train Epoch: 8 [5200/6700 (78%)]\tLoss: 0.286307\n",
      "Train Epoch: 8 [5300/6700 (79%)]\tLoss: 0.268280\n",
      "Train Epoch: 8 [5400/6700 (81%)]\tLoss: 0.045730\n",
      "Train Epoch: 8 [5500/6700 (82%)]\tLoss: 0.786717\n",
      "Train Epoch: 8 [5600/6700 (84%)]\tLoss: 0.926244\n",
      "Train Epoch: 8 [5700/6700 (85%)]\tLoss: 3.377732\n",
      "Train Epoch: 8 [5800/6700 (87%)]\tLoss: 1.075761\n",
      "Train Epoch: 8 [5900/6700 (88%)]\tLoss: 0.195868\n",
      "Train Epoch: 8 [6000/6700 (90%)]\tLoss: 0.491252\n",
      "Train Epoch: 8 [6100/6700 (91%)]\tLoss: 0.000632\n",
      "Train Epoch: 8 [6200/6700 (93%)]\tLoss: 0.010817\n",
      "Train Epoch: 8 [6300/6700 (94%)]\tLoss: 0.010576\n",
      "Train Epoch: 8 [6400/6700 (96%)]\tLoss: 0.032313\n",
      "Train Epoch: 8 [6500/6700 (97%)]\tLoss: 0.118826\n",
      "Train Epoch: 8 [6600/6700 (99%)]\tLoss: 0.008318\n",
      "====> Epoch: 8 Average loss: 0.5694\n",
      "Train Epoch: 9 [0/6700 (0%)]\tLoss: 0.353671\n",
      "Train Epoch: 9 [100/6700 (1%)]\tLoss: 0.009958\n",
      "Train Epoch: 9 [200/6700 (3%)]\tLoss: 0.123392\n",
      "Train Epoch: 9 [300/6700 (4%)]\tLoss: 0.006572\n",
      "Train Epoch: 9 [400/6700 (6%)]\tLoss: 1.664638\n",
      "Train Epoch: 9 [500/6700 (7%)]\tLoss: 0.332491\n",
      "Train Epoch: 9 [600/6700 (9%)]\tLoss: 0.051193\n",
      "Train Epoch: 9 [700/6700 (10%)]\tLoss: 0.693681\n",
      "Train Epoch: 9 [800/6700 (12%)]\tLoss: 0.749723\n",
      "Train Epoch: 9 [900/6700 (13%)]\tLoss: 0.113928\n",
      "Train Epoch: 9 [1000/6700 (15%)]\tLoss: 0.266898\n",
      "Train Epoch: 9 [1100/6700 (16%)]\tLoss: 0.000004\n",
      "Train Epoch: 9 [1200/6700 (18%)]\tLoss: 0.000254\n",
      "Train Epoch: 9 [1300/6700 (19%)]\tLoss: 0.010494\n",
      "Train Epoch: 9 [1400/6700 (21%)]\tLoss: 0.004498\n",
      "Train Epoch: 9 [1500/6700 (22%)]\tLoss: 0.105215\n",
      "Train Epoch: 9 [1600/6700 (24%)]\tLoss: 0.282427\n",
      "Train Epoch: 9 [1700/6700 (25%)]\tLoss: 0.000079\n",
      "Train Epoch: 9 [1800/6700 (27%)]\tLoss: 0.001018\n",
      "Train Epoch: 9 [1900/6700 (28%)]\tLoss: 0.258910\n",
      "Train Epoch: 9 [2000/6700 (30%)]\tLoss: 5.997082\n",
      "Train Epoch: 9 [2100/6700 (31%)]\tLoss: 0.029728\n",
      "Train Epoch: 9 [2200/6700 (33%)]\tLoss: 0.174179\n",
      "Train Epoch: 9 [2300/6700 (34%)]\tLoss: 0.002609\n",
      "Train Epoch: 9 [2400/6700 (36%)]\tLoss: 0.099514\n",
      "Train Epoch: 9 [2500/6700 (37%)]\tLoss: 0.055017\n",
      "Train Epoch: 9 [2600/6700 (39%)]\tLoss: 0.090376\n",
      "Train Epoch: 9 [2700/6700 (40%)]\tLoss: 0.110146\n",
      "Train Epoch: 9 [2800/6700 (42%)]\tLoss: 0.036609\n",
      "Train Epoch: 9 [2900/6700 (43%)]\tLoss: 0.000028\n",
      "Train Epoch: 9 [3000/6700 (45%)]\tLoss: 0.895125\n",
      "Train Epoch: 9 [3100/6700 (46%)]\tLoss: 0.021856\n",
      "Train Epoch: 9 [3200/6700 (48%)]\tLoss: 0.118731\n",
      "Train Epoch: 9 [3300/6700 (49%)]\tLoss: 3.456285\n",
      "Train Epoch: 9 [3400/6700 (51%)]\tLoss: 0.041611\n",
      "Train Epoch: 9 [3500/6700 (52%)]\tLoss: 0.161557\n",
      "Train Epoch: 9 [3600/6700 (54%)]\tLoss: 2.135725\n",
      "Train Epoch: 9 [3700/6700 (55%)]\tLoss: 0.123249\n",
      "Train Epoch: 9 [3800/6700 (57%)]\tLoss: 0.040518\n",
      "Train Epoch: 9 [3900/6700 (58%)]\tLoss: 0.001821\n",
      "Train Epoch: 9 [4000/6700 (60%)]\tLoss: 2.571986\n",
      "Train Epoch: 9 [4100/6700 (61%)]\tLoss: 0.412410\n",
      "Train Epoch: 9 [4200/6700 (63%)]\tLoss: 0.001039\n",
      "Train Epoch: 9 [4300/6700 (64%)]\tLoss: 0.436756\n",
      "Train Epoch: 9 [4400/6700 (66%)]\tLoss: 0.000001\n",
      "Train Epoch: 9 [4500/6700 (67%)]\tLoss: 0.432573\n",
      "Train Epoch: 9 [4600/6700 (69%)]\tLoss: 0.577561\n",
      "Train Epoch: 9 [4700/6700 (70%)]\tLoss: 0.026158\n",
      "Train Epoch: 9 [4800/6700 (72%)]\tLoss: 2.946037\n",
      "Train Epoch: 9 [4900/6700 (73%)]\tLoss: 0.011066\n",
      "Train Epoch: 9 [5000/6700 (75%)]\tLoss: 0.307981\n",
      "Train Epoch: 9 [5100/6700 (76%)]\tLoss: 0.007012\n",
      "Train Epoch: 9 [5200/6700 (78%)]\tLoss: 0.173311\n",
      "Train Epoch: 9 [5300/6700 (79%)]\tLoss: 0.295848\n",
      "Train Epoch: 9 [5400/6700 (81%)]\tLoss: 0.076438\n",
      "Train Epoch: 9 [5500/6700 (82%)]\tLoss: 0.540545\n",
      "Train Epoch: 9 [5600/6700 (84%)]\tLoss: 0.999370\n",
      "Train Epoch: 9 [5700/6700 (85%)]\tLoss: 2.758778\n",
      "Train Epoch: 9 [5800/6700 (87%)]\tLoss: 1.054099\n",
      "Train Epoch: 9 [5900/6700 (88%)]\tLoss: 0.410690\n",
      "Train Epoch: 9 [6000/6700 (90%)]\tLoss: 0.407559\n",
      "Train Epoch: 9 [6100/6700 (91%)]\tLoss: 0.000116\n",
      "Train Epoch: 9 [6200/6700 (93%)]\tLoss: 0.013314\n",
      "Train Epoch: 9 [6300/6700 (94%)]\tLoss: 0.003582\n",
      "Train Epoch: 9 [6400/6700 (96%)]\tLoss: 0.038094\n",
      "Train Epoch: 9 [6500/6700 (97%)]\tLoss: 0.164306\n",
      "Train Epoch: 9 [6600/6700 (99%)]\tLoss: 0.003527\n",
      "====> Epoch: 9 Average loss: 0.5051\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 12 22  7  4]\n",
      " [ 2  1  9  4 15]\n",
      " [ 3 12  4 39 22]\n",
      " ...\n",
      " [ 9  2 16 45  1]\n",
      " [ 4 37  5 16 18]\n",
      " [ 3 12 22 37 10]]\n",
      "[3. 2. 3. ... 9. 4. 3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "print (y_pred)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.774 prec@3: 0.917 prec@5: 0.950\n",
      "mprec@1: 5.034e-01 mprec@3: 7.645e-01 mprec@5: 8.343e-01\n",
      "prec matrix [0.77363636 0.87909091 0.9169697  0.94060606 0.94969697]\n",
      "mprec matrix [0.50340555 0.69311973 0.7645074  0.81593861 0.83426069]\n"
     ]
    }
   ],
   "source": [
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
