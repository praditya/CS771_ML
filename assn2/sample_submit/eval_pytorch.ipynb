{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import predict\n",
    "import time as tm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.datasets import make_classification\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Data\n",
    "dictSize = 225\n",
    "(X, y) = utils.loadData( \"train\", dictSize = dictSize )\n",
    "X = scipy.sparse.csr_matrix.toarray(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/multi-class-classification/47565\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            outp = self.forward(x)\n",
    "            return F.softmax(outp)\n",
    "# add softmax layer: used for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model declared\n",
    "model = NeuralNet(225 , 10000, 51)  \n",
    "# earlier hidden layers- 1000 \n",
    "# 1 - poor, 2- ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "model_opt = optim.SGD(model.parameters(), lr = 0.02)\n",
    "\n",
    "train_set_X = Variable(torch.from_numpy(X_train)).float()\n",
    "train_set_y = Variable(torch.LongTensor(y_train)).long()\n",
    "test_set_X = Variable(torch.from_numpy(X_test)).float()\n",
    "test_set_y = Variable(torch.LongTensor(y_test)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "epochs = 50\n",
    "for epochs in range(epochs):\n",
    "    model_opt.zero_grad()\n",
    "    out = model(train_set_X)\n",
    "    loss = loss_function(out, train_set_y)\n",
    "    loss.backward()\n",
    "    model_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "# for i in range(3299):\n",
    "#     ans_max,ind = torch.max(ans[i],0)\n",
    "#     print (test_set_y[i].numpy() - ind.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4  1  7  2]\n",
      " [ 2  1  4  3  9]\n",
      " [ 3  1  4  2 10]\n",
      " ...\n",
      " [ 1  2  4  9  3]\n",
      " [ 2  1  4  3  9]\n",
      " [ 3  4  1  2 10]]\n",
      "[3. 2. 3. ... 9. 4. 3.]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "print (y_pred)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.454 prec@3: 0.669 prec@5: 0.765\n",
      "mprec@1: 1.509e-02 mprec@3: 6.147e-02 mprec@5: 1.019e-01\n",
      "prec matrix [0.45363636 0.59242424 0.66939394 0.71393939 0.76454545]\n",
      "mprec matrix [0.01508809 0.04888622 0.06147312 0.08406356 0.1019489 ]\n"
     ]
    }
   ],
   "source": [
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 \n",
    "# same model diff train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_latent_X = data_utils.TensorDataset(train_set_X, train_set_y)\n",
    "te_latent_X = data_utils.TensorDataset(test_set_X,  test_set_y)\n",
    "train_loader_X = torch.utils.data.DataLoader(dataset=tr_latent_X)\n",
    "test_loader_X = torch.utils.data.DataLoader(dataset=te_latent_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data,label) in enumerate(train_loader_X):\n",
    "\n",
    "        model_opt.zero_grad()\n",
    "\n",
    "        out = model(data)\n",
    "        loss = loss_function(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        model_opt.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_X.dataset),\n",
    "                100. * batch_idx / len(train_loader_X), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader_X.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6700 (0%)]\tLoss: 2.049522\n",
      "Train Epoch: 1 [100/6700 (1%)]\tLoss: 0.885262\n",
      "Train Epoch: 1 [200/6700 (3%)]\tLoss: 0.256305\n",
      "Train Epoch: 1 [300/6700 (4%)]\tLoss: 5.151550\n",
      "Train Epoch: 1 [400/6700 (6%)]\tLoss: 5.028206\n",
      "Train Epoch: 1 [500/6700 (7%)]\tLoss: 0.602708\n",
      "Train Epoch: 1 [600/6700 (9%)]\tLoss: 1.652547\n",
      "Train Epoch: 1 [700/6700 (10%)]\tLoss: 0.907288\n",
      "Train Epoch: 1 [800/6700 (12%)]\tLoss: 1.879640\n",
      "Train Epoch: 1 [900/6700 (13%)]\tLoss: 0.296418\n",
      "Train Epoch: 1 [1000/6700 (15%)]\tLoss: 3.316686\n",
      "Train Epoch: 1 [1100/6700 (16%)]\tLoss: 0.000075\n",
      "Train Epoch: 1 [1200/6700 (18%)]\tLoss: 20.039415\n",
      "Train Epoch: 1 [1300/6700 (19%)]\tLoss: 0.105142\n",
      "Train Epoch: 1 [1400/6700 (21%)]\tLoss: 0.421650\n",
      "Train Epoch: 1 [1500/6700 (22%)]\tLoss: 0.378309\n",
      "Train Epoch: 1 [1600/6700 (24%)]\tLoss: 4.647684\n",
      "Train Epoch: 1 [1700/6700 (25%)]\tLoss: 0.019948\n",
      "Train Epoch: 1 [1800/6700 (27%)]\tLoss: 1.970050\n",
      "Train Epoch: 1 [1900/6700 (28%)]\tLoss: 1.825400\n",
      "Train Epoch: 1 [2000/6700 (30%)]\tLoss: 4.814600\n",
      "Train Epoch: 1 [2100/6700 (31%)]\tLoss: 0.525765\n",
      "Train Epoch: 1 [2200/6700 (33%)]\tLoss: 1.528555\n",
      "Train Epoch: 1 [2300/6700 (34%)]\tLoss: 0.043081\n",
      "Train Epoch: 1 [2400/6700 (36%)]\tLoss: 0.838617\n",
      "Train Epoch: 1 [2500/6700 (37%)]\tLoss: 0.032101\n",
      "Train Epoch: 1 [2600/6700 (39%)]\tLoss: 0.841208\n",
      "Train Epoch: 1 [2700/6700 (40%)]\tLoss: 4.498678\n",
      "Train Epoch: 1 [2800/6700 (42%)]\tLoss: 1.366824\n",
      "Train Epoch: 1 [2900/6700 (43%)]\tLoss: 0.298355\n",
      "Train Epoch: 1 [3000/6700 (45%)]\tLoss: 1.486375\n",
      "Train Epoch: 1 [3100/6700 (46%)]\tLoss: 1.107109\n",
      "Train Epoch: 1 [3200/6700 (48%)]\tLoss: 0.165380\n",
      "Train Epoch: 1 [3300/6700 (49%)]\tLoss: 3.848707\n",
      "Train Epoch: 1 [3400/6700 (51%)]\tLoss: 0.080665\n",
      "Train Epoch: 1 [3500/6700 (52%)]\tLoss: 0.319840\n",
      "Train Epoch: 1 [3600/6700 (54%)]\tLoss: 1.657158\n",
      "Train Epoch: 1 [3700/6700 (55%)]\tLoss: 0.333291\n",
      "Train Epoch: 1 [3800/6700 (57%)]\tLoss: 0.198892\n",
      "Train Epoch: 1 [3900/6700 (58%)]\tLoss: 0.147633\n",
      "Train Epoch: 1 [4000/6700 (60%)]\tLoss: 5.790795\n",
      "Train Epoch: 1 [4100/6700 (61%)]\tLoss: 0.208956\n",
      "Train Epoch: 1 [4200/6700 (63%)]\tLoss: 0.036578\n",
      "Train Epoch: 1 [4300/6700 (64%)]\tLoss: 1.167042\n",
      "Train Epoch: 1 [4400/6700 (66%)]\tLoss: 1.608238\n",
      "Train Epoch: 1 [4500/6700 (67%)]\tLoss: 1.990529\n",
      "Train Epoch: 1 [4600/6700 (69%)]\tLoss: 2.571256\n",
      "Train Epoch: 1 [4700/6700 (70%)]\tLoss: 0.542740\n",
      "Train Epoch: 1 [4800/6700 (72%)]\tLoss: 2.085116\n",
      "Train Epoch: 1 [4900/6700 (73%)]\tLoss: 2.057611\n",
      "Train Epoch: 1 [5000/6700 (75%)]\tLoss: 3.015985\n",
      "Train Epoch: 1 [5100/6700 (76%)]\tLoss: 0.658445\n",
      "Train Epoch: 1 [5200/6700 (78%)]\tLoss: 2.067592\n",
      "Train Epoch: 1 [5300/6700 (79%)]\tLoss: 0.752497\n",
      "Train Epoch: 1 [5400/6700 (81%)]\tLoss: 0.155145\n",
      "Train Epoch: 1 [5500/6700 (82%)]\tLoss: 4.811197\n",
      "Train Epoch: 1 [5600/6700 (84%)]\tLoss: 5.350845\n",
      "Train Epoch: 1 [5700/6700 (85%)]\tLoss: 2.696417\n",
      "Train Epoch: 1 [5800/6700 (87%)]\tLoss: 2.008203\n",
      "Train Epoch: 1 [5900/6700 (88%)]\tLoss: 0.536445\n",
      "Train Epoch: 1 [6000/6700 (90%)]\tLoss: 0.910975\n",
      "Train Epoch: 1 [6100/6700 (91%)]\tLoss: 0.018943\n",
      "Train Epoch: 1 [6200/6700 (93%)]\tLoss: 0.413521\n",
      "Train Epoch: 1 [6300/6700 (94%)]\tLoss: 0.083356\n",
      "Train Epoch: 1 [6400/6700 (96%)]\tLoss: 1.932796\n",
      "Train Epoch: 1 [6500/6700 (97%)]\tLoss: 0.230353\n",
      "Train Epoch: 1 [6600/6700 (99%)]\tLoss: 0.168437\n",
      "====> Epoch: 1 Average loss: 1.5913\n",
      "Train Epoch: 2 [0/6700 (0%)]\tLoss: 0.315510\n",
      "Train Epoch: 2 [100/6700 (1%)]\tLoss: 0.094846\n",
      "Train Epoch: 2 [200/6700 (3%)]\tLoss: 0.110450\n",
      "Train Epoch: 2 [300/6700 (4%)]\tLoss: 0.415527\n",
      "Train Epoch: 2 [400/6700 (6%)]\tLoss: 3.865882\n",
      "Train Epoch: 2 [500/6700 (7%)]\tLoss: 0.112751\n",
      "Train Epoch: 2 [600/6700 (9%)]\tLoss: 0.683069\n",
      "Train Epoch: 2 [700/6700 (10%)]\tLoss: 0.386674\n",
      "Train Epoch: 2 [800/6700 (12%)]\tLoss: 1.491774\n",
      "Train Epoch: 2 [900/6700 (13%)]\tLoss: 0.084391\n",
      "Train Epoch: 2 [1000/6700 (15%)]\tLoss: 1.793030\n",
      "Train Epoch: 2 [1100/6700 (16%)]\tLoss: 3.218888\n",
      "Train Epoch: 2 [1200/6700 (18%)]\tLoss: 1.759394\n",
      "Train Epoch: 2 [1300/6700 (19%)]\tLoss: 0.106386\n",
      "Train Epoch: 2 [1400/6700 (21%)]\tLoss: 0.031316\n",
      "Train Epoch: 2 [1500/6700 (22%)]\tLoss: 0.182456\n",
      "Train Epoch: 2 [1600/6700 (24%)]\tLoss: 0.002997\n",
      "Train Epoch: 2 [1700/6700 (25%)]\tLoss: 0.005113\n",
      "Train Epoch: 2 [1800/6700 (27%)]\tLoss: 0.595536\n",
      "Train Epoch: 2 [1900/6700 (28%)]\tLoss: 1.326064\n",
      "Train Epoch: 2 [2000/6700 (30%)]\tLoss: 6.092058\n",
      "Train Epoch: 2 [2100/6700 (31%)]\tLoss: 0.132278\n",
      "Train Epoch: 2 [2200/6700 (33%)]\tLoss: 1.114376\n",
      "Train Epoch: 2 [2300/6700 (34%)]\tLoss: 0.032910\n",
      "Train Epoch: 2 [2400/6700 (36%)]\tLoss: 0.133307\n",
      "Train Epoch: 2 [2500/6700 (37%)]\tLoss: 0.028705\n",
      "Train Epoch: 2 [2600/6700 (39%)]\tLoss: 0.746307\n",
      "Train Epoch: 2 [2700/6700 (40%)]\tLoss: 2.541287\n",
      "Train Epoch: 2 [2800/6700 (42%)]\tLoss: 0.270704\n",
      "Train Epoch: 2 [2900/6700 (43%)]\tLoss: 0.024365\n",
      "Train Epoch: 2 [3000/6700 (45%)]\tLoss: 1.104302\n",
      "Train Epoch: 2 [3100/6700 (46%)]\tLoss: 0.454928\n",
      "Train Epoch: 2 [3200/6700 (48%)]\tLoss: 0.102457\n",
      "Train Epoch: 2 [3300/6700 (49%)]\tLoss: 2.995719\n",
      "Train Epoch: 2 [3400/6700 (51%)]\tLoss: 0.048140\n",
      "Train Epoch: 2 [3500/6700 (52%)]\tLoss: 2.788409\n",
      "Train Epoch: 2 [3600/6700 (54%)]\tLoss: 2.746816\n",
      "Train Epoch: 2 [3700/6700 (55%)]\tLoss: 0.116635\n",
      "Train Epoch: 2 [3800/6700 (57%)]\tLoss: 0.120022\n",
      "Train Epoch: 2 [3900/6700 (58%)]\tLoss: 0.054652\n",
      "Train Epoch: 2 [4000/6700 (60%)]\tLoss: 4.014215\n",
      "Train Epoch: 2 [4100/6700 (61%)]\tLoss: 0.238855\n",
      "Train Epoch: 2 [4200/6700 (63%)]\tLoss: 0.004425\n",
      "Train Epoch: 2 [4300/6700 (64%)]\tLoss: 1.851872\n",
      "Train Epoch: 2 [4400/6700 (66%)]\tLoss: 0.011681\n",
      "Train Epoch: 2 [4500/6700 (67%)]\tLoss: 1.993495\n",
      "Train Epoch: 2 [4600/6700 (69%)]\tLoss: 1.532675\n",
      "Train Epoch: 2 [4700/6700 (70%)]\tLoss: 0.192356\n",
      "Train Epoch: 2 [4800/6700 (72%)]\tLoss: 2.452541\n",
      "Train Epoch: 2 [4900/6700 (73%)]\tLoss: 0.249680\n",
      "Train Epoch: 2 [5000/6700 (75%)]\tLoss: 2.424728\n",
      "Train Epoch: 2 [5100/6700 (76%)]\tLoss: 0.179236\n",
      "Train Epoch: 2 [5200/6700 (78%)]\tLoss: 1.610217\n",
      "Train Epoch: 2 [5300/6700 (79%)]\tLoss: 0.480246\n",
      "Train Epoch: 2 [5400/6700 (81%)]\tLoss: 0.165901\n",
      "Train Epoch: 2 [5500/6700 (82%)]\tLoss: 2.828207\n",
      "Train Epoch: 2 [5600/6700 (84%)]\tLoss: 3.174736\n",
      "Train Epoch: 2 [5700/6700 (85%)]\tLoss: 2.685610\n",
      "Train Epoch: 2 [5800/6700 (87%)]\tLoss: 1.800302\n",
      "Train Epoch: 2 [5900/6700 (88%)]\tLoss: 0.120182\n",
      "Train Epoch: 2 [6000/6700 (90%)]\tLoss: 0.892231\n",
      "Train Epoch: 2 [6100/6700 (91%)]\tLoss: 0.004166\n",
      "Train Epoch: 2 [6200/6700 (93%)]\tLoss: 0.077076\n",
      "Train Epoch: 2 [6300/6700 (94%)]\tLoss: 0.025283\n",
      "Train Epoch: 2 [6400/6700 (96%)]\tLoss: 0.428065\n",
      "Train Epoch: 2 [6500/6700 (97%)]\tLoss: 0.196709\n",
      "Train Epoch: 2 [6600/6700 (99%)]\tLoss: 0.052259\n",
      "====> Epoch: 2 Average loss: 1.0147\n",
      "Train Epoch: 3 [0/6700 (0%)]\tLoss: 0.628619\n",
      "Train Epoch: 3 [100/6700 (1%)]\tLoss: 0.043461\n",
      "Train Epoch: 3 [200/6700 (3%)]\tLoss: 0.116534\n",
      "Train Epoch: 3 [300/6700 (4%)]\tLoss: 0.157111\n",
      "Train Epoch: 3 [400/6700 (6%)]\tLoss: 3.658468\n",
      "Train Epoch: 3 [500/6700 (7%)]\tLoss: 0.188568\n",
      "Train Epoch: 3 [600/6700 (9%)]\tLoss: 0.276871\n",
      "Train Epoch: 3 [700/6700 (10%)]\tLoss: 0.423520\n",
      "Train Epoch: 3 [800/6700 (12%)]\tLoss: 1.181050\n",
      "Train Epoch: 3 [900/6700 (13%)]\tLoss: 0.067015\n",
      "Train Epoch: 3 [1000/6700 (15%)]\tLoss: 2.118765\n",
      "Train Epoch: 3 [1100/6700 (16%)]\tLoss: 0.002142\n",
      "Train Epoch: 3 [1200/6700 (18%)]\tLoss: 3.191847\n",
      "Train Epoch: 3 [1300/6700 (19%)]\tLoss: 0.029675\n",
      "Train Epoch: 3 [1400/6700 (21%)]\tLoss: 0.028441\n",
      "Train Epoch: 3 [1500/6700 (22%)]\tLoss: 0.136121\n",
      "Train Epoch: 3 [1600/6700 (24%)]\tLoss: 0.006832\n",
      "Train Epoch: 3 [1700/6700 (25%)]\tLoss: 0.007566\n",
      "Train Epoch: 3 [1800/6700 (27%)]\tLoss: 0.180979\n",
      "Train Epoch: 3 [1900/6700 (28%)]\tLoss: 1.080033\n",
      "Train Epoch: 3 [2000/6700 (30%)]\tLoss: 6.330151\n",
      "Train Epoch: 3 [2100/6700 (31%)]\tLoss: 0.059258\n",
      "Train Epoch: 3 [2200/6700 (33%)]\tLoss: 0.908712\n",
      "Train Epoch: 3 [2300/6700 (34%)]\tLoss: 0.006951\n",
      "Train Epoch: 3 [2400/6700 (36%)]\tLoss: 0.062680\n",
      "Train Epoch: 3 [2500/6700 (37%)]\tLoss: 0.023761\n",
      "Train Epoch: 3 [2600/6700 (39%)]\tLoss: 0.610852\n",
      "Train Epoch: 3 [2700/6700 (40%)]\tLoss: 1.333104\n",
      "Train Epoch: 3 [2800/6700 (42%)]\tLoss: 0.169021\n",
      "Train Epoch: 3 [2900/6700 (43%)]\tLoss: 0.003781\n",
      "Train Epoch: 3 [3000/6700 (45%)]\tLoss: 0.720038\n",
      "Train Epoch: 3 [3100/6700 (46%)]\tLoss: 0.143352\n",
      "Train Epoch: 3 [3200/6700 (48%)]\tLoss: 0.137133\n",
      "Train Epoch: 3 [3300/6700 (49%)]\tLoss: 2.709331\n",
      "Train Epoch: 3 [3400/6700 (51%)]\tLoss: 0.033081\n",
      "Train Epoch: 3 [3500/6700 (52%)]\tLoss: 0.233407\n",
      "Train Epoch: 3 [3600/6700 (54%)]\tLoss: 2.163257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [3700/6700 (55%)]\tLoss: 0.082510\n",
      "Train Epoch: 3 [3800/6700 (57%)]\tLoss: 0.069798\n",
      "Train Epoch: 3 [3900/6700 (58%)]\tLoss: 0.033343\n",
      "Train Epoch: 3 [4000/6700 (60%)]\tLoss: 2.509884\n",
      "Train Epoch: 3 [4100/6700 (61%)]\tLoss: 0.322819\n",
      "Train Epoch: 3 [4200/6700 (63%)]\tLoss: 0.003722\n",
      "Train Epoch: 3 [4300/6700 (64%)]\tLoss: 1.529987\n",
      "Train Epoch: 3 [4400/6700 (66%)]\tLoss: 0.006075\n",
      "Train Epoch: 3 [4500/6700 (67%)]\tLoss: 1.434485\n",
      "Train Epoch: 3 [4600/6700 (69%)]\tLoss: 1.347577\n",
      "Train Epoch: 3 [4700/6700 (70%)]\tLoss: 0.170593\n",
      "Train Epoch: 3 [4800/6700 (72%)]\tLoss: 2.673012\n",
      "Train Epoch: 3 [4900/6700 (73%)]\tLoss: 0.080038\n",
      "Train Epoch: 3 [5000/6700 (75%)]\tLoss: 1.100973\n",
      "Train Epoch: 3 [5100/6700 (76%)]\tLoss: 0.099057\n",
      "Train Epoch: 3 [5200/6700 (78%)]\tLoss: 0.706849\n",
      "Train Epoch: 3 [5300/6700 (79%)]\tLoss: 0.366289\n",
      "Train Epoch: 3 [5400/6700 (81%)]\tLoss: 0.191033\n",
      "Train Epoch: 3 [5500/6700 (82%)]\tLoss: 3.179729\n",
      "Train Epoch: 3 [5600/6700 (84%)]\tLoss: 2.778670\n",
      "Train Epoch: 3 [5700/6700 (85%)]\tLoss: 2.639697\n",
      "Train Epoch: 3 [5800/6700 (87%)]\tLoss: 1.748322\n",
      "Train Epoch: 3 [5900/6700 (88%)]\tLoss: 0.163285\n",
      "Train Epoch: 3 [6000/6700 (90%)]\tLoss: 0.651805\n",
      "Train Epoch: 3 [6100/6700 (91%)]\tLoss: 0.001794\n",
      "Train Epoch: 3 [6200/6700 (93%)]\tLoss: 0.039341\n",
      "Train Epoch: 3 [6300/6700 (94%)]\tLoss: 0.017095\n",
      "Train Epoch: 3 [6400/6700 (96%)]\tLoss: 0.161548\n",
      "Train Epoch: 3 [6500/6700 (97%)]\tLoss: 0.206935\n",
      "Train Epoch: 3 [6600/6700 (99%)]\tLoss: 0.030318\n",
      "====> Epoch: 3 Average loss: 0.8058\n",
      "Train Epoch: 4 [0/6700 (0%)]\tLoss: 0.405850\n",
      "Train Epoch: 4 [100/6700 (1%)]\tLoss: 0.020355\n",
      "Train Epoch: 4 [200/6700 (3%)]\tLoss: 0.115767\n",
      "Train Epoch: 4 [300/6700 (4%)]\tLoss: 0.060190\n",
      "Train Epoch: 4 [400/6700 (6%)]\tLoss: 3.335927\n",
      "Train Epoch: 4 [500/6700 (7%)]\tLoss: 0.211884\n",
      "Train Epoch: 4 [600/6700 (9%)]\tLoss: 0.242731\n",
      "Train Epoch: 4 [700/6700 (10%)]\tLoss: 0.396841\n",
      "Train Epoch: 4 [800/6700 (12%)]\tLoss: 1.203646\n",
      "Train Epoch: 4 [900/6700 (13%)]\tLoss: 0.064356\n",
      "Train Epoch: 4 [1000/6700 (15%)]\tLoss: 1.296715\n",
      "Train Epoch: 4 [1100/6700 (16%)]\tLoss: 0.456292\n",
      "Train Epoch: 4 [1200/6700 (18%)]\tLoss: 10.092370\n",
      "Train Epoch: 4 [1300/6700 (19%)]\tLoss: 0.022678\n",
      "Train Epoch: 4 [1400/6700 (21%)]\tLoss: 0.013860\n",
      "Train Epoch: 4 [1500/6700 (22%)]\tLoss: 0.126037\n",
      "Train Epoch: 4 [1600/6700 (24%)]\tLoss: 0.055073\n",
      "Train Epoch: 4 [1700/6700 (25%)]\tLoss: 0.003258\n",
      "Train Epoch: 4 [1800/6700 (27%)]\tLoss: 0.003497\n",
      "Train Epoch: 4 [1900/6700 (28%)]\tLoss: 0.969951\n",
      "Train Epoch: 4 [2000/6700 (30%)]\tLoss: 6.059000\n",
      "Train Epoch: 4 [2100/6700 (31%)]\tLoss: 0.051195\n",
      "Train Epoch: 4 [2200/6700 (33%)]\tLoss: 0.638306\n",
      "Train Epoch: 4 [2300/6700 (34%)]\tLoss: 0.005253\n",
      "Train Epoch: 4 [2400/6700 (36%)]\tLoss: 0.056778\n",
      "Train Epoch: 4 [2500/6700 (37%)]\tLoss: 0.024253\n",
      "Train Epoch: 4 [2600/6700 (39%)]\tLoss: 0.322131\n",
      "Train Epoch: 4 [2700/6700 (40%)]\tLoss: 0.988410\n",
      "Train Epoch: 4 [2800/6700 (42%)]\tLoss: 0.210275\n",
      "Train Epoch: 4 [2900/6700 (43%)]\tLoss: 0.001531\n",
      "Train Epoch: 4 [3000/6700 (45%)]\tLoss: 0.829235\n",
      "Train Epoch: 4 [3100/6700 (46%)]\tLoss: 0.104090\n",
      "Train Epoch: 4 [3200/6700 (48%)]\tLoss: 0.151464\n",
      "Train Epoch: 4 [3300/6700 (49%)]\tLoss: 2.618133\n",
      "Train Epoch: 4 [3400/6700 (51%)]\tLoss: 0.030666\n",
      "Train Epoch: 4 [3500/6700 (52%)]\tLoss: 0.234739\n",
      "Train Epoch: 4 [3600/6700 (54%)]\tLoss: 1.853714\n",
      "Train Epoch: 4 [3700/6700 (55%)]\tLoss: 0.098160\n",
      "Train Epoch: 4 [3800/6700 (57%)]\tLoss: 0.044533\n",
      "Train Epoch: 4 [3900/6700 (58%)]\tLoss: 0.014783\n",
      "Train Epoch: 4 [4000/6700 (60%)]\tLoss: 1.585932\n",
      "Train Epoch: 4 [4100/6700 (61%)]\tLoss: 0.480807\n",
      "Train Epoch: 4 [4200/6700 (63%)]\tLoss: 0.002063\n",
      "Train Epoch: 4 [4300/6700 (64%)]\tLoss: 0.522632\n",
      "Train Epoch: 4 [4400/6700 (66%)]\tLoss: 0.000816\n",
      "Train Epoch: 4 [4500/6700 (67%)]\tLoss: 1.130889\n",
      "Train Epoch: 4 [4600/6700 (69%)]\tLoss: 0.923583\n",
      "Train Epoch: 4 [4700/6700 (70%)]\tLoss: 0.101780\n",
      "Train Epoch: 4 [4800/6700 (72%)]\tLoss: 2.719980\n",
      "Train Epoch: 4 [4900/6700 (73%)]\tLoss: 0.031993\n",
      "Train Epoch: 4 [5000/6700 (75%)]\tLoss: 0.838109\n",
      "Train Epoch: 4 [5100/6700 (76%)]\tLoss: 0.082873\n",
      "Train Epoch: 4 [5200/6700 (78%)]\tLoss: 0.478889\n",
      "Train Epoch: 4 [5300/6700 (79%)]\tLoss: 0.321081\n",
      "Train Epoch: 4 [5400/6700 (81%)]\tLoss: 0.170002\n",
      "Train Epoch: 4 [5500/6700 (82%)]\tLoss: 2.117287\n",
      "Train Epoch: 4 [5600/6700 (84%)]\tLoss: 1.555430\n",
      "Train Epoch: 4 [5700/6700 (85%)]\tLoss: 2.875878\n",
      "Train Epoch: 4 [5800/6700 (87%)]\tLoss: 1.460772\n",
      "Train Epoch: 4 [5900/6700 (88%)]\tLoss: 0.234473\n",
      "Train Epoch: 4 [6000/6700 (90%)]\tLoss: 0.412838\n",
      "Train Epoch: 4 [6100/6700 (91%)]\tLoss: 0.000903\n",
      "Train Epoch: 4 [6200/6700 (93%)]\tLoss: 0.039452\n",
      "Train Epoch: 4 [6300/6700 (94%)]\tLoss: 0.016252\n",
      "Train Epoch: 4 [6400/6700 (96%)]\tLoss: 0.077626\n",
      "Train Epoch: 4 [6500/6700 (97%)]\tLoss: 0.150213\n",
      "Train Epoch: 4 [6600/6700 (99%)]\tLoss: 0.021186\n",
      "====> Epoch: 4 Average loss: 0.6828\n",
      "Train Epoch: 5 [0/6700 (0%)]\tLoss: 0.383419\n",
      "Train Epoch: 5 [100/6700 (1%)]\tLoss: 0.014672\n",
      "Train Epoch: 5 [200/6700 (3%)]\tLoss: 0.157818\n",
      "Train Epoch: 5 [300/6700 (4%)]\tLoss: 0.018229\n",
      "Train Epoch: 5 [400/6700 (6%)]\tLoss: 2.584012\n",
      "Train Epoch: 5 [500/6700 (7%)]\tLoss: 0.291540\n",
      "Train Epoch: 5 [600/6700 (9%)]\tLoss: 0.155103\n",
      "Train Epoch: 5 [700/6700 (10%)]\tLoss: 0.356221\n",
      "Train Epoch: 5 [800/6700 (12%)]\tLoss: 0.838228\n",
      "Train Epoch: 5 [900/6700 (13%)]\tLoss: 0.083946\n",
      "Train Epoch: 5 [1000/6700 (15%)]\tLoss: 0.149639\n",
      "Train Epoch: 5 [1100/6700 (16%)]\tLoss: 0.000008\n",
      "Train Epoch: 5 [1200/6700 (18%)]\tLoss: 0.000140\n",
      "Train Epoch: 5 [1300/6700 (19%)]\tLoss: 0.011191\n",
      "Train Epoch: 5 [1400/6700 (21%)]\tLoss: 0.006066\n",
      "Train Epoch: 5 [1500/6700 (22%)]\tLoss: 0.124771\n",
      "Train Epoch: 5 [1600/6700 (24%)]\tLoss: 2.590249\n",
      "Train Epoch: 5 [1700/6700 (25%)]\tLoss: 0.001405\n",
      "Train Epoch: 5 [1800/6700 (27%)]\tLoss: 0.000584\n",
      "Train Epoch: 5 [1900/6700 (28%)]\tLoss: 0.638614\n",
      "Train Epoch: 5 [2000/6700 (30%)]\tLoss: 5.269356\n",
      "Train Epoch: 5 [2100/6700 (31%)]\tLoss: 0.032114\n",
      "Train Epoch: 5 [2200/6700 (33%)]\tLoss: 0.423830\n",
      "Train Epoch: 5 [2300/6700 (34%)]\tLoss: 0.002894\n",
      "Train Epoch: 5 [2400/6700 (36%)]\tLoss: 0.089590\n",
      "Train Epoch: 5 [2500/6700 (37%)]\tLoss: 0.025995\n",
      "Train Epoch: 5 [2600/6700 (39%)]\tLoss: 0.116297\n",
      "Train Epoch: 5 [2700/6700 (40%)]\tLoss: 0.239366\n",
      "Train Epoch: 5 [2800/6700 (42%)]\tLoss: 0.202878\n",
      "Train Epoch: 5 [2900/6700 (43%)]\tLoss: 0.000287\n",
      "Train Epoch: 5 [3000/6700 (45%)]\tLoss: 1.014067\n",
      "Train Epoch: 5 [3100/6700 (46%)]\tLoss: 0.074343\n",
      "Train Epoch: 5 [3200/6700 (48%)]\tLoss: 0.135853\n",
      "Train Epoch: 5 [3300/6700 (49%)]\tLoss: 2.490787\n",
      "Train Epoch: 5 [3400/6700 (51%)]\tLoss: 0.029797\n",
      "Train Epoch: 5 [3500/6700 (52%)]\tLoss: 1.190333\n",
      "Train Epoch: 5 [3600/6700 (54%)]\tLoss: 2.934788\n",
      "Train Epoch: 5 [3700/6700 (55%)]\tLoss: 0.104544\n",
      "Train Epoch: 5 [3800/6700 (57%)]\tLoss: 0.034980\n",
      "Train Epoch: 5 [3900/6700 (58%)]\tLoss: 0.010010\n",
      "Train Epoch: 5 [4000/6700 (60%)]\tLoss: 1.954315\n",
      "Train Epoch: 5 [4100/6700 (61%)]\tLoss: 0.574938\n",
      "Train Epoch: 5 [4200/6700 (63%)]\tLoss: 0.002625\n",
      "Train Epoch: 5 [4300/6700 (64%)]\tLoss: 0.155142\n",
      "Train Epoch: 5 [4400/6700 (66%)]\tLoss: 0.000260\n",
      "Train Epoch: 5 [4500/6700 (67%)]\tLoss: 1.008164\n",
      "Train Epoch: 5 [4600/6700 (69%)]\tLoss: 0.594631\n",
      "Train Epoch: 5 [4700/6700 (70%)]\tLoss: 0.060279\n",
      "Train Epoch: 5 [4800/6700 (72%)]\tLoss: 2.707923\n",
      "Train Epoch: 5 [4900/6700 (73%)]\tLoss: 0.021227\n",
      "Train Epoch: 5 [5000/6700 (75%)]\tLoss: 0.619965\n",
      "Train Epoch: 5 [5100/6700 (76%)]\tLoss: 0.012625\n",
      "Train Epoch: 5 [5200/6700 (78%)]\tLoss: 0.176749\n",
      "Train Epoch: 5 [5300/6700 (79%)]\tLoss: 0.321319\n",
      "Train Epoch: 5 [5400/6700 (81%)]\tLoss: 0.164601\n",
      "Train Epoch: 5 [5500/6700 (82%)]\tLoss: 1.068432\n",
      "Train Epoch: 5 [5600/6700 (84%)]\tLoss: 1.166159\n",
      "Train Epoch: 5 [5700/6700 (85%)]\tLoss: 3.033607\n",
      "Train Epoch: 5 [5800/6700 (87%)]\tLoss: 1.274409\n",
      "Train Epoch: 5 [5900/6700 (88%)]\tLoss: 0.331890\n",
      "Train Epoch: 5 [6000/6700 (90%)]\tLoss: 0.138262\n",
      "Train Epoch: 5 [6100/6700 (91%)]\tLoss: 0.000613\n",
      "Train Epoch: 5 [6200/6700 (93%)]\tLoss: 0.018717\n",
      "Train Epoch: 5 [6300/6700 (94%)]\tLoss: 0.018774\n",
      "Train Epoch: 5 [6400/6700 (96%)]\tLoss: 0.047404\n",
      "Train Epoch: 5 [6500/6700 (97%)]\tLoss: 0.173149\n",
      "Train Epoch: 5 [6600/6700 (99%)]\tLoss: 0.019094\n",
      "====> Epoch: 5 Average loss: 0.5900\n",
      "Train Epoch: 6 [0/6700 (0%)]\tLoss: 0.460758\n",
      "Train Epoch: 6 [100/6700 (1%)]\tLoss: 0.008543\n",
      "Train Epoch: 6 [200/6700 (3%)]\tLoss: 0.102153\n",
      "Train Epoch: 6 [300/6700 (4%)]\tLoss: 0.011373\n",
      "Train Epoch: 6 [400/6700 (6%)]\tLoss: 1.612479\n",
      "Train Epoch: 6 [500/6700 (7%)]\tLoss: 0.325709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [600/6700 (9%)]\tLoss: 0.075927\n",
      "Train Epoch: 6 [700/6700 (10%)]\tLoss: 0.565931\n",
      "Train Epoch: 6 [800/6700 (12%)]\tLoss: 1.058079\n",
      "Train Epoch: 6 [900/6700 (13%)]\tLoss: 0.084677\n",
      "Train Epoch: 6 [1000/6700 (15%)]\tLoss: 0.084108\n",
      "Train Epoch: 6 [1100/6700 (16%)]\tLoss: 0.000036\n",
      "Train Epoch: 6 [1200/6700 (18%)]\tLoss: 0.000903\n",
      "Train Epoch: 6 [1300/6700 (19%)]\tLoss: 0.013028\n",
      "Train Epoch: 6 [1400/6700 (21%)]\tLoss: 0.005875\n",
      "Train Epoch: 6 [1500/6700 (22%)]\tLoss: 0.070695\n",
      "Train Epoch: 6 [1600/6700 (24%)]\tLoss: 0.000004\n",
      "Train Epoch: 6 [1700/6700 (25%)]\tLoss: 0.000816\n",
      "Train Epoch: 6 [1800/6700 (27%)]\tLoss: 0.000361\n",
      "Train Epoch: 6 [1900/6700 (28%)]\tLoss: 0.490602\n",
      "Train Epoch: 6 [2000/6700 (30%)]\tLoss: 6.388147\n",
      "Train Epoch: 6 [2100/6700 (31%)]\tLoss: 0.026410\n",
      "Train Epoch: 6 [2200/6700 (33%)]\tLoss: 0.193434\n",
      "Train Epoch: 6 [2300/6700 (34%)]\tLoss: 0.001366\n",
      "Train Epoch: 6 [2400/6700 (36%)]\tLoss: 0.083673\n",
      "Train Epoch: 6 [2500/6700 (37%)]\tLoss: 0.015256\n",
      "Train Epoch: 6 [2600/6700 (39%)]\tLoss: 0.139194\n",
      "Train Epoch: 6 [2700/6700 (40%)]\tLoss: 0.183128\n",
      "Train Epoch: 6 [2800/6700 (42%)]\tLoss: 0.113230\n",
      "Train Epoch: 6 [2900/6700 (43%)]\tLoss: 0.000134\n",
      "Train Epoch: 6 [3000/6700 (45%)]\tLoss: 0.942661\n",
      "Train Epoch: 6 [3100/6700 (46%)]\tLoss: 0.110017\n",
      "Train Epoch: 6 [3200/6700 (48%)]\tLoss: 0.115635\n",
      "Train Epoch: 6 [3300/6700 (49%)]\tLoss: 2.197543\n",
      "Train Epoch: 6 [3400/6700 (51%)]\tLoss: 0.040569\n",
      "Train Epoch: 6 [3500/6700 (52%)]\tLoss: 0.000180\n",
      "Train Epoch: 6 [3600/6700 (54%)]\tLoss: 1.051208\n",
      "Train Epoch: 6 [3700/6700 (55%)]\tLoss: 0.107436\n",
      "Train Epoch: 6 [3800/6700 (57%)]\tLoss: 0.020796\n",
      "Train Epoch: 6 [3900/6700 (58%)]\tLoss: 0.007354\n",
      "Train Epoch: 6 [4000/6700 (60%)]\tLoss: 0.788755\n",
      "Train Epoch: 6 [4100/6700 (61%)]\tLoss: 0.426533\n",
      "Train Epoch: 6 [4200/6700 (63%)]\tLoss: 0.000875\n",
      "Train Epoch: 6 [4300/6700 (64%)]\tLoss: 0.707548\n",
      "Train Epoch: 6 [4400/6700 (66%)]\tLoss: 0.000894\n",
      "Train Epoch: 6 [4500/6700 (67%)]\tLoss: 0.496259\n",
      "Train Epoch: 6 [4600/6700 (69%)]\tLoss: 0.450764\n",
      "Train Epoch: 6 [4700/6700 (70%)]\tLoss: 0.063381\n",
      "Train Epoch: 6 [4800/6700 (72%)]\tLoss: 3.056046\n",
      "Train Epoch: 6 [4900/6700 (73%)]\tLoss: 0.015864\n",
      "Train Epoch: 6 [5000/6700 (75%)]\tLoss: 0.404509\n",
      "Train Epoch: 6 [5100/6700 (76%)]\tLoss: 0.018766\n",
      "Train Epoch: 6 [5200/6700 (78%)]\tLoss: 0.245016\n",
      "Train Epoch: 6 [5300/6700 (79%)]\tLoss: 0.279324\n",
      "Train Epoch: 6 [5400/6700 (81%)]\tLoss: 0.079604\n",
      "Train Epoch: 6 [5500/6700 (82%)]\tLoss: 0.978971\n",
      "Train Epoch: 6 [5600/6700 (84%)]\tLoss: 1.252949\n",
      "Train Epoch: 6 [5700/6700 (85%)]\tLoss: 2.678935\n",
      "Train Epoch: 6 [5800/6700 (87%)]\tLoss: 1.379611\n",
      "Train Epoch: 6 [5900/6700 (88%)]\tLoss: 0.323859\n",
      "Train Epoch: 6 [6000/6700 (90%)]\tLoss: 0.380322\n",
      "Train Epoch: 6 [6100/6700 (91%)]\tLoss: 0.000294\n",
      "Train Epoch: 6 [6200/6700 (93%)]\tLoss: 0.009310\n",
      "Train Epoch: 6 [6300/6700 (94%)]\tLoss: 0.006295\n",
      "Train Epoch: 6 [6400/6700 (96%)]\tLoss: 0.046233\n",
      "Train Epoch: 6 [6500/6700 (97%)]\tLoss: 0.257999\n",
      "Train Epoch: 6 [6600/6700 (99%)]\tLoss: 0.013722\n",
      "====> Epoch: 6 Average loss: 0.5348\n",
      "Train Epoch: 7 [0/6700 (0%)]\tLoss: 0.294232\n",
      "Train Epoch: 7 [100/6700 (1%)]\tLoss: 0.005985\n",
      "Train Epoch: 7 [200/6700 (3%)]\tLoss: 0.149382\n",
      "Train Epoch: 7 [300/6700 (4%)]\tLoss: 0.006819\n",
      "Train Epoch: 7 [400/6700 (6%)]\tLoss: 1.974093\n",
      "Train Epoch: 7 [500/6700 (7%)]\tLoss: 0.170424\n",
      "Train Epoch: 7 [600/6700 (9%)]\tLoss: 0.067178\n",
      "Train Epoch: 7 [700/6700 (10%)]\tLoss: 0.519081\n",
      "Train Epoch: 7 [800/6700 (12%)]\tLoss: 0.949717\n",
      "Train Epoch: 7 [900/6700 (13%)]\tLoss: 0.057191\n",
      "Train Epoch: 7 [1000/6700 (15%)]\tLoss: 0.057091\n",
      "Train Epoch: 7 [1100/6700 (16%)]\tLoss: 0.063016\n",
      "Train Epoch: 7 [1200/6700 (18%)]\tLoss: 0.000505\n",
      "Train Epoch: 7 [1300/6700 (19%)]\tLoss: 0.013296\n",
      "Train Epoch: 7 [1400/6700 (21%)]\tLoss: 0.005013\n",
      "Train Epoch: 7 [1500/6700 (22%)]\tLoss: 0.064919\n",
      "Train Epoch: 7 [1600/6700 (24%)]\tLoss: 0.000172\n",
      "Train Epoch: 7 [1700/6700 (25%)]\tLoss: 0.000364\n",
      "Train Epoch: 7 [1800/6700 (27%)]\tLoss: 0.000013\n",
      "Train Epoch: 7 [1900/6700 (28%)]\tLoss: 0.859035\n",
      "Train Epoch: 7 [2000/6700 (30%)]\tLoss: 6.264906\n",
      "Train Epoch: 7 [2100/6700 (31%)]\tLoss: 0.031075\n",
      "Train Epoch: 7 [2200/6700 (33%)]\tLoss: 0.133895\n",
      "Train Epoch: 7 [2300/6700 (34%)]\tLoss: 0.001448\n",
      "Train Epoch: 7 [2400/6700 (36%)]\tLoss: 0.094741\n",
      "Train Epoch: 7 [2500/6700 (37%)]\tLoss: 0.018602\n",
      "Train Epoch: 7 [2600/6700 (39%)]\tLoss: 0.068521\n",
      "Train Epoch: 7 [2700/6700 (40%)]\tLoss: 0.261048\n",
      "Train Epoch: 7 [2800/6700 (42%)]\tLoss: 0.139416\n",
      "Train Epoch: 7 [2900/6700 (43%)]\tLoss: 0.000081\n",
      "Train Epoch: 7 [3000/6700 (45%)]\tLoss: 1.025531\n",
      "Train Epoch: 7 [3100/6700 (46%)]\tLoss: 0.045865\n",
      "Train Epoch: 7 [3200/6700 (48%)]\tLoss: 0.137905\n",
      "Train Epoch: 7 [3300/6700 (49%)]\tLoss: 1.674300\n",
      "Train Epoch: 7 [3400/6700 (51%)]\tLoss: 0.048320\n",
      "Train Epoch: 7 [3500/6700 (52%)]\tLoss: 0.000881\n",
      "Train Epoch: 7 [3600/6700 (54%)]\tLoss: 1.872151\n",
      "Train Epoch: 7 [3700/6700 (55%)]\tLoss: 0.079010\n",
      "Train Epoch: 7 [3800/6700 (57%)]\tLoss: 0.009154\n",
      "Train Epoch: 7 [3900/6700 (58%)]\tLoss: 0.004188\n",
      "Train Epoch: 7 [4000/6700 (60%)]\tLoss: 0.937793\n",
      "Train Epoch: 7 [4100/6700 (61%)]\tLoss: 0.373547\n",
      "Train Epoch: 7 [4200/6700 (63%)]\tLoss: 0.000575\n",
      "Train Epoch: 7 [4300/6700 (64%)]\tLoss: 0.116527\n",
      "Train Epoch: 7 [4400/6700 (66%)]\tLoss: 0.000006\n",
      "Train Epoch: 7 [4500/6700 (67%)]\tLoss: 0.522075\n",
      "Train Epoch: 7 [4600/6700 (69%)]\tLoss: 0.349726\n",
      "Train Epoch: 7 [4700/6700 (70%)]\tLoss: 0.038514\n",
      "Train Epoch: 7 [4800/6700 (72%)]\tLoss: 3.067355\n",
      "Train Epoch: 7 [4900/6700 (73%)]\tLoss: 0.010515\n",
      "Train Epoch: 7 [5000/6700 (75%)]\tLoss: 0.425345\n",
      "Train Epoch: 7 [5100/6700 (76%)]\tLoss: 0.008232\n",
      "Train Epoch: 7 [5200/6700 (78%)]\tLoss: 0.176461\n",
      "Train Epoch: 7 [5300/6700 (79%)]\tLoss: 0.292000\n",
      "Train Epoch: 7 [5400/6700 (81%)]\tLoss: 0.070281\n",
      "Train Epoch: 7 [5500/6700 (82%)]\tLoss: 0.356314\n",
      "Train Epoch: 7 [5600/6700 (84%)]\tLoss: 1.679121\n",
      "Train Epoch: 7 [5700/6700 (85%)]\tLoss: 3.053516\n",
      "Train Epoch: 7 [5800/6700 (87%)]\tLoss: 1.166247\n",
      "Train Epoch: 7 [5900/6700 (88%)]\tLoss: 0.389608\n",
      "Train Epoch: 7 [6000/6700 (90%)]\tLoss: 0.026276\n",
      "Train Epoch: 7 [6100/6700 (91%)]\tLoss: 0.000254\n",
      "Train Epoch: 7 [6200/6700 (93%)]\tLoss: 0.020916\n",
      "Train Epoch: 7 [6300/6700 (94%)]\tLoss: 0.028274\n",
      "Train Epoch: 7 [6400/6700 (96%)]\tLoss: 0.036025\n",
      "Train Epoch: 7 [6500/6700 (97%)]\tLoss: 0.167528\n",
      "Train Epoch: 7 [6600/6700 (99%)]\tLoss: 0.018219\n",
      "====> Epoch: 7 Average loss: 0.4954\n",
      "Train Epoch: 8 [0/6700 (0%)]\tLoss: 0.325335\n",
      "Train Epoch: 8 [100/6700 (1%)]\tLoss: 0.006953\n",
      "Train Epoch: 8 [200/6700 (3%)]\tLoss: 0.140785\n",
      "Train Epoch: 8 [300/6700 (4%)]\tLoss: 0.005922\n",
      "Train Epoch: 8 [400/6700 (6%)]\tLoss: 0.691202\n",
      "Train Epoch: 8 [500/6700 (7%)]\tLoss: 0.199077\n",
      "Train Epoch: 8 [600/6700 (9%)]\tLoss: 0.025853\n",
      "Train Epoch: 8 [700/6700 (10%)]\tLoss: 0.617200\n",
      "Train Epoch: 8 [800/6700 (12%)]\tLoss: 0.581906\n",
      "Train Epoch: 8 [900/6700 (13%)]\tLoss: 0.086926\n",
      "Train Epoch: 8 [1000/6700 (15%)]\tLoss: 0.047310\n",
      "Train Epoch: 8 [1100/6700 (16%)]\tLoss: 0.000000\n",
      "Train Epoch: 8 [1200/6700 (18%)]\tLoss: 0.000081\n",
      "Train Epoch: 8 [1300/6700 (19%)]\tLoss: 0.015857\n",
      "Train Epoch: 8 [1400/6700 (21%)]\tLoss: 0.002839\n",
      "Train Epoch: 8 [1500/6700 (22%)]\tLoss: 0.041877\n",
      "Train Epoch: 8 [1600/6700 (24%)]\tLoss: 0.000035\n",
      "Train Epoch: 8 [1700/6700 (25%)]\tLoss: 0.000128\n",
      "Train Epoch: 8 [1800/6700 (27%)]\tLoss: 0.000188\n",
      "Train Epoch: 8 [1900/6700 (28%)]\tLoss: 0.256984\n",
      "Train Epoch: 8 [2000/6700 (30%)]\tLoss: 5.546315\n",
      "Train Epoch: 8 [2100/6700 (31%)]\tLoss: 0.025015\n",
      "Train Epoch: 8 [2200/6700 (33%)]\tLoss: 0.046460\n",
      "Train Epoch: 8 [2300/6700 (34%)]\tLoss: 0.000882\n",
      "Train Epoch: 8 [2400/6700 (36%)]\tLoss: 0.220421\n",
      "Train Epoch: 8 [2500/6700 (37%)]\tLoss: 0.012294\n",
      "Train Epoch: 8 [2600/6700 (39%)]\tLoss: 0.056404\n",
      "Train Epoch: 8 [2700/6700 (40%)]\tLoss: 0.054661\n",
      "Train Epoch: 8 [2800/6700 (42%)]\tLoss: 0.121457\n",
      "Train Epoch: 8 [2900/6700 (43%)]\tLoss: 0.000030\n",
      "Train Epoch: 8 [3000/6700 (45%)]\tLoss: 1.036560\n",
      "Train Epoch: 8 [3100/6700 (46%)]\tLoss: 0.022898\n",
      "Train Epoch: 8 [3200/6700 (48%)]\tLoss: 0.125875\n",
      "Train Epoch: 8 [3300/6700 (49%)]\tLoss: 2.189814\n",
      "Train Epoch: 8 [3400/6700 (51%)]\tLoss: 0.040464\n",
      "Train Epoch: 8 [3500/6700 (52%)]\tLoss: 3.389654\n",
      "Train Epoch: 8 [3600/6700 (54%)]\tLoss: 2.109454\n",
      "Train Epoch: 8 [3700/6700 (55%)]\tLoss: 0.063416\n",
      "Train Epoch: 8 [3800/6700 (57%)]\tLoss: 0.030676\n",
      "Train Epoch: 8 [3900/6700 (58%)]\tLoss: 0.002534\n",
      "Train Epoch: 8 [4000/6700 (60%)]\tLoss: 2.903078\n",
      "Train Epoch: 8 [4100/6700 (61%)]\tLoss: 0.471784\n",
      "Train Epoch: 8 [4200/6700 (63%)]\tLoss: 0.001340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [4300/6700 (64%)]\tLoss: 0.018532\n",
      "Train Epoch: 8 [4400/6700 (66%)]\tLoss: 0.000006\n",
      "Train Epoch: 8 [4500/6700 (67%)]\tLoss: 0.335584\n",
      "Train Epoch: 8 [4600/6700 (69%)]\tLoss: 0.350255\n",
      "Train Epoch: 8 [4700/6700 (70%)]\tLoss: 0.018560\n",
      "Train Epoch: 8 [4800/6700 (72%)]\tLoss: 2.933100\n",
      "Train Epoch: 8 [4900/6700 (73%)]\tLoss: 0.008084\n",
      "Train Epoch: 8 [5000/6700 (75%)]\tLoss: 0.385090\n",
      "Train Epoch: 8 [5100/6700 (76%)]\tLoss: 0.007060\n",
      "Train Epoch: 8 [5200/6700 (78%)]\tLoss: 0.161712\n",
      "Train Epoch: 8 [5300/6700 (79%)]\tLoss: 0.240506\n",
      "Train Epoch: 8 [5400/6700 (81%)]\tLoss: 0.000093\n",
      "Train Epoch: 8 [5500/6700 (82%)]\tLoss: 0.372610\n",
      "Train Epoch: 8 [5600/6700 (84%)]\tLoss: 0.900231\n",
      "Train Epoch: 8 [5700/6700 (85%)]\tLoss: 2.750024\n",
      "Train Epoch: 8 [5800/6700 (87%)]\tLoss: 0.698008\n",
      "Train Epoch: 8 [5900/6700 (88%)]\tLoss: 0.323333\n",
      "Train Epoch: 8 [6000/6700 (90%)]\tLoss: 0.028429\n",
      "Train Epoch: 8 [6100/6700 (91%)]\tLoss: 0.000160\n",
      "Train Epoch: 8 [6200/6700 (93%)]\tLoss: 0.019020\n",
      "Train Epoch: 8 [6300/6700 (94%)]\tLoss: 0.012661\n",
      "Train Epoch: 8 [6400/6700 (96%)]\tLoss: 0.027760\n",
      "Train Epoch: 8 [6500/6700 (97%)]\tLoss: 0.253894\n",
      "Train Epoch: 8 [6600/6700 (99%)]\tLoss: 0.008193\n",
      "====> Epoch: 8 Average loss: 0.4503\n",
      "Train Epoch: 9 [0/6700 (0%)]\tLoss: 0.179982\n",
      "Train Epoch: 9 [100/6700 (1%)]\tLoss: 0.005079\n",
      "Train Epoch: 9 [200/6700 (3%)]\tLoss: 0.109511\n",
      "Train Epoch: 9 [300/6700 (4%)]\tLoss: 0.002964\n",
      "Train Epoch: 9 [400/6700 (6%)]\tLoss: 1.186289\n",
      "Train Epoch: 9 [500/6700 (7%)]\tLoss: 0.121750\n",
      "Train Epoch: 9 [600/6700 (9%)]\tLoss: 0.033833\n",
      "Train Epoch: 9 [700/6700 (10%)]\tLoss: 0.810713\n",
      "Train Epoch: 9 [800/6700 (12%)]\tLoss: 0.759367\n",
      "Train Epoch: 9 [900/6700 (13%)]\tLoss: 0.100447\n",
      "Train Epoch: 9 [1000/6700 (15%)]\tLoss: 0.016319\n",
      "Train Epoch: 9 [1100/6700 (16%)]\tLoss: 0.000227\n",
      "Train Epoch: 9 [1200/6700 (18%)]\tLoss: 0.181596\n",
      "Train Epoch: 9 [1300/6700 (19%)]\tLoss: 0.008789\n",
      "Train Epoch: 9 [1400/6700 (21%)]\tLoss: 0.002289\n",
      "Train Epoch: 9 [1500/6700 (22%)]\tLoss: 0.055041\n",
      "Train Epoch: 9 [1600/6700 (24%)]\tLoss: 0.000272\n",
      "Train Epoch: 9 [1700/6700 (25%)]\tLoss: 0.000052\n",
      "Train Epoch: 9 [1800/6700 (27%)]\tLoss: 0.000019\n",
      "Train Epoch: 9 [1900/6700 (28%)]\tLoss: 0.400468\n",
      "Train Epoch: 9 [2000/6700 (30%)]\tLoss: 4.877581\n",
      "Train Epoch: 9 [2100/6700 (31%)]\tLoss: 0.006502\n",
      "Train Epoch: 9 [2200/6700 (33%)]\tLoss: 0.055857\n",
      "Train Epoch: 9 [2300/6700 (34%)]\tLoss: 0.000597\n",
      "Train Epoch: 9 [2400/6700 (36%)]\tLoss: 0.055539\n",
      "Train Epoch: 9 [2500/6700 (37%)]\tLoss: 0.014305\n",
      "Train Epoch: 9 [2600/6700 (39%)]\tLoss: 0.103042\n",
      "Train Epoch: 9 [2700/6700 (40%)]\tLoss: 0.088080\n",
      "Train Epoch: 9 [2800/6700 (42%)]\tLoss: 0.161666\n",
      "Train Epoch: 9 [2900/6700 (43%)]\tLoss: 0.000021\n",
      "Train Epoch: 9 [3000/6700 (45%)]\tLoss: 0.689047\n",
      "Train Epoch: 9 [3100/6700 (46%)]\tLoss: 0.016051\n",
      "Train Epoch: 9 [3200/6700 (48%)]\tLoss: 0.184970\n",
      "Train Epoch: 9 [3300/6700 (49%)]\tLoss: 3.232903\n",
      "Train Epoch: 9 [3400/6700 (51%)]\tLoss: 0.042362\n",
      "Train Epoch: 9 [3500/6700 (52%)]\tLoss: 0.000010\n",
      "Train Epoch: 9 [3600/6700 (54%)]\tLoss: 1.796437\n",
      "Train Epoch: 9 [3700/6700 (55%)]\tLoss: 0.068932\n",
      "Train Epoch: 9 [3800/6700 (57%)]\tLoss: 0.015548\n",
      "Train Epoch: 9 [3900/6700 (58%)]\tLoss: 0.002688\n",
      "Train Epoch: 9 [4000/6700 (60%)]\tLoss: 3.317417\n",
      "Train Epoch: 9 [4100/6700 (61%)]\tLoss: 0.384607\n",
      "Train Epoch: 9 [4200/6700 (63%)]\tLoss: 0.000453\n",
      "Train Epoch: 9 [4300/6700 (64%)]\tLoss: 0.463879\n",
      "Train Epoch: 9 [4400/6700 (66%)]\tLoss: 0.000002\n",
      "Train Epoch: 9 [4500/6700 (67%)]\tLoss: 0.159964\n",
      "Train Epoch: 9 [4600/6700 (69%)]\tLoss: 0.233610\n",
      "Train Epoch: 9 [4700/6700 (70%)]\tLoss: 0.019418\n",
      "Train Epoch: 9 [4800/6700 (72%)]\tLoss: 3.522160\n",
      "Train Epoch: 9 [4900/6700 (73%)]\tLoss: 0.002588\n",
      "Train Epoch: 9 [5000/6700 (75%)]\tLoss: 0.333286\n",
      "Train Epoch: 9 [5100/6700 (76%)]\tLoss: 0.009088\n",
      "Train Epoch: 9 [5200/6700 (78%)]\tLoss: 0.178988\n",
      "Train Epoch: 9 [5300/6700 (79%)]\tLoss: 0.241175\n",
      "Train Epoch: 9 [5400/6700 (81%)]\tLoss: 0.078055\n",
      "Train Epoch: 9 [5500/6700 (82%)]\tLoss: 0.647127\n",
      "Train Epoch: 9 [5600/6700 (84%)]\tLoss: 0.945957\n",
      "Train Epoch: 9 [5700/6700 (85%)]\tLoss: 3.149135\n",
      "Train Epoch: 9 [5800/6700 (87%)]\tLoss: 0.517130\n",
      "Train Epoch: 9 [5900/6700 (88%)]\tLoss: 0.236736\n",
      "Train Epoch: 9 [6000/6700 (90%)]\tLoss: 0.488854\n",
      "Train Epoch: 9 [6100/6700 (91%)]\tLoss: 0.000183\n",
      "Train Epoch: 9 [6200/6700 (93%)]\tLoss: 0.005685\n",
      "Train Epoch: 9 [6300/6700 (94%)]\tLoss: 0.003308\n",
      "Train Epoch: 9 [6400/6700 (96%)]\tLoss: 0.025026\n",
      "Train Epoch: 9 [6500/6700 (97%)]\tLoss: 0.166187\n",
      "Train Epoch: 9 [6600/6700 (99%)]\tLoss: 0.014799\n",
      "====> Epoch: 9 Average loss: 0.4598\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 12 22  4  7]\n",
      " [ 2  4  1  9 21]\n",
      " [ 3 12  4  1 39]\n",
      " ...\n",
      " [ 9  2 45 15 16]\n",
      " [ 4 37  5 18  2]\n",
      " [ 3 12 37 22 10]]\n",
      "[3. 2. 3. ... 9. 4. 3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "print (y_pred)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.762 prec@3: 0.918 prec@5: 0.955\n",
      "mprec@1: 8.627e-03 mprec@3: 6.489e-02 mprec@5: 1.113e-01\n",
      "prec matrix [0.76212121 0.88       0.91757576 0.94030303 0.95545455]\n",
      "mprec matrix [0.00862691 0.0407148  0.06489299 0.09325235 0.11130134]\n"
     ]
    }
   ],
   "source": [
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
