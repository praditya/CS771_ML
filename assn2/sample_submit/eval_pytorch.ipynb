{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import predict\n",
    "import time as tm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.datasets import make_classification\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Data\n",
    "dictSize = 225\n",
    "(X, y) = utils.loadData( \"train\", dictSize = dictSize )\n",
    "X = scipy.sparse.csr_matrix.toarray(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/multi-class-classification/47565\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            outp = self.forward(x)\n",
    "            return F.softmax(outp)\n",
    "# add softmax layer: used for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(225 , 1000, 51) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "model_opt = optim.SGD(model.parameters(), lr = 0.02)\n",
    "\n",
    "train_set_X = Variable(torch.from_numpy(X_train)).float()\n",
    "train_set_y = Variable(torch.LongTensor(y_train)).long()\n",
    "test_set_X = Variable(torch.from_numpy(X_test)).float()\n",
    "test_set_y = Variable(torch.LongTensor(y_test)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "for epochs in range(epochs):\n",
    "    model_opt.zero_grad()\n",
    "    out = model(train_set_X)\n",
    "    loss = loss_function(out, train_set_y)\n",
    "    loss.backward()\n",
    "    model_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "# for i in range(3299):\n",
    "#     ans_max,ind = torch.max(ans[i],0)\n",
    "#     print (test_set_y[i].numpy() - ind.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  2  4  1  7]\n",
      " [ 2  1  3  4  9]\n",
      " [ 2  3  4  1 10]\n",
      " ...\n",
      " [ 2  1  3  4  9]\n",
      " [ 2  1  4  3  9]\n",
      " [ 2  3  4  1 10]]\n",
      "[3. 2. 3. ... 9. 4. 3.]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "print (y_pred)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.321 prec@3: 0.640 prec@5: 0.756\n",
      "mprec@1: 1.485e-02 mprec@3: 6.839e-02 mprec@5: 9.979e-02\n",
      "prec matrix [0.32121212 0.5469697  0.64030303 0.69363636 0.75575758]\n",
      "mprec matrix [0.01485361 0.05146679 0.06839326 0.08510638 0.09979241]\n"
     ]
    }
   ],
   "source": [
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_latent_X = data_utils.TensorDataset(train_set_X, train_set_y)\n",
    "te_latent_X = data_utils.TensorDataset(test_set_X,  test_set_y)\n",
    "train_loader_X = torch.utils.data.DataLoader(dataset=tr_latent_X)\n",
    "test_loader_X = torch.utils.data.DataLoader(dataset=te_latent_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data,label) in enumerate(train_loader_X):\n",
    "\n",
    "        model_opt.zero_grad()\n",
    "\n",
    "        out = model(data)\n",
    "        loss = loss_function(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        model_opt.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_X.dataset),\n",
    "                100. * batch_idx / len(train_loader_X), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader_X.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6700 (0%)]\tLoss: 2.782231\n",
      "Train Epoch: 1 [100/6700 (1%)]\tLoss: 2.185000\n",
      "Train Epoch: 1 [200/6700 (3%)]\tLoss: 0.777501\n",
      "Train Epoch: 1 [300/6700 (4%)]\tLoss: 4.263538\n",
      "Train Epoch: 1 [400/6700 (6%)]\tLoss: 3.963913\n",
      "Train Epoch: 1 [500/6700 (7%)]\tLoss: 1.399235\n",
      "Train Epoch: 1 [600/6700 (9%)]\tLoss: 1.802389\n",
      "Train Epoch: 1 [700/6700 (10%)]\tLoss: 0.861583\n",
      "Train Epoch: 1 [800/6700 (12%)]\tLoss: 2.324794\n",
      "Train Epoch: 1 [900/6700 (13%)]\tLoss: 0.489476\n",
      "Train Epoch: 1 [1000/6700 (15%)]\tLoss: 2.900987\n",
      "Train Epoch: 1 [1100/6700 (16%)]\tLoss: 0.046456\n",
      "Train Epoch: 1 [1200/6700 (18%)]\tLoss: 7.725688\n",
      "Train Epoch: 1 [1300/6700 (19%)]\tLoss: 0.208752\n",
      "Train Epoch: 1 [1400/6700 (21%)]\tLoss: 1.557099\n",
      "Train Epoch: 1 [1500/6700 (22%)]\tLoss: 0.621560\n",
      "Train Epoch: 1 [1600/6700 (24%)]\tLoss: 1.850730\n",
      "Train Epoch: 1 [1700/6700 (25%)]\tLoss: 0.042184\n",
      "Train Epoch: 1 [1800/6700 (27%)]\tLoss: 0.900797\n",
      "Train Epoch: 1 [1900/6700 (28%)]\tLoss: 1.109613\n",
      "Train Epoch: 1 [2000/6700 (30%)]\tLoss: 4.435700\n",
      "Train Epoch: 1 [2100/6700 (31%)]\tLoss: 0.978669\n",
      "Train Epoch: 1 [2200/6700 (33%)]\tLoss: 1.812021\n",
      "Train Epoch: 1 [2300/6700 (34%)]\tLoss: 0.056960\n",
      "Train Epoch: 1 [2400/6700 (36%)]\tLoss: 1.583511\n",
      "Train Epoch: 1 [2500/6700 (37%)]\tLoss: 0.118531\n",
      "Train Epoch: 1 [2600/6700 (39%)]\tLoss: 1.285213\n",
      "Train Epoch: 1 [2700/6700 (40%)]\tLoss: 5.263152\n",
      "Train Epoch: 1 [2800/6700 (42%)]\tLoss: 1.080371\n",
      "Train Epoch: 1 [2900/6700 (43%)]\tLoss: 0.826520\n",
      "Train Epoch: 1 [3000/6700 (45%)]\tLoss: 1.232475\n",
      "Train Epoch: 1 [3100/6700 (46%)]\tLoss: 1.364134\n",
      "Train Epoch: 1 [3200/6700 (48%)]\tLoss: 0.167407\n",
      "Train Epoch: 1 [3300/6700 (49%)]\tLoss: 4.050312\n",
      "Train Epoch: 1 [3400/6700 (51%)]\tLoss: 0.145650\n",
      "Train Epoch: 1 [3500/6700 (52%)]\tLoss: 0.357292\n",
      "Train Epoch: 1 [3600/6700 (54%)]\tLoss: 1.618011\n",
      "Train Epoch: 1 [3700/6700 (55%)]\tLoss: 0.582812\n",
      "Train Epoch: 1 [3800/6700 (57%)]\tLoss: 0.504519\n",
      "Train Epoch: 1 [3900/6700 (58%)]\tLoss: 0.354280\n",
      "Train Epoch: 1 [4000/6700 (60%)]\tLoss: 7.474514\n",
      "Train Epoch: 1 [4100/6700 (61%)]\tLoss: 0.203819\n",
      "Train Epoch: 1 [4200/6700 (63%)]\tLoss: 0.037518\n",
      "Train Epoch: 1 [4300/6700 (64%)]\tLoss: 1.275638\n",
      "Train Epoch: 1 [4400/6700 (66%)]\tLoss: 1.031405\n",
      "Train Epoch: 1 [4500/6700 (67%)]\tLoss: 1.902439\n",
      "Train Epoch: 1 [4600/6700 (69%)]\tLoss: 3.030015\n",
      "Train Epoch: 1 [4700/6700 (70%)]\tLoss: 0.768025\n",
      "Train Epoch: 1 [4800/6700 (72%)]\tLoss: 1.983924\n",
      "Train Epoch: 1 [4900/6700 (73%)]\tLoss: 3.414760\n",
      "Train Epoch: 1 [5000/6700 (75%)]\tLoss: 3.309292\n",
      "Train Epoch: 1 [5100/6700 (76%)]\tLoss: 0.752932\n",
      "Train Epoch: 1 [5200/6700 (78%)]\tLoss: 1.942665\n",
      "Train Epoch: 1 [5300/6700 (79%)]\tLoss: 0.874649\n",
      "Train Epoch: 1 [5400/6700 (81%)]\tLoss: 0.139057\n",
      "Train Epoch: 1 [5500/6700 (82%)]\tLoss: 4.441352\n",
      "Train Epoch: 1 [5600/6700 (84%)]\tLoss: 6.278313\n",
      "Train Epoch: 1 [5700/6700 (85%)]\tLoss: 3.032212\n",
      "Train Epoch: 1 [5800/6700 (87%)]\tLoss: 2.012036\n",
      "Train Epoch: 1 [5900/6700 (88%)]\tLoss: 0.610590\n",
      "Train Epoch: 1 [6000/6700 (90%)]\tLoss: 0.423794\n",
      "Train Epoch: 1 [6100/6700 (91%)]\tLoss: 0.063223\n",
      "Train Epoch: 1 [6200/6700 (93%)]\tLoss: 0.527689\n",
      "Train Epoch: 1 [6300/6700 (94%)]\tLoss: 0.079154\n",
      "Train Epoch: 1 [6400/6700 (96%)]\tLoss: 2.627208\n",
      "Train Epoch: 1 [6500/6700 (97%)]\tLoss: 0.252911\n",
      "Train Epoch: 1 [6600/6700 (99%)]\tLoss: 0.531627\n",
      "====> Epoch: 1 Average loss: 1.6464\n",
      "Train Epoch: 2 [0/6700 (0%)]\tLoss: 0.570594\n",
      "Train Epoch: 2 [100/6700 (1%)]\tLoss: 0.152756\n",
      "Train Epoch: 2 [200/6700 (3%)]\tLoss: 0.206405\n",
      "Train Epoch: 2 [300/6700 (4%)]\tLoss: 0.611232\n",
      "Train Epoch: 2 [400/6700 (6%)]\tLoss: 3.593591\n",
      "Train Epoch: 2 [500/6700 (7%)]\tLoss: 0.235231\n",
      "Train Epoch: 2 [600/6700 (9%)]\tLoss: 1.086029\n",
      "Train Epoch: 2 [700/6700 (10%)]\tLoss: 0.567192\n",
      "Train Epoch: 2 [800/6700 (12%)]\tLoss: 1.571751\n",
      "Train Epoch: 2 [900/6700 (13%)]\tLoss: 0.110522\n",
      "Train Epoch: 2 [1000/6700 (15%)]\tLoss: 1.734495\n",
      "Train Epoch: 2 [1100/6700 (16%)]\tLoss: 3.466577\n",
      "Train Epoch: 2 [1200/6700 (18%)]\tLoss: 7.178528\n",
      "Train Epoch: 2 [1300/6700 (19%)]\tLoss: 0.055314\n",
      "Train Epoch: 2 [1400/6700 (21%)]\tLoss: 0.084709\n",
      "Train Epoch: 2 [1500/6700 (22%)]\tLoss: 0.198700\n",
      "Train Epoch: 2 [1600/6700 (24%)]\tLoss: 0.454072\n",
      "Train Epoch: 2 [1700/6700 (25%)]\tLoss: 0.038436\n",
      "Train Epoch: 2 [1800/6700 (27%)]\tLoss: 1.707354\n",
      "Train Epoch: 2 [1900/6700 (28%)]\tLoss: 1.204040\n",
      "Train Epoch: 2 [2000/6700 (30%)]\tLoss: 5.906093\n",
      "Train Epoch: 2 [2100/6700 (31%)]\tLoss: 0.436694\n",
      "Train Epoch: 2 [2200/6700 (33%)]\tLoss: 1.350892\n",
      "Train Epoch: 2 [2300/6700 (34%)]\tLoss: 0.046288\n",
      "Train Epoch: 2 [2400/6700 (36%)]\tLoss: 0.169264\n",
      "Train Epoch: 2 [2500/6700 (37%)]\tLoss: 0.073920\n",
      "Train Epoch: 2 [2600/6700 (39%)]\tLoss: 0.924249\n",
      "Train Epoch: 2 [2700/6700 (40%)]\tLoss: 2.828913\n",
      "Train Epoch: 2 [2800/6700 (42%)]\tLoss: 0.347858\n",
      "Train Epoch: 2 [2900/6700 (43%)]\tLoss: 0.047215\n",
      "Train Epoch: 2 [3000/6700 (45%)]\tLoss: 0.659256\n",
      "Train Epoch: 2 [3100/6700 (46%)]\tLoss: 0.678571\n",
      "Train Epoch: 2 [3200/6700 (48%)]\tLoss: 0.124702\n",
      "Train Epoch: 2 [3300/6700 (49%)]\tLoss: 2.766029\n",
      "Train Epoch: 2 [3400/6700 (51%)]\tLoss: 0.030169\n",
      "Train Epoch: 2 [3500/6700 (52%)]\tLoss: 0.041368\n",
      "Train Epoch: 2 [3600/6700 (54%)]\tLoss: 1.764829\n",
      "Train Epoch: 2 [3700/6700 (55%)]\tLoss: 0.184845\n",
      "Train Epoch: 2 [3800/6700 (57%)]\tLoss: 0.182529\n",
      "Train Epoch: 2 [3900/6700 (58%)]\tLoss: 0.073353\n",
      "Train Epoch: 2 [4000/6700 (60%)]\tLoss: 4.953071\n",
      "Train Epoch: 2 [4100/6700 (61%)]\tLoss: 0.193428\n",
      "Train Epoch: 2 [4200/6700 (63%)]\tLoss: 0.013442\n",
      "Train Epoch: 2 [4300/6700 (64%)]\tLoss: 1.101166\n",
      "Train Epoch: 2 [4400/6700 (66%)]\tLoss: 0.020122\n",
      "Train Epoch: 2 [4500/6700 (67%)]\tLoss: 2.345531\n",
      "Train Epoch: 2 [4600/6700 (69%)]\tLoss: 2.351766\n",
      "Train Epoch: 2 [4700/6700 (70%)]\tLoss: 0.284351\n",
      "Train Epoch: 2 [4800/6700 (72%)]\tLoss: 2.140597\n",
      "Train Epoch: 2 [4900/6700 (73%)]\tLoss: 1.187556\n",
      "Train Epoch: 2 [5000/6700 (75%)]\tLoss: 2.429159\n",
      "Train Epoch: 2 [5100/6700 (76%)]\tLoss: 0.190591\n",
      "Train Epoch: 2 [5200/6700 (78%)]\tLoss: 1.828986\n",
      "Train Epoch: 2 [5300/6700 (79%)]\tLoss: 0.646318\n",
      "Train Epoch: 2 [5400/6700 (81%)]\tLoss: 0.079621\n",
      "Train Epoch: 2 [5500/6700 (82%)]\tLoss: 2.523793\n",
      "Train Epoch: 2 [5600/6700 (84%)]\tLoss: 4.929485\n",
      "Train Epoch: 2 [5700/6700 (85%)]\tLoss: 2.890671\n",
      "Train Epoch: 2 [5800/6700 (87%)]\tLoss: 1.423283\n",
      "Train Epoch: 2 [5900/6700 (88%)]\tLoss: 0.263366\n",
      "Train Epoch: 2 [6000/6700 (90%)]\tLoss: 0.339514\n",
      "Train Epoch: 2 [6100/6700 (91%)]\tLoss: 0.013758\n",
      "Train Epoch: 2 [6200/6700 (93%)]\tLoss: 0.151396\n",
      "Train Epoch: 2 [6300/6700 (94%)]\tLoss: 0.026812\n",
      "Train Epoch: 2 [6400/6700 (96%)]\tLoss: 0.589192\n",
      "Train Epoch: 2 [6500/6700 (97%)]\tLoss: 0.189520\n",
      "Train Epoch: 2 [6600/6700 (99%)]\tLoss: 0.098952\n",
      "====> Epoch: 2 Average loss: 1.1106\n",
      "Train Epoch: 3 [0/6700 (0%)]\tLoss: 0.245038\n",
      "Train Epoch: 3 [100/6700 (1%)]\tLoss: 0.060514\n",
      "Train Epoch: 3 [200/6700 (3%)]\tLoss: 0.179917\n",
      "Train Epoch: 3 [300/6700 (4%)]\tLoss: 0.307778\n",
      "Train Epoch: 3 [400/6700 (6%)]\tLoss: 3.443704\n",
      "Train Epoch: 3 [500/6700 (7%)]\tLoss: 0.148591\n",
      "Train Epoch: 3 [600/6700 (9%)]\tLoss: 0.405231\n",
      "Train Epoch: 3 [700/6700 (10%)]\tLoss: 0.494060\n",
      "Train Epoch: 3 [800/6700 (12%)]\tLoss: 1.372577\n",
      "Train Epoch: 3 [900/6700 (13%)]\tLoss: 0.048877\n",
      "Train Epoch: 3 [1000/6700 (15%)]\tLoss: 1.576137\n",
      "Train Epoch: 3 [1100/6700 (16%)]\tLoss: 0.004918\n",
      "Train Epoch: 3 [1200/6700 (18%)]\tLoss: 3.542111\n",
      "Train Epoch: 3 [1300/6700 (19%)]\tLoss: 0.043258\n",
      "Train Epoch: 3 [1400/6700 (21%)]\tLoss: 0.031078\n",
      "Train Epoch: 3 [1500/6700 (22%)]\tLoss: 0.188117\n",
      "Train Epoch: 3 [1600/6700 (24%)]\tLoss: 1.006713\n",
      "Train Epoch: 3 [1700/6700 (25%)]\tLoss: 0.004873\n",
      "Train Epoch: 3 [1800/6700 (27%)]\tLoss: 0.269394\n",
      "Train Epoch: 3 [1900/6700 (28%)]\tLoss: 1.443143\n",
      "Train Epoch: 3 [2000/6700 (30%)]\tLoss: 5.487508\n",
      "Train Epoch: 3 [2100/6700 (31%)]\tLoss: 0.164897\n",
      "Train Epoch: 3 [2200/6700 (33%)]\tLoss: 0.871617\n",
      "Train Epoch: 3 [2300/6700 (34%)]\tLoss: 0.038550\n",
      "Train Epoch: 3 [2400/6700 (36%)]\tLoss: 0.076740\n",
      "Train Epoch: 3 [2500/6700 (37%)]\tLoss: 0.075864\n",
      "Train Epoch: 3 [2600/6700 (39%)]\tLoss: 0.561400\n",
      "Train Epoch: 3 [2700/6700 (40%)]\tLoss: 1.598040\n",
      "Train Epoch: 3 [2800/6700 (42%)]\tLoss: 0.110086\n",
      "Train Epoch: 3 [2900/6700 (43%)]\tLoss: 0.007043\n",
      "Train Epoch: 3 [3000/6700 (45%)]\tLoss: 0.460847\n",
      "Train Epoch: 3 [3100/6700 (46%)]\tLoss: 0.321676\n",
      "Train Epoch: 3 [3200/6700 (48%)]\tLoss: 0.147314\n",
      "Train Epoch: 3 [3300/6700 (49%)]\tLoss: 2.867159\n",
      "Train Epoch: 3 [3400/6700 (51%)]\tLoss: 0.035680\n",
      "Train Epoch: 3 [3500/6700 (52%)]\tLoss: 1.668690\n",
      "Train Epoch: 3 [3600/6700 (54%)]\tLoss: 1.501359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [3700/6700 (55%)]\tLoss: 0.104322\n",
      "Train Epoch: 3 [3800/6700 (57%)]\tLoss: 0.064507\n",
      "Train Epoch: 3 [3900/6700 (58%)]\tLoss: 0.034301\n",
      "Train Epoch: 3 [4000/6700 (60%)]\tLoss: 1.905348\n",
      "Train Epoch: 3 [4100/6700 (61%)]\tLoss: 0.217452\n",
      "Train Epoch: 3 [4200/6700 (63%)]\tLoss: 0.007071\n",
      "Train Epoch: 3 [4300/6700 (64%)]\tLoss: 1.024406\n",
      "Train Epoch: 3 [4400/6700 (66%)]\tLoss: 0.002218\n",
      "Train Epoch: 3 [4500/6700 (67%)]\tLoss: 2.127766\n",
      "Train Epoch: 3 [4600/6700 (69%)]\tLoss: 1.839814\n",
      "Train Epoch: 3 [4700/6700 (70%)]\tLoss: 0.240608\n",
      "Train Epoch: 3 [4800/6700 (72%)]\tLoss: 2.227814\n",
      "Train Epoch: 3 [4900/6700 (73%)]\tLoss: 0.338265\n",
      "Train Epoch: 3 [5000/6700 (75%)]\tLoss: 2.020960\n",
      "Train Epoch: 3 [5100/6700 (76%)]\tLoss: 0.052181\n",
      "Train Epoch: 3 [5200/6700 (78%)]\tLoss: 1.538784\n",
      "Train Epoch: 3 [5300/6700 (79%)]\tLoss: 0.472497\n",
      "Train Epoch: 3 [5400/6700 (81%)]\tLoss: 0.117076\n",
      "Train Epoch: 3 [5500/6700 (82%)]\tLoss: 2.206626\n",
      "Train Epoch: 3 [5600/6700 (84%)]\tLoss: 2.920035\n",
      "Train Epoch: 3 [5700/6700 (85%)]\tLoss: 2.393973\n",
      "Train Epoch: 3 [5800/6700 (87%)]\tLoss: 1.330660\n",
      "Train Epoch: 3 [5900/6700 (88%)]\tLoss: 0.167432\n",
      "Train Epoch: 3 [6000/6700 (90%)]\tLoss: 0.658086\n",
      "Train Epoch: 3 [6100/6700 (91%)]\tLoss: 0.004878\n",
      "Train Epoch: 3 [6200/6700 (93%)]\tLoss: 0.068209\n",
      "Train Epoch: 3 [6300/6700 (94%)]\tLoss: 0.016806\n",
      "Train Epoch: 3 [6400/6700 (96%)]\tLoss: 0.175585\n",
      "Train Epoch: 3 [6500/6700 (97%)]\tLoss: 0.123803\n",
      "Train Epoch: 3 [6600/6700 (99%)]\tLoss: 0.041023\n",
      "====> Epoch: 3 Average loss: 0.9125\n",
      "Train Epoch: 4 [0/6700 (0%)]\tLoss: 0.182577\n",
      "Train Epoch: 4 [100/6700 (1%)]\tLoss: 0.030395\n",
      "Train Epoch: 4 [200/6700 (3%)]\tLoss: 0.180241\n",
      "Train Epoch: 4 [300/6700 (4%)]\tLoss: 0.187796\n",
      "Train Epoch: 4 [400/6700 (6%)]\tLoss: 3.541520\n",
      "Train Epoch: 4 [500/6700 (7%)]\tLoss: 0.144155\n",
      "Train Epoch: 4 [600/6700 (9%)]\tLoss: 0.307609\n",
      "Train Epoch: 4 [700/6700 (10%)]\tLoss: 0.563215\n",
      "Train Epoch: 4 [800/6700 (12%)]\tLoss: 1.201541\n",
      "Train Epoch: 4 [900/6700 (13%)]\tLoss: 0.085290\n",
      "Train Epoch: 4 [1000/6700 (15%)]\tLoss: 0.605560\n",
      "Train Epoch: 4 [1100/6700 (16%)]\tLoss: 0.005555\n",
      "Train Epoch: 4 [1200/6700 (18%)]\tLoss: 0.958083\n",
      "Train Epoch: 4 [1300/6700 (19%)]\tLoss: 0.028115\n",
      "Train Epoch: 4 [1400/6700 (21%)]\tLoss: 0.020745\n",
      "Train Epoch: 4 [1500/6700 (22%)]\tLoss: 0.169650\n",
      "Train Epoch: 4 [1600/6700 (24%)]\tLoss: 0.063988\n",
      "Train Epoch: 4 [1700/6700 (25%)]\tLoss: 0.010327\n",
      "Train Epoch: 4 [1800/6700 (27%)]\tLoss: 0.758232\n",
      "Train Epoch: 4 [1900/6700 (28%)]\tLoss: 0.556571\n",
      "Train Epoch: 4 [2000/6700 (30%)]\tLoss: 5.750257\n",
      "Train Epoch: 4 [2100/6700 (31%)]\tLoss: 0.072989\n",
      "Train Epoch: 4 [2200/6700 (33%)]\tLoss: 0.820367\n",
      "Train Epoch: 4 [2300/6700 (34%)]\tLoss: 0.022961\n",
      "Train Epoch: 4 [2400/6700 (36%)]\tLoss: 0.067664\n",
      "Train Epoch: 4 [2500/6700 (37%)]\tLoss: 0.058243\n",
      "Train Epoch: 4 [2600/6700 (39%)]\tLoss: 0.523858\n",
      "Train Epoch: 4 [2700/6700 (40%)]\tLoss: 0.993830\n",
      "Train Epoch: 4 [2800/6700 (42%)]\tLoss: 0.110341\n",
      "Train Epoch: 4 [2900/6700 (43%)]\tLoss: 0.001735\n",
      "Train Epoch: 4 [3000/6700 (45%)]\tLoss: 0.589572\n",
      "Train Epoch: 4 [3100/6700 (46%)]\tLoss: 0.172618\n",
      "Train Epoch: 4 [3200/6700 (48%)]\tLoss: 0.141329\n",
      "Train Epoch: 4 [3300/6700 (49%)]\tLoss: 2.362944\n",
      "Train Epoch: 4 [3400/6700 (51%)]\tLoss: 0.030215\n",
      "Train Epoch: 4 [3500/6700 (52%)]\tLoss: 3.004770\n",
      "Train Epoch: 4 [3600/6700 (54%)]\tLoss: 2.249798\n",
      "Train Epoch: 4 [3700/6700 (55%)]\tLoss: 0.117656\n",
      "Train Epoch: 4 [3800/6700 (57%)]\tLoss: 0.109968\n",
      "Train Epoch: 4 [3900/6700 (58%)]\tLoss: 0.018662\n",
      "Train Epoch: 4 [4000/6700 (60%)]\tLoss: 1.966531\n",
      "Train Epoch: 4 [4100/6700 (61%)]\tLoss: 0.293176\n",
      "Train Epoch: 4 [4200/6700 (63%)]\tLoss: 0.005170\n",
      "Train Epoch: 4 [4300/6700 (64%)]\tLoss: 0.718929\n",
      "Train Epoch: 4 [4400/6700 (66%)]\tLoss: 0.001733\n",
      "Train Epoch: 4 [4500/6700 (67%)]\tLoss: 1.748412\n",
      "Train Epoch: 4 [4600/6700 (69%)]\tLoss: 1.355690\n",
      "Train Epoch: 4 [4700/6700 (70%)]\tLoss: 0.111316\n",
      "Train Epoch: 4 [4800/6700 (72%)]\tLoss: 2.498370\n",
      "Train Epoch: 4 [4900/6700 (73%)]\tLoss: 0.058445\n",
      "Train Epoch: 4 [5000/6700 (75%)]\tLoss: 1.939748\n",
      "Train Epoch: 4 [5100/6700 (76%)]\tLoss: 0.045329\n",
      "Train Epoch: 4 [5200/6700 (78%)]\tLoss: 1.195357\n",
      "Train Epoch: 4 [5300/6700 (79%)]\tLoss: 0.300032\n",
      "Train Epoch: 4 [5400/6700 (81%)]\tLoss: 0.117830\n",
      "Train Epoch: 4 [5500/6700 (82%)]\tLoss: 2.054397\n",
      "Train Epoch: 4 [5600/6700 (84%)]\tLoss: 2.164398\n",
      "Train Epoch: 4 [5700/6700 (85%)]\tLoss: 2.197716\n",
      "Train Epoch: 4 [5800/6700 (87%)]\tLoss: 1.480918\n",
      "Train Epoch: 4 [5900/6700 (88%)]\tLoss: 0.093946\n",
      "Train Epoch: 4 [6000/6700 (90%)]\tLoss: 0.327579\n",
      "Train Epoch: 4 [6100/6700 (91%)]\tLoss: 0.002716\n",
      "Train Epoch: 4 [6200/6700 (93%)]\tLoss: 0.044386\n",
      "Train Epoch: 4 [6300/6700 (94%)]\tLoss: 0.015502\n",
      "Train Epoch: 4 [6400/6700 (96%)]\tLoss: 0.131538\n",
      "Train Epoch: 4 [6500/6700 (97%)]\tLoss: 0.144825\n",
      "Train Epoch: 4 [6600/6700 (99%)]\tLoss: 0.018936\n",
      "====> Epoch: 4 Average loss: 0.7882\n",
      "Train Epoch: 5 [0/6700 (0%)]\tLoss: 0.160543\n",
      "Train Epoch: 5 [100/6700 (1%)]\tLoss: 0.021540\n",
      "Train Epoch: 5 [200/6700 (3%)]\tLoss: 0.187573\n",
      "Train Epoch: 5 [300/6700 (4%)]\tLoss: 0.106476\n",
      "Train Epoch: 5 [400/6700 (6%)]\tLoss: 3.596336\n",
      "Train Epoch: 5 [500/6700 (7%)]\tLoss: 0.206003\n",
      "Train Epoch: 5 [600/6700 (9%)]\tLoss: 0.164033\n",
      "Train Epoch: 5 [700/6700 (10%)]\tLoss: 0.401043\n",
      "Train Epoch: 5 [800/6700 (12%)]\tLoss: 1.084414\n",
      "Train Epoch: 5 [900/6700 (13%)]\tLoss: 0.098341\n",
      "Train Epoch: 5 [1000/6700 (15%)]\tLoss: 0.638354\n",
      "Train Epoch: 5 [1100/6700 (16%)]\tLoss: 0.000768\n",
      "Train Epoch: 5 [1200/6700 (18%)]\tLoss: 0.048025\n",
      "Train Epoch: 5 [1300/6700 (19%)]\tLoss: 0.021016\n",
      "Train Epoch: 5 [1400/6700 (21%)]\tLoss: 0.011195\n",
      "Train Epoch: 5 [1500/6700 (22%)]\tLoss: 0.152220\n",
      "Train Epoch: 5 [1600/6700 (24%)]\tLoss: 0.514550\n",
      "Train Epoch: 5 [1700/6700 (25%)]\tLoss: 0.004349\n",
      "Train Epoch: 5 [1800/6700 (27%)]\tLoss: 0.037937\n",
      "Train Epoch: 5 [1900/6700 (28%)]\tLoss: 0.596760\n",
      "Train Epoch: 5 [2000/6700 (30%)]\tLoss: 5.335354\n",
      "Train Epoch: 5 [2100/6700 (31%)]\tLoss: 0.055689\n",
      "Train Epoch: 5 [2200/6700 (33%)]\tLoss: 0.651325\n",
      "Train Epoch: 5 [2300/6700 (34%)]\tLoss: 0.015997\n",
      "Train Epoch: 5 [2400/6700 (36%)]\tLoss: 0.084280\n",
      "Train Epoch: 5 [2500/6700 (37%)]\tLoss: 0.053991\n",
      "Train Epoch: 5 [2600/6700 (39%)]\tLoss: 0.163658\n",
      "Train Epoch: 5 [2700/6700 (40%)]\tLoss: 0.537546\n",
      "Train Epoch: 5 [2800/6700 (42%)]\tLoss: 0.075749\n",
      "Train Epoch: 5 [2900/6700 (43%)]\tLoss: 0.000507\n",
      "Train Epoch: 5 [3000/6700 (45%)]\tLoss: 0.462856\n",
      "Train Epoch: 5 [3100/6700 (46%)]\tLoss: 0.114948\n",
      "Train Epoch: 5 [3200/6700 (48%)]\tLoss: 0.167776\n",
      "Train Epoch: 5 [3300/6700 (49%)]\tLoss: 2.327162\n",
      "Train Epoch: 5 [3400/6700 (51%)]\tLoss: 0.028653\n",
      "Train Epoch: 5 [3500/6700 (52%)]\tLoss: 0.000319\n",
      "Train Epoch: 5 [3600/6700 (54%)]\tLoss: 1.967539\n",
      "Train Epoch: 5 [3700/6700 (55%)]\tLoss: 0.105439\n",
      "Train Epoch: 5 [3800/6700 (57%)]\tLoss: 0.060478\n",
      "Train Epoch: 5 [3900/6700 (58%)]\tLoss: 0.008798\n",
      "Train Epoch: 5 [4000/6700 (60%)]\tLoss: 0.515176\n",
      "Train Epoch: 5 [4100/6700 (61%)]\tLoss: 0.400004\n",
      "Train Epoch: 5 [4200/6700 (63%)]\tLoss: 0.004213\n",
      "Train Epoch: 5 [4300/6700 (64%)]\tLoss: 1.329996\n",
      "Train Epoch: 5 [4400/6700 (66%)]\tLoss: 0.001001\n",
      "Train Epoch: 5 [4500/6700 (67%)]\tLoss: 1.391202\n",
      "Train Epoch: 5 [4600/6700 (69%)]\tLoss: 1.446118\n",
      "Train Epoch: 5 [4700/6700 (70%)]\tLoss: 0.115583\n",
      "Train Epoch: 5 [4800/6700 (72%)]\tLoss: 2.747044\n",
      "Train Epoch: 5 [4900/6700 (73%)]\tLoss: 0.030282\n",
      "Train Epoch: 5 [5000/6700 (75%)]\tLoss: 0.808454\n",
      "Train Epoch: 5 [5100/6700 (76%)]\tLoss: 0.021700\n",
      "Train Epoch: 5 [5200/6700 (78%)]\tLoss: 0.581454\n",
      "Train Epoch: 5 [5300/6700 (79%)]\tLoss: 0.369274\n",
      "Train Epoch: 5 [5400/6700 (81%)]\tLoss: 0.112754\n",
      "Train Epoch: 5 [5500/6700 (82%)]\tLoss: 1.235211\n",
      "Train Epoch: 5 [5600/6700 (84%)]\tLoss: 2.122772\n",
      "Train Epoch: 5 [5700/6700 (85%)]\tLoss: 2.509340\n",
      "Train Epoch: 5 [5800/6700 (87%)]\tLoss: 1.457991\n",
      "Train Epoch: 5 [5900/6700 (88%)]\tLoss: 0.111368\n",
      "Train Epoch: 5 [6000/6700 (90%)]\tLoss: 0.262910\n",
      "Train Epoch: 5 [6100/6700 (91%)]\tLoss: 0.001581\n",
      "Train Epoch: 5 [6200/6700 (93%)]\tLoss: 0.029584\n",
      "Train Epoch: 5 [6300/6700 (94%)]\tLoss: 0.013956\n",
      "Train Epoch: 5 [6400/6700 (96%)]\tLoss: 0.092556\n",
      "Train Epoch: 5 [6500/6700 (97%)]\tLoss: 0.141229\n",
      "Train Epoch: 5 [6600/6700 (99%)]\tLoss: 0.021421\n",
      "====> Epoch: 5 Average loss: 0.7067\n",
      "Train Epoch: 6 [0/6700 (0%)]\tLoss: 0.291043\n",
      "Train Epoch: 6 [100/6700 (1%)]\tLoss: 0.015267\n",
      "Train Epoch: 6 [200/6700 (3%)]\tLoss: 0.161388\n",
      "Train Epoch: 6 [300/6700 (4%)]\tLoss: 0.040817\n",
      "Train Epoch: 6 [400/6700 (6%)]\tLoss: 2.897579\n",
      "Train Epoch: 6 [500/6700 (7%)]\tLoss: 0.165037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [600/6700 (9%)]\tLoss: 0.127912\n",
      "Train Epoch: 6 [700/6700 (10%)]\tLoss: 0.546995\n",
      "Train Epoch: 6 [800/6700 (12%)]\tLoss: 0.926126\n",
      "Train Epoch: 6 [900/6700 (13%)]\tLoss: 0.110515\n",
      "Train Epoch: 6 [1000/6700 (15%)]\tLoss: 0.227906\n",
      "Train Epoch: 6 [1100/6700 (16%)]\tLoss: 0.006099\n",
      "Train Epoch: 6 [1200/6700 (18%)]\tLoss: 0.039444\n",
      "Train Epoch: 6 [1300/6700 (19%)]\tLoss: 0.021875\n",
      "Train Epoch: 6 [1400/6700 (21%)]\tLoss: 0.009246\n",
      "Train Epoch: 6 [1500/6700 (22%)]\tLoss: 0.129961\n",
      "Train Epoch: 6 [1600/6700 (24%)]\tLoss: 0.048303\n",
      "Train Epoch: 6 [1700/6700 (25%)]\tLoss: 0.002262\n",
      "Train Epoch: 6 [1800/6700 (27%)]\tLoss: 0.003417\n",
      "Train Epoch: 6 [1900/6700 (28%)]\tLoss: 0.344847\n",
      "Train Epoch: 6 [2000/6700 (30%)]\tLoss: 5.736419\n",
      "Train Epoch: 6 [2100/6700 (31%)]\tLoss: 0.037935\n",
      "Train Epoch: 6 [2200/6700 (33%)]\tLoss: 0.534989\n",
      "Train Epoch: 6 [2300/6700 (34%)]\tLoss: 0.008634\n",
      "Train Epoch: 6 [2400/6700 (36%)]\tLoss: 0.104421\n",
      "Train Epoch: 6 [2500/6700 (37%)]\tLoss: 0.044141\n",
      "Train Epoch: 6 [2600/6700 (39%)]\tLoss: 0.146316\n",
      "Train Epoch: 6 [2700/6700 (40%)]\tLoss: 0.483739\n",
      "Train Epoch: 6 [2800/6700 (42%)]\tLoss: 0.075757\n",
      "Train Epoch: 6 [2900/6700 (43%)]\tLoss: 0.000252\n",
      "Train Epoch: 6 [3000/6700 (45%)]\tLoss: 0.694383\n",
      "Train Epoch: 6 [3100/6700 (46%)]\tLoss: 0.068381\n",
      "Train Epoch: 6 [3200/6700 (48%)]\tLoss: 0.172874\n",
      "Train Epoch: 6 [3300/6700 (49%)]\tLoss: 2.083364\n",
      "Train Epoch: 6 [3400/6700 (51%)]\tLoss: 0.023712\n",
      "Train Epoch: 6 [3500/6700 (52%)]\tLoss: 0.034413\n",
      "Train Epoch: 6 [3600/6700 (54%)]\tLoss: 1.456640\n",
      "Train Epoch: 6 [3700/6700 (55%)]\tLoss: 0.098876\n",
      "Train Epoch: 6 [3800/6700 (57%)]\tLoss: 0.064942\n",
      "Train Epoch: 6 [3900/6700 (58%)]\tLoss: 0.007141\n",
      "Train Epoch: 6 [4000/6700 (60%)]\tLoss: 0.898282\n",
      "Train Epoch: 6 [4100/6700 (61%)]\tLoss: 0.559521\n",
      "Train Epoch: 6 [4200/6700 (63%)]\tLoss: 0.003491\n",
      "Train Epoch: 6 [4300/6700 (64%)]\tLoss: 0.887093\n",
      "Train Epoch: 6 [4400/6700 (66%)]\tLoss: 0.000833\n",
      "Train Epoch: 6 [4500/6700 (67%)]\tLoss: 0.897451\n",
      "Train Epoch: 6 [4600/6700 (69%)]\tLoss: 0.978491\n",
      "Train Epoch: 6 [4700/6700 (70%)]\tLoss: 0.090611\n",
      "Train Epoch: 6 [4800/6700 (72%)]\tLoss: 3.604882\n",
      "Train Epoch: 6 [4900/6700 (73%)]\tLoss: 0.026640\n",
      "Train Epoch: 6 [5000/6700 (75%)]\tLoss: 0.824778\n",
      "Train Epoch: 6 [5100/6700 (76%)]\tLoss: 0.020064\n",
      "Train Epoch: 6 [5200/6700 (78%)]\tLoss: 0.432798\n",
      "Train Epoch: 6 [5300/6700 (79%)]\tLoss: 0.338519\n",
      "Train Epoch: 6 [5400/6700 (81%)]\tLoss: 0.113893\n",
      "Train Epoch: 6 [5500/6700 (82%)]\tLoss: 4.955598\n",
      "Train Epoch: 6 [5600/6700 (84%)]\tLoss: 1.149675\n",
      "Train Epoch: 6 [5700/6700 (85%)]\tLoss: 2.275938\n",
      "Train Epoch: 6 [5800/6700 (87%)]\tLoss: 1.287729\n",
      "Train Epoch: 6 [5900/6700 (88%)]\tLoss: 0.275901\n",
      "Train Epoch: 6 [6000/6700 (90%)]\tLoss: 0.099268\n",
      "Train Epoch: 6 [6100/6700 (91%)]\tLoss: 0.000892\n",
      "Train Epoch: 6 [6200/6700 (93%)]\tLoss: 0.019793\n",
      "Train Epoch: 6 [6300/6700 (94%)]\tLoss: 0.008457\n",
      "Train Epoch: 6 [6400/6700 (96%)]\tLoss: 0.075286\n",
      "Train Epoch: 6 [6500/6700 (97%)]\tLoss: 0.173531\n",
      "Train Epoch: 6 [6600/6700 (99%)]\tLoss: 0.013792\n",
      "====> Epoch: 6 Average loss: 0.6400\n",
      "Train Epoch: 7 [0/6700 (0%)]\tLoss: 0.181077\n",
      "Train Epoch: 7 [100/6700 (1%)]\tLoss: 0.010100\n",
      "Train Epoch: 7 [200/6700 (3%)]\tLoss: 0.106518\n",
      "Train Epoch: 7 [300/6700 (4%)]\tLoss: 0.030418\n",
      "Train Epoch: 7 [400/6700 (6%)]\tLoss: 2.480155\n",
      "Train Epoch: 7 [500/6700 (7%)]\tLoss: 0.404292\n",
      "Train Epoch: 7 [600/6700 (9%)]\tLoss: 0.126874\n",
      "Train Epoch: 7 [700/6700 (10%)]\tLoss: 0.649425\n",
      "Train Epoch: 7 [800/6700 (12%)]\tLoss: 0.830536\n",
      "Train Epoch: 7 [900/6700 (13%)]\tLoss: 0.086861\n",
      "Train Epoch: 7 [1000/6700 (15%)]\tLoss: 0.334438\n",
      "Train Epoch: 7 [1100/6700 (16%)]\tLoss: 3.143661\n",
      "Train Epoch: 7 [1200/6700 (18%)]\tLoss: 1.535386\n",
      "Train Epoch: 7 [1300/6700 (19%)]\tLoss: 0.011335\n",
      "Train Epoch: 7 [1400/6700 (21%)]\tLoss: 0.003755\n",
      "Train Epoch: 7 [1500/6700 (22%)]\tLoss: 0.115712\n",
      "Train Epoch: 7 [1600/6700 (24%)]\tLoss: 0.000124\n",
      "Train Epoch: 7 [1700/6700 (25%)]\tLoss: 0.000667\n",
      "Train Epoch: 7 [1800/6700 (27%)]\tLoss: 0.007245\n",
      "Train Epoch: 7 [1900/6700 (28%)]\tLoss: 0.599867\n",
      "Train Epoch: 7 [2000/6700 (30%)]\tLoss: 5.763762\n",
      "Train Epoch: 7 [2100/6700 (31%)]\tLoss: 0.063593\n",
      "Train Epoch: 7 [2200/6700 (33%)]\tLoss: 0.367483\n",
      "Train Epoch: 7 [2300/6700 (34%)]\tLoss: 0.003982\n",
      "Train Epoch: 7 [2400/6700 (36%)]\tLoss: 0.098842\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
