{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import predict\n",
    "import time as tm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.datasets import make_classification\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# from w2v import *\n",
    "# from embedding_layer import embedding_layer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.io as sio\n",
    "from scipy import sparse\n",
    "import argparse\n",
    "from visdom import Visdom\n",
    "from sklearn.externals import joblib \n",
    "# from futils import *\n",
    "# from loss import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Data\n",
    "dictSize = 225\n",
    "(X, y) = utils.loadData( \"train\", dictSize = dictSize )\n",
    "X = scipy.sparse.csr_matrix.toarray(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/multi-class-classification/47565\n",
    "# https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            outp = self.forward(x)\n",
    "            return F.softmax(outp)\n",
    "# add softmax layer: used for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model declared\n",
    "model = NeuralNet(225 , 1000, 51)  \n",
    "# earlier hidden layers- 1000 \n",
    "# 1 - poor, 2- ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "model_opt = optim.SGD(model.parameters(), lr = 0.02)\n",
    "\n",
    "train_set_X = Variable(torch.from_numpy(X_train)).float()\n",
    "train_set_y = Variable(torch.LongTensor(y_train)).long()\n",
    "test_set_X = Variable(torch.from_numpy(X_test)).float()\n",
    "test_set_y = Variable(torch.LongTensor(y_test)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "epochs = 50\n",
    "for epochs in range(epochs):\n",
    "    model_opt.zero_grad()\n",
    "    out = model(train_set_X)\n",
    "    loss = loss_function(out, train_set_y)\n",
    "    loss.backward()\n",
    "    model_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "# for i in range(3299):\n",
    "#     ans_max,ind = torch.max(ans[i],0)\n",
    "#     print (test_set_y[i].numpy() - ind.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  2  4  1  7]\n",
      " [ 2  1  3  4  9]\n",
      " [ 3  2  1  4 10]\n",
      " ...\n",
      " [ 2  1  3  4  9]\n",
      " [ 2  1  3  4  9]\n",
      " [ 3  2  1  4 10]]\n",
      "[3. 2. 3. ... 9. 4. 3.]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "print (y_pred)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.314 prec@3: 0.614 prec@5: 0.752\n",
      "mprec@1: 2.968e-02 mprec@3: 7.338e-02 mprec@5: 1.294e-01\n",
      "prec matrix [0.31393939 0.50333333 0.61363636 0.69363636 0.75151515]\n",
      "mprec matrix [0.02968053 0.05729217 0.07338063 0.08510638 0.12942324]\n"
     ]
    }
   ],
   "source": [
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 \n",
    "# same model diff train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_latent_X = data_utils.TensorDataset(train_set_X, train_set_y)\n",
    "te_latent_X = data_utils.TensorDataset(test_set_X,  test_set_y)\n",
    "train_loader_X = torch.utils.data.DataLoader(dataset=tr_latent_X)\n",
    "test_loader_X = torch.utils.data.DataLoader(dataset=te_latent_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data,label) in enumerate(train_loader_X):\n",
    "\n",
    "        model_opt.zero_grad()\n",
    "\n",
    "        out = model(data)\n",
    "        loss = loss_function(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        model_opt.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_X.dataset),\n",
    "                100. * batch_idx / len(train_loader_X), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader_X.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6700 (0%)]\tLoss: 2.854280\n",
      "Train Epoch: 1 [100/6700 (1%)]\tLoss: 2.127586\n",
      "Train Epoch: 1 [200/6700 (3%)]\tLoss: 0.779639\n",
      "Train Epoch: 1 [300/6700 (4%)]\tLoss: 4.261716\n",
      "Train Epoch: 1 [400/6700 (6%)]\tLoss: 3.735106\n",
      "Train Epoch: 1 [500/6700 (7%)]\tLoss: 1.373702\n",
      "Train Epoch: 1 [600/6700 (9%)]\tLoss: 1.796077\n",
      "Train Epoch: 1 [700/6700 (10%)]\tLoss: 0.799777\n",
      "Train Epoch: 1 [800/6700 (12%)]\tLoss: 2.275002\n",
      "Train Epoch: 1 [900/6700 (13%)]\tLoss: 0.553542\n",
      "Train Epoch: 1 [1000/6700 (15%)]\tLoss: 2.927905\n",
      "Train Epoch: 1 [1100/6700 (16%)]\tLoss: 0.007938\n",
      "Train Epoch: 1 [1200/6700 (18%)]\tLoss: 8.221107\n",
      "Train Epoch: 1 [1300/6700 (19%)]\tLoss: 0.170846\n",
      "Train Epoch: 1 [1400/6700 (21%)]\tLoss: 1.714790\n",
      "Train Epoch: 1 [1500/6700 (22%)]\tLoss: 0.666515\n",
      "Train Epoch: 1 [1600/6700 (24%)]\tLoss: 1.358858\n",
      "Train Epoch: 1 [1700/6700 (25%)]\tLoss: 0.041263\n",
      "Train Epoch: 1 [1800/6700 (27%)]\tLoss: 0.881191\n",
      "Train Epoch: 1 [1900/6700 (28%)]\tLoss: 1.189125\n",
      "Train Epoch: 1 [2000/6700 (30%)]\tLoss: 4.536890\n",
      "Train Epoch: 1 [2100/6700 (31%)]\tLoss: 0.840930\n",
      "Train Epoch: 1 [2200/6700 (33%)]\tLoss: 1.710115\n",
      "Train Epoch: 1 [2300/6700 (34%)]\tLoss: 0.062518\n",
      "Train Epoch: 1 [2400/6700 (36%)]\tLoss: 1.692596\n",
      "Train Epoch: 1 [2500/6700 (37%)]\tLoss: 0.126120\n",
      "Train Epoch: 1 [2600/6700 (39%)]\tLoss: 1.171261\n",
      "Train Epoch: 1 [2700/6700 (40%)]\tLoss: 5.115711\n",
      "Train Epoch: 1 [2800/6700 (42%)]\tLoss: 1.099595\n",
      "Train Epoch: 1 [2900/6700 (43%)]\tLoss: 0.871613\n",
      "Train Epoch: 1 [3000/6700 (45%)]\tLoss: 1.211437\n",
      "Train Epoch: 1 [3100/6700 (46%)]\tLoss: 1.369971\n",
      "Train Epoch: 1 [3200/6700 (48%)]\tLoss: 0.149597\n",
      "Train Epoch: 1 [3300/6700 (49%)]\tLoss: 4.014397\n",
      "Train Epoch: 1 [3400/6700 (51%)]\tLoss: 0.145292\n",
      "Train Epoch: 1 [3500/6700 (52%)]\tLoss: 0.663467\n",
      "Train Epoch: 1 [3600/6700 (54%)]\tLoss: 1.870785\n",
      "Train Epoch: 1 [3700/6700 (55%)]\tLoss: 0.545822\n",
      "Train Epoch: 1 [3800/6700 (57%)]\tLoss: 0.456351\n",
      "Train Epoch: 1 [3900/6700 (58%)]\tLoss: 0.330432\n",
      "Train Epoch: 1 [4000/6700 (60%)]\tLoss: 6.193199\n",
      "Train Epoch: 1 [4100/6700 (61%)]\tLoss: 0.213120\n",
      "Train Epoch: 1 [4200/6700 (63%)]\tLoss: 0.031421\n",
      "Train Epoch: 1 [4300/6700 (64%)]\tLoss: 0.968627\n",
      "Train Epoch: 1 [4400/6700 (66%)]\tLoss: 0.827891\n",
      "Train Epoch: 1 [4500/6700 (67%)]\tLoss: 2.089381\n",
      "Train Epoch: 1 [4600/6700 (69%)]\tLoss: 2.875101\n",
      "Train Epoch: 1 [4700/6700 (70%)]\tLoss: 0.702693\n",
      "Train Epoch: 1 [4800/6700 (72%)]\tLoss: 2.145113\n",
      "Train Epoch: 1 [4900/6700 (73%)]\tLoss: 3.427392\n",
      "Train Epoch: 1 [5000/6700 (75%)]\tLoss: 3.351680\n",
      "Train Epoch: 1 [5100/6700 (76%)]\tLoss: 0.699721\n",
      "Train Epoch: 1 [5200/6700 (78%)]\tLoss: 1.925920\n",
      "Train Epoch: 1 [5300/6700 (79%)]\tLoss: 0.919481\n",
      "Train Epoch: 1 [5400/6700 (81%)]\tLoss: 0.128469\n",
      "Train Epoch: 1 [5500/6700 (82%)]\tLoss: 3.952187\n",
      "Train Epoch: 1 [5600/6700 (84%)]\tLoss: 6.162556\n",
      "Train Epoch: 1 [5700/6700 (85%)]\tLoss: 3.337572\n",
      "Train Epoch: 1 [5800/6700 (87%)]\tLoss: 1.997642\n",
      "Train Epoch: 1 [5900/6700 (88%)]\tLoss: 0.510477\n",
      "Train Epoch: 1 [6000/6700 (90%)]\tLoss: 0.492505\n",
      "Train Epoch: 1 [6100/6700 (91%)]\tLoss: 0.069325\n",
      "Train Epoch: 1 [6200/6700 (93%)]\tLoss: 0.378018\n",
      "Train Epoch: 1 [6300/6700 (94%)]\tLoss: 0.082598\n",
      "Train Epoch: 1 [6400/6700 (96%)]\tLoss: 2.709408\n",
      "Train Epoch: 1 [6500/6700 (97%)]\tLoss: 0.242798\n",
      "Train Epoch: 1 [6600/6700 (99%)]\tLoss: 0.357947\n",
      "====> Epoch: 1 Average loss: 1.6501\n",
      "Train Epoch: 2 [0/6700 (0%)]\tLoss: 0.647992\n",
      "Train Epoch: 2 [100/6700 (1%)]\tLoss: 0.152965\n",
      "Train Epoch: 2 [200/6700 (3%)]\tLoss: 0.176920\n",
      "Train Epoch: 2 [300/6700 (4%)]\tLoss: 0.706737\n",
      "Train Epoch: 2 [400/6700 (6%)]\tLoss: 3.466714\n",
      "Train Epoch: 2 [500/6700 (7%)]\tLoss: 0.220941\n",
      "Train Epoch: 2 [600/6700 (9%)]\tLoss: 1.056107\n",
      "Train Epoch: 2 [700/6700 (10%)]\tLoss: 0.489006\n",
      "Train Epoch: 2 [800/6700 (12%)]\tLoss: 1.523707\n",
      "Train Epoch: 2 [900/6700 (13%)]\tLoss: 0.073501\n",
      "Train Epoch: 2 [1000/6700 (15%)]\tLoss: 1.719626\n",
      "Train Epoch: 2 [1100/6700 (16%)]\tLoss: 3.181440\n",
      "Train Epoch: 2 [1200/6700 (18%)]\tLoss: 7.117931\n",
      "Train Epoch: 2 [1300/6700 (19%)]\tLoss: 0.050894\n",
      "Train Epoch: 2 [1400/6700 (21%)]\tLoss: 0.099282\n",
      "Train Epoch: 2 [1500/6700 (22%)]\tLoss: 0.232893\n",
      "Train Epoch: 2 [1600/6700 (24%)]\tLoss: 0.270244\n",
      "Train Epoch: 2 [1700/6700 (25%)]\tLoss: 0.025209\n",
      "Train Epoch: 2 [1800/6700 (27%)]\tLoss: 0.561432\n",
      "Train Epoch: 2 [1900/6700 (28%)]\tLoss: 0.921224\n",
      "Train Epoch: 2 [2000/6700 (30%)]\tLoss: 5.511085\n",
      "Train Epoch: 2 [2100/6700 (31%)]\tLoss: 0.421144\n",
      "Train Epoch: 2 [2200/6700 (33%)]\tLoss: 1.779433\n",
      "Train Epoch: 2 [2300/6700 (34%)]\tLoss: 0.051312\n",
      "Train Epoch: 2 [2400/6700 (36%)]\tLoss: 0.237149\n",
      "Train Epoch: 2 [2500/6700 (37%)]\tLoss: 0.046263\n",
      "Train Epoch: 2 [2600/6700 (39%)]\tLoss: 0.821921\n",
      "Train Epoch: 2 [2700/6700 (40%)]\tLoss: 2.778877\n",
      "Train Epoch: 2 [2800/6700 (42%)]\tLoss: 0.333829\n",
      "Train Epoch: 2 [2900/6700 (43%)]\tLoss: 0.054054\n",
      "Train Epoch: 2 [3000/6700 (45%)]\tLoss: 0.668843\n",
      "Train Epoch: 2 [3100/6700 (46%)]\tLoss: 0.765051\n",
      "Train Epoch: 2 [3200/6700 (48%)]\tLoss: 0.127699\n",
      "Train Epoch: 2 [3300/6700 (49%)]\tLoss: 2.872908\n",
      "Train Epoch: 2 [3400/6700 (51%)]\tLoss: 0.032908\n",
      "Train Epoch: 2 [3500/6700 (52%)]\tLoss: 0.040209\n",
      "Train Epoch: 2 [3600/6700 (54%)]\tLoss: 1.700993\n",
      "Train Epoch: 2 [3700/6700 (55%)]\tLoss: 0.171540\n",
      "Train Epoch: 2 [3800/6700 (57%)]\tLoss: 0.149348\n",
      "Train Epoch: 2 [3900/6700 (58%)]\tLoss: 0.065281\n",
      "Train Epoch: 2 [4000/6700 (60%)]\tLoss: 6.634068\n",
      "Train Epoch: 2 [4100/6700 (61%)]\tLoss: 0.173996\n",
      "Train Epoch: 2 [4200/6700 (63%)]\tLoss: 0.010068\n",
      "Train Epoch: 2 [4300/6700 (64%)]\tLoss: 1.191321\n",
      "Train Epoch: 2 [4400/6700 (66%)]\tLoss: 0.014131\n",
      "Train Epoch: 2 [4500/6700 (67%)]\tLoss: 2.170988\n",
      "Train Epoch: 2 [4600/6700 (69%)]\tLoss: 2.397587\n",
      "Train Epoch: 2 [4700/6700 (70%)]\tLoss: 0.318486\n",
      "Train Epoch: 2 [4800/6700 (72%)]\tLoss: 2.147949\n",
      "Train Epoch: 2 [4900/6700 (73%)]\tLoss: 1.311871\n",
      "Train Epoch: 2 [5000/6700 (75%)]\tLoss: 2.477401\n",
      "Train Epoch: 2 [5100/6700 (76%)]\tLoss: 0.251169\n",
      "Train Epoch: 2 [5200/6700 (78%)]\tLoss: 1.842445\n",
      "Train Epoch: 2 [5300/6700 (79%)]\tLoss: 0.741384\n",
      "Train Epoch: 2 [5400/6700 (81%)]\tLoss: 0.077835\n",
      "Train Epoch: 2 [5500/6700 (82%)]\tLoss: 3.098050\n",
      "Train Epoch: 2 [5600/6700 (84%)]\tLoss: 4.557931\n",
      "Train Epoch: 2 [5700/6700 (85%)]\tLoss: 2.861485\n",
      "Train Epoch: 2 [5800/6700 (87%)]\tLoss: 1.494783\n",
      "Train Epoch: 2 [5900/6700 (88%)]\tLoss: 0.220343\n",
      "Train Epoch: 2 [6000/6700 (90%)]\tLoss: 0.183142\n",
      "Train Epoch: 2 [6100/6700 (91%)]\tLoss: 0.015163\n",
      "Train Epoch: 2 [6200/6700 (93%)]\tLoss: 0.135118\n",
      "Train Epoch: 2 [6300/6700 (94%)]\tLoss: 0.041607\n",
      "Train Epoch: 2 [6400/6700 (96%)]\tLoss: 0.597684\n",
      "Train Epoch: 2 [6500/6700 (97%)]\tLoss: 0.208127\n",
      "Train Epoch: 2 [6600/6700 (99%)]\tLoss: 0.101975\n",
      "====> Epoch: 2 Average loss: 1.1123\n",
      "Train Epoch: 3 [0/6700 (0%)]\tLoss: 0.404258\n",
      "Train Epoch: 3 [100/6700 (1%)]\tLoss: 0.061440\n",
      "Train Epoch: 3 [200/6700 (3%)]\tLoss: 0.142631\n",
      "Train Epoch: 3 [300/6700 (4%)]\tLoss: 0.309567\n",
      "Train Epoch: 3 [400/6700 (6%)]\tLoss: 3.520515\n",
      "Train Epoch: 3 [500/6700 (7%)]\tLoss: 0.125733\n",
      "Train Epoch: 3 [600/6700 (9%)]\tLoss: 0.498759\n",
      "Train Epoch: 3 [700/6700 (10%)]\tLoss: 0.434492\n",
      "Train Epoch: 3 [800/6700 (12%)]\tLoss: 1.473970\n",
      "Train Epoch: 3 [900/6700 (13%)]\tLoss: 0.047222\n",
      "Train Epoch: 3 [1000/6700 (15%)]\tLoss: 1.523413\n",
      "Train Epoch: 3 [1100/6700 (16%)]\tLoss: 0.231419\n",
      "Train Epoch: 3 [1200/6700 (18%)]\tLoss: 3.916740\n",
      "Train Epoch: 3 [1300/6700 (19%)]\tLoss: 0.048053\n",
      "Train Epoch: 3 [1400/6700 (21%)]\tLoss: 0.036708\n",
      "Train Epoch: 3 [1500/6700 (22%)]\tLoss: 0.173881\n",
      "Train Epoch: 3 [1600/6700 (24%)]\tLoss: 1.242796\n",
      "Train Epoch: 3 [1700/6700 (25%)]\tLoss: 0.004725\n",
      "Train Epoch: 3 [1800/6700 (27%)]\tLoss: 0.504806\n",
      "Train Epoch: 3 [1900/6700 (28%)]\tLoss: 1.192604\n",
      "Train Epoch: 3 [2000/6700 (30%)]\tLoss: 5.887111\n",
      "Train Epoch: 3 [2100/6700 (31%)]\tLoss: 0.145785\n",
      "Train Epoch: 3 [2200/6700 (33%)]\tLoss: 1.129056\n",
      "Train Epoch: 3 [2300/6700 (34%)]\tLoss: 0.029706\n",
      "Train Epoch: 3 [2400/6700 (36%)]\tLoss: 0.116819\n",
      "Train Epoch: 3 [2500/6700 (37%)]\tLoss: 0.054816\n",
      "Train Epoch: 3 [2600/6700 (39%)]\tLoss: 0.526635\n",
      "Train Epoch: 3 [2700/6700 (40%)]\tLoss: 1.416759\n",
      "Train Epoch: 3 [2800/6700 (42%)]\tLoss: 0.094073\n",
      "Train Epoch: 3 [2900/6700 (43%)]\tLoss: 0.005792\n",
      "Train Epoch: 3 [3000/6700 (45%)]\tLoss: 0.566755\n",
      "Train Epoch: 3 [3100/6700 (46%)]\tLoss: 0.297084\n",
      "Train Epoch: 3 [3200/6700 (48%)]\tLoss: 0.137428\n",
      "Train Epoch: 3 [3300/6700 (49%)]\tLoss: 2.739563\n",
      "Train Epoch: 3 [3400/6700 (51%)]\tLoss: 0.041479\n",
      "Train Epoch: 3 [3500/6700 (52%)]\tLoss: 1.564184\n",
      "Train Epoch: 3 [3600/6700 (54%)]\tLoss: 1.963746\n",
      "Train Epoch: 3 [3700/6700 (55%)]\tLoss: 0.113508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [3800/6700 (57%)]\tLoss: 0.042151\n",
      "Train Epoch: 3 [3900/6700 (58%)]\tLoss: 0.048629\n",
      "Train Epoch: 3 [4000/6700 (60%)]\tLoss: 4.288632\n",
      "Train Epoch: 3 [4100/6700 (61%)]\tLoss: 0.258256\n",
      "Train Epoch: 3 [4200/6700 (63%)]\tLoss: 0.007191\n",
      "Train Epoch: 3 [4300/6700 (64%)]\tLoss: 0.958228\n",
      "Train Epoch: 3 [4400/6700 (66%)]\tLoss: 0.000575\n",
      "Train Epoch: 3 [4500/6700 (67%)]\tLoss: 2.134486\n",
      "Train Epoch: 3 [4600/6700 (69%)]\tLoss: 2.114346\n",
      "Train Epoch: 3 [4700/6700 (70%)]\tLoss: 0.196387\n",
      "Train Epoch: 3 [4800/6700 (72%)]\tLoss: 2.319604\n",
      "Train Epoch: 3 [4900/6700 (73%)]\tLoss: 0.394407\n",
      "Train Epoch: 3 [5000/6700 (75%)]\tLoss: 1.637612\n",
      "Train Epoch: 3 [5100/6700 (76%)]\tLoss: 0.151898\n",
      "Train Epoch: 3 [5200/6700 (78%)]\tLoss: 1.353289\n",
      "Train Epoch: 3 [5300/6700 (79%)]\tLoss: 0.622690\n",
      "Train Epoch: 3 [5400/6700 (81%)]\tLoss: 0.124146\n",
      "Train Epoch: 3 [5500/6700 (82%)]\tLoss: 2.925913\n",
      "Train Epoch: 3 [5600/6700 (84%)]\tLoss: 2.762436\n",
      "Train Epoch: 3 [5700/6700 (85%)]\tLoss: 2.358912\n",
      "Train Epoch: 3 [5800/6700 (87%)]\tLoss: 1.407470\n",
      "Train Epoch: 3 [5900/6700 (88%)]\tLoss: 0.077015\n",
      "Train Epoch: 3 [6000/6700 (90%)]\tLoss: 0.108318\n",
      "Train Epoch: 3 [6100/6700 (91%)]\tLoss: 0.004597\n",
      "Train Epoch: 3 [6200/6700 (93%)]\tLoss: 0.067413\n",
      "Train Epoch: 3 [6300/6700 (94%)]\tLoss: 0.037800\n",
      "Train Epoch: 3 [6400/6700 (96%)]\tLoss: 0.192875\n",
      "Train Epoch: 3 [6500/6700 (97%)]\tLoss: 0.158225\n",
      "Train Epoch: 3 [6600/6700 (99%)]\tLoss: 0.040858\n",
      "====> Epoch: 3 Average loss: 0.9088\n",
      "Train Epoch: 4 [0/6700 (0%)]\tLoss: 0.192890\n",
      "Train Epoch: 4 [100/6700 (1%)]\tLoss: 0.033533\n",
      "Train Epoch: 4 [200/6700 (3%)]\tLoss: 0.168103\n",
      "Train Epoch: 4 [300/6700 (4%)]\tLoss: 0.211785\n",
      "Train Epoch: 4 [400/6700 (6%)]\tLoss: 3.312735\n",
      "Train Epoch: 4 [500/6700 (7%)]\tLoss: 0.145387\n",
      "Train Epoch: 4 [600/6700 (9%)]\tLoss: 0.302018\n",
      "Train Epoch: 4 [700/6700 (10%)]\tLoss: 0.518648\n",
      "Train Epoch: 4 [800/6700 (12%)]\tLoss: 1.229703\n",
      "Train Epoch: 4 [900/6700 (13%)]\tLoss: 0.078260\n",
      "Train Epoch: 4 [1000/6700 (15%)]\tLoss: 1.551551\n",
      "Train Epoch: 4 [1100/6700 (16%)]\tLoss: 0.024835\n",
      "Train Epoch: 4 [1200/6700 (18%)]\tLoss: 0.917445\n",
      "Train Epoch: 4 [1300/6700 (19%)]\tLoss: 0.027726\n",
      "Train Epoch: 4 [1400/6700 (21%)]\tLoss: 0.018283\n",
      "Train Epoch: 4 [1500/6700 (22%)]\tLoss: 0.150177\n",
      "Train Epoch: 4 [1600/6700 (24%)]\tLoss: 0.388994\n",
      "Train Epoch: 4 [1700/6700 (25%)]\tLoss: 0.010578\n",
      "Train Epoch: 4 [1800/6700 (27%)]\tLoss: 0.183034\n",
      "Train Epoch: 4 [1900/6700 (28%)]\tLoss: 0.692844\n",
      "Train Epoch: 4 [2000/6700 (30%)]\tLoss: 6.053277\n",
      "Train Epoch: 4 [2100/6700 (31%)]\tLoss: 0.073933\n",
      "Train Epoch: 4 [2200/6700 (33%)]\tLoss: 1.346615\n",
      "Train Epoch: 4 [2300/6700 (34%)]\tLoss: 0.021404\n",
      "Train Epoch: 4 [2400/6700 (36%)]\tLoss: 0.083119\n",
      "Train Epoch: 4 [2500/6700 (37%)]\tLoss: 0.067680\n",
      "Train Epoch: 4 [2600/6700 (39%)]\tLoss: 0.339100\n",
      "Train Epoch: 4 [2700/6700 (40%)]\tLoss: 0.928221\n",
      "Train Epoch: 4 [2800/6700 (42%)]\tLoss: 0.118837\n",
      "Train Epoch: 4 [2900/6700 (43%)]\tLoss: 0.002523\n",
      "Train Epoch: 4 [3000/6700 (45%)]\tLoss: 0.690234\n",
      "Train Epoch: 4 [3100/6700 (46%)]\tLoss: 0.193925\n",
      "Train Epoch: 4 [3200/6700 (48%)]\tLoss: 0.140073\n",
      "Train Epoch: 4 [3300/6700 (49%)]\tLoss: 2.360635\n",
      "Train Epoch: 4 [3400/6700 (51%)]\tLoss: 0.032455\n",
      "Train Epoch: 4 [3500/6700 (52%)]\tLoss: 1.244053\n",
      "Train Epoch: 4 [3600/6700 (54%)]\tLoss: 2.670191\n",
      "Train Epoch: 4 [3700/6700 (55%)]\tLoss: 0.106288\n",
      "Train Epoch: 4 [3800/6700 (57%)]\tLoss: 0.039373\n",
      "Train Epoch: 4 [3900/6700 (58%)]\tLoss: 0.028331\n",
      "Train Epoch: 4 [4000/6700 (60%)]\tLoss: 2.610952\n",
      "Train Epoch: 4 [4100/6700 (61%)]\tLoss: 0.320480\n",
      "Train Epoch: 4 [4200/6700 (63%)]\tLoss: 0.003424\n",
      "Train Epoch: 4 [4300/6700 (64%)]\tLoss: 0.580645\n",
      "Train Epoch: 4 [4400/6700 (66%)]\tLoss: 0.000688\n",
      "Train Epoch: 4 [4500/6700 (67%)]\tLoss: 1.660425\n",
      "Train Epoch: 4 [4600/6700 (69%)]\tLoss: 1.461280\n",
      "Train Epoch: 4 [4700/6700 (70%)]\tLoss: 0.101246\n",
      "Train Epoch: 4 [4800/6700 (72%)]\tLoss: 2.643058\n",
      "Train Epoch: 4 [4900/6700 (73%)]\tLoss: 0.090875\n",
      "Train Epoch: 4 [5000/6700 (75%)]\tLoss: 1.051537\n",
      "Train Epoch: 4 [5100/6700 (76%)]\tLoss: 0.091203\n",
      "Train Epoch: 4 [5200/6700 (78%)]\tLoss: 0.945413\n",
      "Train Epoch: 4 [5300/6700 (79%)]\tLoss: 0.520741\n",
      "Train Epoch: 4 [5400/6700 (81%)]\tLoss: 0.170167\n",
      "Train Epoch: 4 [5500/6700 (82%)]\tLoss: 3.023252\n",
      "Train Epoch: 4 [5600/6700 (84%)]\tLoss: 2.333809\n",
      "Train Epoch: 4 [5700/6700 (85%)]\tLoss: 2.523880\n",
      "Train Epoch: 4 [5800/6700 (87%)]\tLoss: 1.306579\n",
      "Train Epoch: 4 [5900/6700 (88%)]\tLoss: 0.098202\n",
      "Train Epoch: 4 [6000/6700 (90%)]\tLoss: 0.292739\n",
      "Train Epoch: 4 [6100/6700 (91%)]\tLoss: 0.002501\n",
      "Train Epoch: 4 [6200/6700 (93%)]\tLoss: 0.074760\n",
      "Train Epoch: 4 [6300/6700 (94%)]\tLoss: 0.023959\n",
      "Train Epoch: 4 [6400/6700 (96%)]\tLoss: 0.103951\n",
      "Train Epoch: 4 [6500/6700 (97%)]\tLoss: 0.171331\n",
      "Train Epoch: 4 [6600/6700 (99%)]\tLoss: 0.025752\n",
      "====> Epoch: 4 Average loss: 0.7857\n",
      "Train Epoch: 5 [0/6700 (0%)]\tLoss: 0.185654\n",
      "Train Epoch: 5 [100/6700 (1%)]\tLoss: 0.022279\n",
      "Train Epoch: 5 [200/6700 (3%)]\tLoss: 0.123099\n",
      "Train Epoch: 5 [300/6700 (4%)]\tLoss: 0.104231\n",
      "Train Epoch: 5 [400/6700 (6%)]\tLoss: 2.942341\n",
      "Train Epoch: 5 [500/6700 (7%)]\tLoss: 0.130807\n",
      "Train Epoch: 5 [600/6700 (9%)]\tLoss: 0.225232\n",
      "Train Epoch: 5 [700/6700 (10%)]\tLoss: 0.550464\n",
      "Train Epoch: 5 [800/6700 (12%)]\tLoss: 1.168722\n",
      "Train Epoch: 5 [900/6700 (13%)]\tLoss: 0.071716\n",
      "Train Epoch: 5 [1000/6700 (15%)]\tLoss: 1.799757\n",
      "Train Epoch: 5 [1100/6700 (16%)]\tLoss: 0.044298\n",
      "Train Epoch: 5 [1200/6700 (18%)]\tLoss: 0.154633\n",
      "Train Epoch: 5 [1300/6700 (19%)]\tLoss: 0.021421\n",
      "Train Epoch: 5 [1400/6700 (21%)]\tLoss: 0.013186\n",
      "Train Epoch: 5 [1500/6700 (22%)]\tLoss: 0.134767\n",
      "Train Epoch: 5 [1600/6700 (24%)]\tLoss: 0.608640\n",
      "Train Epoch: 5 [1700/6700 (25%)]\tLoss: 0.004848\n",
      "Train Epoch: 5 [1800/6700 (27%)]\tLoss: 0.270638\n",
      "Train Epoch: 5 [1900/6700 (28%)]\tLoss: 0.523855\n",
      "Train Epoch: 5 [2000/6700 (30%)]\tLoss: 6.523617\n",
      "Train Epoch: 5 [2100/6700 (31%)]\tLoss: 0.041076\n",
      "Train Epoch: 5 [2200/6700 (33%)]\tLoss: 0.808733\n",
      "Train Epoch: 5 [2300/6700 (34%)]\tLoss: 0.009055\n",
      "Train Epoch: 5 [2400/6700 (36%)]\tLoss: 0.086675\n",
      "Train Epoch: 5 [2500/6700 (37%)]\tLoss: 0.056598\n",
      "Train Epoch: 5 [2600/6700 (39%)]\tLoss: 0.186490\n",
      "Train Epoch: 5 [2700/6700 (40%)]\tLoss: 0.567520\n",
      "Train Epoch: 5 [2800/6700 (42%)]\tLoss: 0.075035\n",
      "Train Epoch: 5 [2900/6700 (43%)]\tLoss: 0.001103\n",
      "Train Epoch: 5 [3000/6700 (45%)]\tLoss: 1.058182\n",
      "Train Epoch: 5 [3100/6700 (46%)]\tLoss: 0.103788\n",
      "Train Epoch: 5 [3200/6700 (48%)]\tLoss: 0.141888\n",
      "Train Epoch: 5 [3300/6700 (49%)]\tLoss: 2.224971\n",
      "Train Epoch: 5 [3400/6700 (51%)]\tLoss: 0.020900\n",
      "Train Epoch: 5 [3500/6700 (52%)]\tLoss: 2.759136\n",
      "Train Epoch: 5 [3600/6700 (54%)]\tLoss: 4.139990\n",
      "Train Epoch: 5 [3700/6700 (55%)]\tLoss: 0.072429\n",
      "Train Epoch: 5 [3800/6700 (57%)]\tLoss: 0.064473\n",
      "Train Epoch: 5 [3900/6700 (58%)]\tLoss: 0.018126\n",
      "Train Epoch: 5 [4000/6700 (60%)]\tLoss: 1.097134\n",
      "Train Epoch: 5 [4100/6700 (61%)]\tLoss: 0.489731\n",
      "Train Epoch: 5 [4200/6700 (63%)]\tLoss: 0.003293\n",
      "Train Epoch: 5 [4300/6700 (64%)]\tLoss: 0.435208\n",
      "Train Epoch: 5 [4400/6700 (66%)]\tLoss: 0.000558\n",
      "Train Epoch: 5 [4500/6700 (67%)]\tLoss: 1.469581\n",
      "Train Epoch: 5 [4600/6700 (69%)]\tLoss: 1.259868\n",
      "Train Epoch: 5 [4700/6700 (70%)]\tLoss: 0.095061\n",
      "Train Epoch: 5 [4800/6700 (72%)]\tLoss: 2.807036\n",
      "Train Epoch: 5 [4900/6700 (73%)]\tLoss: 0.040749\n",
      "Train Epoch: 5 [5000/6700 (75%)]\tLoss: 0.914633\n",
      "Train Epoch: 5 [5100/6700 (76%)]\tLoss: 0.072785\n",
      "Train Epoch: 5 [5200/6700 (78%)]\tLoss: 0.610034\n",
      "Train Epoch: 5 [5300/6700 (79%)]\tLoss: 0.407180\n",
      "Train Epoch: 5 [5400/6700 (81%)]\tLoss: 0.160953\n",
      "Train Epoch: 5 [5500/6700 (82%)]\tLoss: 2.520026\n",
      "Train Epoch: 5 [5600/6700 (84%)]\tLoss: 1.606850\n",
      "Train Epoch: 5 [5700/6700 (85%)]\tLoss: 3.339835\n",
      "Train Epoch: 5 [5800/6700 (87%)]\tLoss: 1.190986\n",
      "Train Epoch: 5 [5900/6700 (88%)]\tLoss: 0.270691\n",
      "Train Epoch: 5 [6000/6700 (90%)]\tLoss: 0.052192\n",
      "Train Epoch: 5 [6100/6700 (91%)]\tLoss: 0.001327\n",
      "Train Epoch: 5 [6200/6700 (93%)]\tLoss: 0.028944\n",
      "Train Epoch: 5 [6300/6700 (94%)]\tLoss: 0.017265\n",
      "Train Epoch: 5 [6400/6700 (96%)]\tLoss: 0.071452\n",
      "Train Epoch: 5 [6500/6700 (97%)]\tLoss: 0.185245\n",
      "Train Epoch: 5 [6600/6700 (99%)]\tLoss: 0.019263\n",
      "====> Epoch: 5 Average loss: 0.7121\n",
      "Train Epoch: 6 [0/6700 (0%)]\tLoss: 0.240052\n",
      "Train Epoch: 6 [100/6700 (1%)]\tLoss: 0.017702\n",
      "Train Epoch: 6 [200/6700 (3%)]\tLoss: 0.126298\n",
      "Train Epoch: 6 [300/6700 (4%)]\tLoss: 0.059399\n",
      "Train Epoch: 6 [400/6700 (6%)]\tLoss: 2.796957\n",
      "Train Epoch: 6 [500/6700 (7%)]\tLoss: 0.182358\n",
      "Train Epoch: 6 [600/6700 (9%)]\tLoss: 0.126697\n",
      "Train Epoch: 6 [700/6700 (10%)]\tLoss: 0.418689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [800/6700 (12%)]\tLoss: 1.106590\n",
      "Train Epoch: 6 [900/6700 (13%)]\tLoss: 0.081521\n",
      "Train Epoch: 6 [1000/6700 (15%)]\tLoss: 1.554601\n",
      "Train Epoch: 6 [1100/6700 (16%)]\tLoss: 0.081904\n",
      "Train Epoch: 6 [1200/6700 (18%)]\tLoss: 0.135601\n",
      "Train Epoch: 6 [1300/6700 (19%)]\tLoss: 0.025907\n",
      "Train Epoch: 6 [1400/6700 (21%)]\tLoss: 0.005191\n",
      "Train Epoch: 6 [1500/6700 (22%)]\tLoss: 0.109704\n",
      "Train Epoch: 6 [1600/6700 (24%)]\tLoss: 0.081467\n",
      "Train Epoch: 6 [1700/6700 (25%)]\tLoss: 0.002404\n",
      "Train Epoch: 6 [1800/6700 (27%)]\tLoss: 0.009346\n",
      "Train Epoch: 6 [1900/6700 (28%)]\tLoss: 0.407837\n",
      "Train Epoch: 6 [2000/6700 (30%)]\tLoss: 6.647480\n",
      "Train Epoch: 6 [2100/6700 (31%)]\tLoss: 0.030649\n",
      "Train Epoch: 6 [2200/6700 (33%)]\tLoss: 0.561600\n",
      "Train Epoch: 6 [2300/6700 (34%)]\tLoss: 0.005816\n",
      "Train Epoch: 6 [2400/6700 (36%)]\tLoss: 0.084271\n",
      "Train Epoch: 6 [2500/6700 (37%)]\tLoss: 0.051288\n",
      "Train Epoch: 6 [2600/6700 (39%)]\tLoss: 0.188711\n",
      "Train Epoch: 6 [2700/6700 (40%)]\tLoss: 0.426144\n",
      "Train Epoch: 6 [2800/6700 (42%)]\tLoss: 0.075147\n",
      "Train Epoch: 6 [2900/6700 (43%)]\tLoss: 0.000289\n",
      "Train Epoch: 6 [3000/6700 (45%)]\tLoss: 0.724287\n",
      "Train Epoch: 6 [3100/6700 (46%)]\tLoss: 0.059838\n",
      "Train Epoch: 6 [3200/6700 (48%)]\tLoss: 0.139235\n",
      "Train Epoch: 6 [3300/6700 (49%)]\tLoss: 2.049669\n",
      "Train Epoch: 6 [3400/6700 (51%)]\tLoss: 0.030679\n",
      "Train Epoch: 6 [3500/6700 (52%)]\tLoss: 0.007188\n",
      "Train Epoch: 6 [3600/6700 (54%)]\tLoss: 1.904114\n",
      "Train Epoch: 6 [3700/6700 (55%)]\tLoss: 0.103085\n",
      "Train Epoch: 6 [3800/6700 (57%)]\tLoss: 0.054893\n",
      "Train Epoch: 6 [3900/6700 (58%)]\tLoss: 0.007149\n",
      "Train Epoch: 6 [4000/6700 (60%)]\tLoss: 0.545804\n",
      "Train Epoch: 6 [4100/6700 (61%)]\tLoss: 0.452286\n",
      "Train Epoch: 6 [4200/6700 (63%)]\tLoss: 0.000441\n",
      "Train Epoch: 6 [4300/6700 (64%)]\tLoss: 0.463240\n",
      "Train Epoch: 6 [4400/6700 (66%)]\tLoss: 0.000234\n",
      "Train Epoch: 6 [4500/6700 (67%)]\tLoss: 1.028421\n",
      "Train Epoch: 6 [4600/6700 (69%)]\tLoss: 0.918309\n",
      "Train Epoch: 6 [4700/6700 (70%)]\tLoss: 0.078408\n",
      "Train Epoch: 6 [4800/6700 (72%)]\tLoss: 2.677818\n",
      "Train Epoch: 6 [4900/6700 (73%)]\tLoss: 0.019500\n",
      "Train Epoch: 6 [5000/6700 (75%)]\tLoss: 0.778666\n",
      "Train Epoch: 6 [5100/6700 (76%)]\tLoss: 0.030922\n",
      "Train Epoch: 6 [5200/6700 (78%)]\tLoss: 0.509334\n",
      "Train Epoch: 6 [5300/6700 (79%)]\tLoss: 0.452216\n",
      "Train Epoch: 6 [5400/6700 (81%)]\tLoss: 0.004872\n",
      "Train Epoch: 6 [5500/6700 (82%)]\tLoss: 8.292712\n",
      "Train Epoch: 6 [5600/6700 (84%)]\tLoss: 1.445010\n",
      "Train Epoch: 6 [5700/6700 (85%)]\tLoss: 2.428874\n",
      "Train Epoch: 6 [5800/6700 (87%)]\tLoss: 1.335945\n",
      "Train Epoch: 6 [5900/6700 (88%)]\tLoss: 0.168161\n",
      "Train Epoch: 6 [6000/6700 (90%)]\tLoss: 0.192753\n",
      "Train Epoch: 6 [6100/6700 (91%)]\tLoss: 0.000591\n",
      "Train Epoch: 6 [6200/6700 (93%)]\tLoss: 0.020194\n",
      "Train Epoch: 6 [6300/6700 (94%)]\tLoss: 0.020916\n",
      "Train Epoch: 6 [6400/6700 (96%)]\tLoss: 0.074266\n",
      "Train Epoch: 6 [6500/6700 (97%)]\tLoss: 0.218687\n",
      "Train Epoch: 6 [6600/6700 (99%)]\tLoss: 0.011033\n",
      "====> Epoch: 6 Average loss: 0.6430\n",
      "Train Epoch: 7 [0/6700 (0%)]\tLoss: 0.376162\n",
      "Train Epoch: 7 [100/6700 (1%)]\tLoss: 0.011820\n",
      "Train Epoch: 7 [200/6700 (3%)]\tLoss: 0.128788\n",
      "Train Epoch: 7 [300/6700 (4%)]\tLoss: 0.025632\n",
      "Train Epoch: 7 [400/6700 (6%)]\tLoss: 3.475104\n",
      "Train Epoch: 7 [500/6700 (7%)]\tLoss: 0.241664\n",
      "Train Epoch: 7 [600/6700 (9%)]\tLoss: 0.066195\n",
      "Train Epoch: 7 [700/6700 (10%)]\tLoss: 0.363759\n",
      "Train Epoch: 7 [800/6700 (12%)]\tLoss: 0.851059\n",
      "Train Epoch: 7 [900/6700 (13%)]\tLoss: 0.089892\n",
      "Train Epoch: 7 [1000/6700 (15%)]\tLoss: 0.612548\n",
      "Train Epoch: 7 [1100/6700 (16%)]\tLoss: 0.040348\n",
      "Train Epoch: 7 [1200/6700 (18%)]\tLoss: 0.043567\n",
      "Train Epoch: 7 [1300/6700 (19%)]\tLoss: 0.012250\n",
      "Train Epoch: 7 [1400/6700 (21%)]\tLoss: 0.005032\n",
      "Train Epoch: 7 [1500/6700 (22%)]\tLoss: 0.103831\n",
      "Train Epoch: 7 [1600/6700 (24%)]\tLoss: 0.142563\n",
      "Train Epoch: 7 [1700/6700 (25%)]\tLoss: 0.001496\n",
      "Train Epoch: 7 [1800/6700 (27%)]\tLoss: 0.000128\n",
      "Train Epoch: 7 [1900/6700 (28%)]\tLoss: 0.376949\n",
      "Train Epoch: 7 [2000/6700 (30%)]\tLoss: 7.118601\n",
      "Train Epoch: 7 [2100/6700 (31%)]\tLoss: 0.034418\n",
      "Train Epoch: 7 [2200/6700 (33%)]\tLoss: 0.497524\n",
      "Train Epoch: 7 [2300/6700 (34%)]\tLoss: 0.003520\n",
      "Train Epoch: 7 [2400/6700 (36%)]\tLoss: 0.099387\n",
      "Train Epoch: 7 [2500/6700 (37%)]\tLoss: 0.052574\n",
      "Train Epoch: 7 [2600/6700 (39%)]\tLoss: 0.111300\n",
      "Train Epoch: 7 [2700/6700 (40%)]\tLoss: 0.293218\n",
      "Train Epoch: 7 [2800/6700 (42%)]\tLoss: 0.052340\n",
      "Train Epoch: 7 [2900/6700 (43%)]\tLoss: 0.000132\n",
      "Train Epoch: 7 [3000/6700 (45%)]\tLoss: 1.029349\n",
      "Train Epoch: 7 [3100/6700 (46%)]\tLoss: 0.052188\n",
      "Train Epoch: 7 [3200/6700 (48%)]\tLoss: 0.163604\n",
      "Train Epoch: 7 [3300/6700 (49%)]\tLoss: 2.500309\n",
      "Train Epoch: 7 [3400/6700 (51%)]\tLoss: 0.037082\n",
      "Train Epoch: 7 [3500/6700 (52%)]\tLoss: 0.019791\n",
      "Train Epoch: 7 [3600/6700 (54%)]\tLoss: 2.012262\n",
      "Train Epoch: 7 [3700/6700 (55%)]\tLoss: 0.095790\n",
      "Train Epoch: 7 [3800/6700 (57%)]\tLoss: 0.036760\n",
      "Train Epoch: 7 [3900/6700 (58%)]\tLoss: 0.006728\n",
      "Train Epoch: 7 [4000/6700 (60%)]\tLoss: 0.916215\n",
      "Train Epoch: 7 [4100/6700 (61%)]\tLoss: 0.405308\n",
      "Train Epoch: 7 [4200/6700 (63%)]\tLoss: 0.002239\n",
      "Train Epoch: 7 [4300/6700 (64%)]\tLoss: 0.293051\n",
      "Train Epoch: 7 [4400/6700 (66%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [4500/6700 (67%)]\tLoss: 0.820005\n",
      "Train Epoch: 7 [4600/6700 (69%)]\tLoss: 0.968172\n",
      "Train Epoch: 7 [4700/6700 (70%)]\tLoss: 0.041429\n",
      "Train Epoch: 7 [4800/6700 (72%)]\tLoss: 2.604939\n",
      "Train Epoch: 7 [4900/6700 (73%)]\tLoss: 0.014327\n",
      "Train Epoch: 7 [5000/6700 (75%)]\tLoss: 0.468093\n",
      "Train Epoch: 7 [5100/6700 (76%)]\tLoss: 0.041676\n",
      "Train Epoch: 7 [5200/6700 (78%)]\tLoss: 0.283490\n",
      "Train Epoch: 7 [5300/6700 (79%)]\tLoss: 0.460736\n",
      "Train Epoch: 7 [5400/6700 (81%)]\tLoss: 0.132360\n",
      "Train Epoch: 7 [5500/6700 (82%)]\tLoss: 0.881247\n",
      "Train Epoch: 7 [5600/6700 (84%)]\tLoss: 0.756328\n",
      "Train Epoch: 7 [5700/6700 (85%)]\tLoss: 3.396205\n",
      "Train Epoch: 7 [5800/6700 (87%)]\tLoss: 1.353782\n",
      "Train Epoch: 7 [5900/6700 (88%)]\tLoss: 0.237582\n",
      "Train Epoch: 7 [6000/6700 (90%)]\tLoss: 0.139829\n",
      "Train Epoch: 7 [6100/6700 (91%)]\tLoss: 0.000578\n",
      "Train Epoch: 7 [6200/6700 (93%)]\tLoss: 0.006944\n",
      "Train Epoch: 7 [6300/6700 (94%)]\tLoss: 0.011708\n",
      "Train Epoch: 7 [6400/6700 (96%)]\tLoss: 0.050951\n",
      "Train Epoch: 7 [6500/6700 (97%)]\tLoss: 0.110622\n",
      "Train Epoch: 7 [6600/6700 (99%)]\tLoss: 0.011714\n",
      "====> Epoch: 7 Average loss: 0.5778\n",
      "Train Epoch: 8 [0/6700 (0%)]\tLoss: 0.126027\n",
      "Train Epoch: 8 [100/6700 (1%)]\tLoss: 0.008041\n",
      "Train Epoch: 8 [200/6700 (3%)]\tLoss: 0.159953\n",
      "Train Epoch: 8 [300/6700 (4%)]\tLoss: 0.018915\n",
      "Train Epoch: 8 [400/6700 (6%)]\tLoss: 2.009325\n",
      "Train Epoch: 8 [500/6700 (7%)]\tLoss: 0.301938\n",
      "Train Epoch: 8 [600/6700 (9%)]\tLoss: 0.076796\n",
      "Train Epoch: 8 [700/6700 (10%)]\tLoss: 0.448102\n",
      "Train Epoch: 8 [800/6700 (12%)]\tLoss: 0.934588\n",
      "Train Epoch: 8 [900/6700 (13%)]\tLoss: 0.085956\n",
      "Train Epoch: 8 [1000/6700 (15%)]\tLoss: 0.361926\n",
      "Train Epoch: 8 [1100/6700 (16%)]\tLoss: 0.448744\n",
      "Train Epoch: 8 [1200/6700 (18%)]\tLoss: 0.383359\n",
      "Train Epoch: 8 [1300/6700 (19%)]\tLoss: 0.020592\n",
      "Train Epoch: 8 [1400/6700 (21%)]\tLoss: 0.005263\n",
      "Train Epoch: 8 [1500/6700 (22%)]\tLoss: 0.095154\n",
      "Train Epoch: 8 [1600/6700 (24%)]\tLoss: 0.005735\n",
      "Train Epoch: 8 [1700/6700 (25%)]\tLoss: 0.000295\n",
      "Train Epoch: 8 [1800/6700 (27%)]\tLoss: 0.000530\n",
      "Train Epoch: 8 [1900/6700 (28%)]\tLoss: 0.408612\n",
      "Train Epoch: 8 [2000/6700 (30%)]\tLoss: 6.329455\n",
      "Train Epoch: 8 [2100/6700 (31%)]\tLoss: 0.043555\n",
      "Train Epoch: 8 [2200/6700 (33%)]\tLoss: 0.214138\n",
      "Train Epoch: 8 [2300/6700 (34%)]\tLoss: 0.002429\n",
      "Train Epoch: 8 [2400/6700 (36%)]\tLoss: 0.087528\n",
      "Train Epoch: 8 [2500/6700 (37%)]\tLoss: 0.035845\n",
      "Train Epoch: 8 [2600/6700 (39%)]\tLoss: 0.059674\n",
      "Train Epoch: 8 [2700/6700 (40%)]\tLoss: 0.165826\n",
      "Train Epoch: 8 [2800/6700 (42%)]\tLoss: 0.066385\n",
      "Train Epoch: 8 [2900/6700 (43%)]\tLoss: 0.000055\n",
      "Train Epoch: 8 [3000/6700 (45%)]\tLoss: 0.863150\n",
      "Train Epoch: 8 [3100/6700 (46%)]\tLoss: 0.065019\n",
      "Train Epoch: 8 [3200/6700 (48%)]\tLoss: 0.191942\n",
      "Train Epoch: 8 [3300/6700 (49%)]\tLoss: 1.860560\n",
      "Train Epoch: 8 [3400/6700 (51%)]\tLoss: 0.030629\n",
      "Train Epoch: 8 [3500/6700 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 8 [3600/6700 (54%)]\tLoss: 2.411574\n",
      "Train Epoch: 8 [3700/6700 (55%)]\tLoss: 0.105019\n",
      "Train Epoch: 8 [3800/6700 (57%)]\tLoss: 0.044699\n",
      "Train Epoch: 8 [3900/6700 (58%)]\tLoss: 0.003857\n",
      "Train Epoch: 8 [4000/6700 (60%)]\tLoss: 1.560280\n",
      "Train Epoch: 8 [4100/6700 (61%)]\tLoss: 0.467245\n",
      "Train Epoch: 8 [4200/6700 (63%)]\tLoss: 0.001534\n",
      "Train Epoch: 8 [4300/6700 (64%)]\tLoss: 0.079361\n",
      "Train Epoch: 8 [4400/6700 (66%)]\tLoss: 0.000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [4500/6700 (67%)]\tLoss: 1.098346\n",
      "Train Epoch: 8 [4600/6700 (69%)]\tLoss: 0.378441\n",
      "Train Epoch: 8 [4700/6700 (70%)]\tLoss: 0.073670\n",
      "Train Epoch: 8 [4800/6700 (72%)]\tLoss: 2.694206\n",
      "Train Epoch: 8 [4900/6700 (73%)]\tLoss: 0.014123\n",
      "Train Epoch: 8 [5000/6700 (75%)]\tLoss: 0.558752\n",
      "Train Epoch: 8 [5100/6700 (76%)]\tLoss: 0.023359\n",
      "Train Epoch: 8 [5200/6700 (78%)]\tLoss: 0.283003\n",
      "Train Epoch: 8 [5300/6700 (79%)]\tLoss: 0.380264\n",
      "Train Epoch: 8 [5400/6700 (81%)]\tLoss: 0.117547\n",
      "Train Epoch: 8 [5500/6700 (82%)]\tLoss: 1.217327\n",
      "Train Epoch: 8 [5600/6700 (84%)]\tLoss: 0.971036\n",
      "Train Epoch: 8 [5700/6700 (85%)]\tLoss: 3.140064\n",
      "Train Epoch: 8 [5800/6700 (87%)]\tLoss: 1.176880\n",
      "Train Epoch: 8 [5900/6700 (88%)]\tLoss: 0.240503\n",
      "Train Epoch: 8 [6000/6700 (90%)]\tLoss: 0.178324\n",
      "Train Epoch: 8 [6100/6700 (91%)]\tLoss: 0.000245\n",
      "Train Epoch: 8 [6200/6700 (93%)]\tLoss: 0.005501\n",
      "Train Epoch: 8 [6300/6700 (94%)]\tLoss: 0.010676\n",
      "Train Epoch: 8 [6400/6700 (96%)]\tLoss: 0.037490\n",
      "Train Epoch: 8 [6500/6700 (97%)]\tLoss: 0.143106\n",
      "Train Epoch: 8 [6600/6700 (99%)]\tLoss: 0.008183\n",
      "====> Epoch: 8 Average loss: 0.5563\n",
      "Train Epoch: 9 [0/6700 (0%)]\tLoss: 0.186964\n",
      "Train Epoch: 9 [100/6700 (1%)]\tLoss: 0.007678\n",
      "Train Epoch: 9 [200/6700 (3%)]\tLoss: 0.152159\n",
      "Train Epoch: 9 [300/6700 (4%)]\tLoss: 0.006618\n",
      "Train Epoch: 9 [400/6700 (6%)]\tLoss: 1.544414\n",
      "Train Epoch: 9 [500/6700 (7%)]\tLoss: 0.165631\n",
      "Train Epoch: 9 [600/6700 (9%)]\tLoss: 0.058329\n",
      "Train Epoch: 9 [700/6700 (10%)]\tLoss: 0.683219\n",
      "Train Epoch: 9 [800/6700 (12%)]\tLoss: 0.716567\n",
      "Train Epoch: 9 [900/6700 (13%)]\tLoss: 0.102853\n",
      "Train Epoch: 9 [1000/6700 (15%)]\tLoss: 0.268313\n",
      "Train Epoch: 9 [1100/6700 (16%)]\tLoss: 0.000003\n",
      "Train Epoch: 9 [1200/6700 (18%)]\tLoss: 0.000054\n",
      "Train Epoch: 9 [1300/6700 (19%)]\tLoss: 0.029190\n",
      "Train Epoch: 9 [1400/6700 (21%)]\tLoss: 0.002261\n",
      "Train Epoch: 9 [1500/6700 (22%)]\tLoss: 0.077055\n",
      "Train Epoch: 9 [1600/6700 (24%)]\tLoss: 0.717051\n",
      "Train Epoch: 9 [1700/6700 (25%)]\tLoss: 0.000037\n",
      "Train Epoch: 9 [1800/6700 (27%)]\tLoss: 0.001826\n",
      "Train Epoch: 9 [1900/6700 (28%)]\tLoss: 0.374147\n",
      "Train Epoch: 9 [2000/6700 (30%)]\tLoss: 5.503875\n",
      "Train Epoch: 9 [2100/6700 (31%)]\tLoss: 0.020891\n",
      "Train Epoch: 9 [2200/6700 (33%)]\tLoss: 0.117875\n",
      "Train Epoch: 9 [2300/6700 (34%)]\tLoss: 0.001888\n",
      "Train Epoch: 9 [2400/6700 (36%)]\tLoss: 0.075825\n",
      "Train Epoch: 9 [2500/6700 (37%)]\tLoss: 0.043716\n",
      "Train Epoch: 9 [2600/6700 (39%)]\tLoss: 0.027152\n",
      "Train Epoch: 9 [2700/6700 (40%)]\tLoss: 0.312261\n",
      "Train Epoch: 9 [2800/6700 (42%)]\tLoss: 0.111837\n",
      "Train Epoch: 9 [2900/6700 (43%)]\tLoss: 0.000025\n",
      "Train Epoch: 9 [3000/6700 (45%)]\tLoss: 1.034220\n",
      "Train Epoch: 9 [3100/6700 (46%)]\tLoss: 0.030339\n",
      "Train Epoch: 9 [3200/6700 (48%)]\tLoss: 0.105245\n",
      "Train Epoch: 9 [3300/6700 (49%)]\tLoss: 2.059276\n",
      "Train Epoch: 9 [3400/6700 (51%)]\tLoss: 0.050341\n",
      "Train Epoch: 9 [3500/6700 (52%)]\tLoss: 0.005662\n",
      "Train Epoch: 9 [3600/6700 (54%)]\tLoss: 2.232668\n",
      "Train Epoch: 9 [3700/6700 (55%)]\tLoss: 0.114137\n",
      "Train Epoch: 9 [3800/6700 (57%)]\tLoss: 0.007587\n",
      "Train Epoch: 9 [3900/6700 (58%)]\tLoss: 0.010191\n",
      "Train Epoch: 9 [4000/6700 (60%)]\tLoss: 1.573350\n",
      "Train Epoch: 9 [4100/6700 (61%)]\tLoss: 0.567551\n",
      "Train Epoch: 9 [4200/6700 (63%)]\tLoss: 0.001758\n",
      "Train Epoch: 9 [4300/6700 (64%)]\tLoss: 0.279286\n",
      "Train Epoch: 9 [4400/6700 (66%)]\tLoss: 0.000309\n",
      "Train Epoch: 9 [4500/6700 (67%)]\tLoss: 0.705679\n",
      "Train Epoch: 9 [4600/6700 (69%)]\tLoss: 0.576370\n",
      "Train Epoch: 9 [4700/6700 (70%)]\tLoss: 0.029909\n",
      "Train Epoch: 9 [4800/6700 (72%)]\tLoss: 3.411132\n",
      "Train Epoch: 9 [4900/6700 (73%)]\tLoss: 0.007802\n",
      "Train Epoch: 9 [5000/6700 (75%)]\tLoss: 0.450413\n",
      "Train Epoch: 9 [5100/6700 (76%)]\tLoss: 0.010007\n",
      "Train Epoch: 9 [5200/6700 (78%)]\tLoss: 0.170791\n",
      "Train Epoch: 9 [5300/6700 (79%)]\tLoss: 0.480717\n",
      "Train Epoch: 9 [5400/6700 (81%)]\tLoss: 0.030901\n",
      "Train Epoch: 9 [5500/6700 (82%)]\tLoss: 0.224475\n",
      "Train Epoch: 9 [5600/6700 (84%)]\tLoss: 0.665429\n",
      "Train Epoch: 9 [5700/6700 (85%)]\tLoss: 3.322302\n",
      "Train Epoch: 9 [5800/6700 (87%)]\tLoss: 0.778795\n",
      "Train Epoch: 9 [5900/6700 (88%)]\tLoss: 0.232396\n",
      "Train Epoch: 9 [6000/6700 (90%)]\tLoss: 0.048789\n",
      "Train Epoch: 9 [6100/6700 (91%)]\tLoss: 0.000229\n",
      "Train Epoch: 9 [6200/6700 (93%)]\tLoss: 0.006411\n",
      "Train Epoch: 9 [6300/6700 (94%)]\tLoss: 0.011216\n",
      "Train Epoch: 9 [6400/6700 (96%)]\tLoss: 0.038039\n",
      "Train Epoch: 9 [6500/6700 (97%)]\tLoss: 0.122797\n",
      "Train Epoch: 9 [6600/6700 (99%)]\tLoss: 0.006290\n",
      "====> Epoch: 9 Average loss: 0.5125\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 12 22  4  7]\n",
      " [ 2  1  9  4 15]\n",
      " [ 3 12  4 22 39]\n",
      " ...\n",
      " [ 9 45  1 15 16]\n",
      " [ 4 37  5 16 18]\n",
      " [ 3 12 22 37  4]]\n",
      "[3. 2. 3. ... 9. 4. 3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "print (y_pred)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.774 prec@3: 0.923 prec@5: 0.958\n",
      "mprec@1: 5.077e-01 mprec@3: 7.707e-01 mprec@5: 8.564e-01\n",
      "prec matrix [0.77363636 0.88878788 0.92272727 0.94363636 0.95787879]\n",
      "mprec matrix [0.50767473 0.70322354 0.77065845 0.81476752 0.85638644]\n"
     ]
    }
   ],
   "source": [
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve nn \n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "#         torch.nn.init.xavier_uniform_(self.layer1.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            outp = self.forward(x)\n",
    "            return F.softmax(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model declared\n",
    "model = NeuralNet(225 , 2000, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "# loss_function = nn.BCELoss()\n",
    "model_opt = optim.SGD(model.parameters(), lr = 2e-2)\n",
    "\n",
    "train_set_X = Variable(torch.from_numpy(X_train)).float()\n",
    "train_set_y = Variable(torch.LongTensor(y_train)).long()\n",
    "test_set_X = Variable(torch.from_numpy(X_test)).float()\n",
    "test_set_y = Variable(torch.LongTensor(y_test)).long()\n",
    "\n",
    "tr_latent_X = data_utils.TensorDataset(train_set_X, train_set_y)\n",
    "te_latent_X = data_utils.TensorDataset(test_set_X,  test_set_y)\n",
    "train_loader_X = torch.utils.data.DataLoader(dataset=tr_latent_X)\n",
    "test_loader_X = torch.utils.data.DataLoader(dataset=te_latent_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data,label) in enumerate(train_loader_X):\n",
    "\n",
    "        model_opt.zero_grad()\n",
    "\n",
    "        out = model(data)\n",
    "        loss = loss_function(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        model_opt.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_X.dataset),\n",
    "                100. * batch_idx / len(train_loader_X), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader_X.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6700 (0%)]\tLoss: 4.035842\n",
      "Train Epoch: 1 [100/6700 (1%)]\tLoss: 2.159297\n",
      "Train Epoch: 1 [200/6700 (3%)]\tLoss: 0.764661\n",
      "Train Epoch: 1 [300/6700 (4%)]\tLoss: 4.318502\n",
      "Train Epoch: 1 [400/6700 (6%)]\tLoss: 3.904516\n",
      "Train Epoch: 1 [500/6700 (7%)]\tLoss: 1.309211\n",
      "Train Epoch: 1 [600/6700 (9%)]\tLoss: 1.763264\n",
      "Train Epoch: 1 [700/6700 (10%)]\tLoss: 0.840062\n",
      "Train Epoch: 1 [800/6700 (12%)]\tLoss: 2.210183\n",
      "Train Epoch: 1 [900/6700 (13%)]\tLoss: 0.477876\n",
      "Train Epoch: 1 [1000/6700 (15%)]\tLoss: 2.694440\n",
      "Train Epoch: 1 [1100/6700 (16%)]\tLoss: 0.010783\n",
      "Train Epoch: 1 [1200/6700 (18%)]\tLoss: 7.714949\n",
      "Train Epoch: 1 [1300/6700 (19%)]\tLoss: 0.160265\n",
      "Train Epoch: 1 [1400/6700 (21%)]\tLoss: 1.296306\n",
      "Train Epoch: 1 [1500/6700 (22%)]\tLoss: 0.595251\n",
      "Train Epoch: 1 [1600/6700 (24%)]\tLoss: 2.287751\n",
      "Train Epoch: 1 [1700/6700 (25%)]\tLoss: 0.043681\n",
      "Train Epoch: 1 [1800/6700 (27%)]\tLoss: 0.857507\n",
      "Train Epoch: 1 [1900/6700 (28%)]\tLoss: 1.402730\n",
      "Train Epoch: 1 [2000/6700 (30%)]\tLoss: 4.756148\n",
      "Train Epoch: 1 [2100/6700 (31%)]\tLoss: 0.789544\n",
      "Train Epoch: 1 [2200/6700 (33%)]\tLoss: 1.806179\n",
      "Train Epoch: 1 [2300/6700 (34%)]\tLoss: 0.050551\n",
      "Train Epoch: 1 [2400/6700 (36%)]\tLoss: 1.364348\n",
      "Train Epoch: 1 [2500/6700 (37%)]\tLoss: 0.086586\n",
      "Train Epoch: 1 [2600/6700 (39%)]\tLoss: 1.363737\n",
      "Train Epoch: 1 [2700/6700 (40%)]\tLoss: 5.152208\n",
      "Train Epoch: 1 [2800/6700 (42%)]\tLoss: 1.169339\n",
      "Train Epoch: 1 [2900/6700 (43%)]\tLoss: 0.669842\n",
      "Train Epoch: 1 [3000/6700 (45%)]\tLoss: 1.247688\n",
      "Train Epoch: 1 [3100/6700 (46%)]\tLoss: 1.192789\n",
      "Train Epoch: 1 [3200/6700 (48%)]\tLoss: 0.144506\n",
      "Train Epoch: 1 [3300/6700 (49%)]\tLoss: 4.162832\n",
      "Train Epoch: 1 [3400/6700 (51%)]\tLoss: 0.163576\n",
      "Train Epoch: 1 [3500/6700 (52%)]\tLoss: 0.765292\n",
      "Train Epoch: 1 [3600/6700 (54%)]\tLoss: 1.679487\n",
      "Train Epoch: 1 [3700/6700 (55%)]\tLoss: 0.523436\n",
      "Train Epoch: 1 [3800/6700 (57%)]\tLoss: 0.435538\n",
      "Train Epoch: 1 [3900/6700 (58%)]\tLoss: 0.318321\n",
      "Train Epoch: 1 [4000/6700 (60%)]\tLoss: 6.546477\n",
      "Train Epoch: 1 [4100/6700 (61%)]\tLoss: 0.218485\n",
      "Train Epoch: 1 [4200/6700 (63%)]\tLoss: 0.031836\n",
      "Train Epoch: 1 [4300/6700 (64%)]\tLoss: 1.068161\n",
      "Train Epoch: 1 [4400/6700 (66%)]\tLoss: 0.883048\n",
      "Train Epoch: 1 [4500/6700 (67%)]\tLoss: 1.942438\n",
      "Train Epoch: 1 [4600/6700 (69%)]\tLoss: 2.785394\n",
      "Train Epoch: 1 [4700/6700 (70%)]\tLoss: 0.667985\n",
      "Train Epoch: 1 [4800/6700 (72%)]\tLoss: 2.229278\n",
      "Train Epoch: 1 [4900/6700 (73%)]\tLoss: 3.252809\n",
      "Train Epoch: 1 [5000/6700 (75%)]\tLoss: 3.355811\n",
      "Train Epoch: 1 [5100/6700 (76%)]\tLoss: 0.788275\n",
      "Train Epoch: 1 [5200/6700 (78%)]\tLoss: 1.982150\n",
      "Train Epoch: 1 [5300/6700 (79%)]\tLoss: 0.990522\n",
      "Train Epoch: 1 [5400/6700 (81%)]\tLoss: 0.123420\n",
      "Train Epoch: 1 [5500/6700 (82%)]\tLoss: 4.910999\n",
      "Train Epoch: 1 [5600/6700 (84%)]\tLoss: 5.867399\n",
      "Train Epoch: 1 [5700/6700 (85%)]\tLoss: 2.930107\n",
      "Train Epoch: 1 [5800/6700 (87%)]\tLoss: 2.128859\n",
      "Train Epoch: 1 [5900/6700 (88%)]\tLoss: 0.430252\n",
      "Train Epoch: 1 [6000/6700 (90%)]\tLoss: 0.558545\n",
      "Train Epoch: 1 [6100/6700 (91%)]\tLoss: 0.050992\n",
      "Train Epoch: 1 [6200/6700 (93%)]\tLoss: 0.344491\n",
      "Train Epoch: 1 [6300/6700 (94%)]\tLoss: 0.103387\n",
      "Train Epoch: 1 [6400/6700 (96%)]\tLoss: 2.375850\n",
      "Train Epoch: 1 [6500/6700 (97%)]\tLoss: 0.193098\n",
      "Train Epoch: 1 [6600/6700 (99%)]\tLoss: 0.368318\n",
      "====> Epoch: 1 Average loss: 1.6333\n",
      "Train Epoch: 2 [0/6700 (0%)]\tLoss: 0.561470\n",
      "Train Epoch: 2 [100/6700 (1%)]\tLoss: 0.139608\n",
      "Train Epoch: 2 [200/6700 (3%)]\tLoss: 0.145862\n",
      "Train Epoch: 2 [300/6700 (4%)]\tLoss: 0.578714\n",
      "Train Epoch: 2 [400/6700 (6%)]\tLoss: 3.549367\n",
      "Train Epoch: 2 [500/6700 (7%)]\tLoss: 0.187396\n",
      "Train Epoch: 2 [600/6700 (9%)]\tLoss: 1.039082\n",
      "Train Epoch: 2 [700/6700 (10%)]\tLoss: 0.423016\n",
      "Train Epoch: 2 [800/6700 (12%)]\tLoss: 1.500415\n",
      "Train Epoch: 2 [900/6700 (13%)]\tLoss: 0.087840\n",
      "Train Epoch: 2 [1000/6700 (15%)]\tLoss: 1.840723\n",
      "Train Epoch: 2 [1100/6700 (16%)]\tLoss: 4.207307\n",
      "Train Epoch: 2 [1200/6700 (18%)]\tLoss: 6.065855\n",
      "Train Epoch: 2 [1300/6700 (19%)]\tLoss: 0.060370\n",
      "Train Epoch: 2 [1400/6700 (21%)]\tLoss: 0.071446\n",
      "Train Epoch: 2 [1500/6700 (22%)]\tLoss: 0.200082\n",
      "Train Epoch: 2 [1600/6700 (24%)]\tLoss: 0.219663\n",
      "Train Epoch: 2 [1700/6700 (25%)]\tLoss: 0.024726\n",
      "Train Epoch: 2 [1800/6700 (27%)]\tLoss: 1.158030\n",
      "Train Epoch: 2 [1900/6700 (28%)]\tLoss: 1.169514\n",
      "Train Epoch: 2 [2000/6700 (30%)]\tLoss: 5.824417\n",
      "Train Epoch: 2 [2100/6700 (31%)]\tLoss: 0.286345\n",
      "Train Epoch: 2 [2200/6700 (33%)]\tLoss: 1.288311\n",
      "Train Epoch: 2 [2300/6700 (34%)]\tLoss: 0.035937\n",
      "Train Epoch: 2 [2400/6700 (36%)]\tLoss: 0.169988\n",
      "Train Epoch: 2 [2500/6700 (37%)]\tLoss: 0.043202\n",
      "Train Epoch: 2 [2600/6700 (39%)]\tLoss: 0.817709\n",
      "Train Epoch: 2 [2700/6700 (40%)]\tLoss: 2.737969\n",
      "Train Epoch: 2 [2800/6700 (42%)]\tLoss: 0.345155\n",
      "Train Epoch: 2 [2900/6700 (43%)]\tLoss: 0.037498\n",
      "Train Epoch: 2 [3000/6700 (45%)]\tLoss: 0.684449\n",
      "Train Epoch: 2 [3100/6700 (46%)]\tLoss: 0.632962\n",
      "Train Epoch: 2 [3200/6700 (48%)]\tLoss: 0.113126\n",
      "Train Epoch: 2 [3300/6700 (49%)]\tLoss: 2.891995\n",
      "Train Epoch: 2 [3400/6700 (51%)]\tLoss: 0.040134\n",
      "Train Epoch: 2 [3500/6700 (52%)]\tLoss: 0.021840\n",
      "Train Epoch: 2 [3600/6700 (54%)]\tLoss: 1.902736\n",
      "Train Epoch: 2 [3700/6700 (55%)]\tLoss: 0.156030\n",
      "Train Epoch: 2 [3800/6700 (57%)]\tLoss: 0.154983\n",
      "Train Epoch: 2 [3900/6700 (58%)]\tLoss: 0.061182\n",
      "Train Epoch: 2 [4000/6700 (60%)]\tLoss: 5.834541\n",
      "Train Epoch: 2 [4100/6700 (61%)]\tLoss: 0.170276\n",
      "Train Epoch: 2 [4200/6700 (63%)]\tLoss: 0.007974\n",
      "Train Epoch: 2 [4300/6700 (64%)]\tLoss: 0.989798\n",
      "Train Epoch: 2 [4400/6700 (66%)]\tLoss: 0.029852\n",
      "Train Epoch: 2 [4500/6700 (67%)]\tLoss: 2.003987\n",
      "Train Epoch: 2 [4600/6700 (69%)]\tLoss: 2.137897\n",
      "Train Epoch: 2 [4700/6700 (70%)]\tLoss: 0.306926\n",
      "Train Epoch: 2 [4800/6700 (72%)]\tLoss: 1.968250\n",
      "Train Epoch: 2 [4900/6700 (73%)]\tLoss: 0.875716\n",
      "Train Epoch: 2 [5000/6700 (75%)]\tLoss: 2.407528\n",
      "Train Epoch: 2 [5100/6700 (76%)]\tLoss: 0.248378\n",
      "Train Epoch: 2 [5200/6700 (78%)]\tLoss: 1.870081\n",
      "Train Epoch: 2 [5300/6700 (79%)]\tLoss: 0.676571\n",
      "Train Epoch: 2 [5400/6700 (81%)]\tLoss: 0.101472\n",
      "Train Epoch: 2 [5500/6700 (82%)]\tLoss: 2.832848\n",
      "Train Epoch: 2 [5600/6700 (84%)]\tLoss: 4.201237\n",
      "Train Epoch: 2 [5700/6700 (85%)]\tLoss: 2.811970\n",
      "Train Epoch: 2 [5800/6700 (87%)]\tLoss: 1.620692\n",
      "Train Epoch: 2 [5900/6700 (88%)]\tLoss: 0.177995\n",
      "Train Epoch: 2 [6000/6700 (90%)]\tLoss: 0.316547\n",
      "Train Epoch: 2 [6100/6700 (91%)]\tLoss: 0.011054\n",
      "Train Epoch: 2 [6200/6700 (93%)]\tLoss: 0.094996\n",
      "Train Epoch: 2 [6300/6700 (94%)]\tLoss: 0.033489\n",
      "Train Epoch: 2 [6400/6700 (96%)]\tLoss: 0.607254\n",
      "Train Epoch: 2 [6500/6700 (97%)]\tLoss: 0.162087\n",
      "Train Epoch: 2 [6600/6700 (99%)]\tLoss: 0.088908\n",
      "====> Epoch: 2 Average loss: 1.0886\n",
      "Train Epoch: 3 [0/6700 (0%)]\tLoss: 0.299843\n",
      "Train Epoch: 3 [100/6700 (1%)]\tLoss: 0.058286\n",
      "Train Epoch: 3 [200/6700 (3%)]\tLoss: 0.127203\n",
      "Train Epoch: 3 [300/6700 (4%)]\tLoss: 0.313218\n",
      "Train Epoch: 3 [400/6700 (6%)]\tLoss: 3.633770\n",
      "Train Epoch: 3 [500/6700 (7%)]\tLoss: 0.152043\n",
      "Train Epoch: 3 [600/6700 (9%)]\tLoss: 0.440143\n",
      "Train Epoch: 3 [700/6700 (10%)]\tLoss: 0.391379\n",
      "Train Epoch: 3 [800/6700 (12%)]\tLoss: 1.397014\n",
      "Train Epoch: 3 [900/6700 (13%)]\tLoss: 0.050559\n",
      "Train Epoch: 3 [1000/6700 (15%)]\tLoss: 1.919106\n",
      "Train Epoch: 3 [1100/6700 (16%)]\tLoss: 0.000097\n",
      "Train Epoch: 3 [1200/6700 (18%)]\tLoss: 3.688317\n",
      "Train Epoch: 3 [1300/6700 (19%)]\tLoss: 0.039574\n",
      "Train Epoch: 3 [1400/6700 (21%)]\tLoss: 0.024127\n",
      "Train Epoch: 3 [1500/6700 (22%)]\tLoss: 0.184782\n",
      "Train Epoch: 3 [1600/6700 (24%)]\tLoss: 0.156714\n",
      "Train Epoch: 3 [1700/6700 (25%)]\tLoss: 0.004486\n",
      "Train Epoch: 3 [1800/6700 (27%)]\tLoss: 0.192718\n",
      "Train Epoch: 3 [1900/6700 (28%)]\tLoss: 1.388044\n",
      "Train Epoch: 3 [2000/6700 (30%)]\tLoss: 5.775528\n",
      "Train Epoch: 3 [2100/6700 (31%)]\tLoss: 0.105778\n",
      "Train Epoch: 3 [2200/6700 (33%)]\tLoss: 1.136151\n",
      "Train Epoch: 3 [2300/6700 (34%)]\tLoss: 0.023191\n",
      "Train Epoch: 3 [2400/6700 (36%)]\tLoss: 0.071152\n",
      "Train Epoch: 3 [2500/6700 (37%)]\tLoss: 0.046414\n",
      "Train Epoch: 3 [2600/6700 (39%)]\tLoss: 0.512958\n",
      "Train Epoch: 3 [2700/6700 (40%)]\tLoss: 1.602047\n",
      "Train Epoch: 3 [2800/6700 (42%)]\tLoss: 0.130806\n",
      "Train Epoch: 3 [2900/6700 (43%)]\tLoss: 0.005143\n",
      "Train Epoch: 3 [3000/6700 (45%)]\tLoss: 0.549258\n",
      "Train Epoch: 3 [3100/6700 (46%)]\tLoss: 0.274222\n",
      "Train Epoch: 3 [3200/6700 (48%)]\tLoss: 0.125536\n",
      "Train Epoch: 3 [3300/6700 (49%)]\tLoss: 2.534282\n",
      "Train Epoch: 3 [3400/6700 (51%)]\tLoss: 0.029076\n",
      "Train Epoch: 3 [3500/6700 (52%)]\tLoss: 1.675557\n",
      "Train Epoch: 3 [3600/6700 (54%)]\tLoss: 2.014712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [3700/6700 (55%)]\tLoss: 0.099102\n",
      "Train Epoch: 3 [3800/6700 (57%)]\tLoss: 0.045264\n",
      "Train Epoch: 3 [3900/6700 (58%)]\tLoss: 0.035081\n",
      "Train Epoch: 3 [4000/6700 (60%)]\tLoss: 3.370197\n",
      "Train Epoch: 3 [4100/6700 (61%)]\tLoss: 0.211939\n",
      "Train Epoch: 3 [4200/6700 (63%)]\tLoss: 0.006051\n",
      "Train Epoch: 3 [4300/6700 (64%)]\tLoss: 1.066134\n",
      "Train Epoch: 3 [4400/6700 (66%)]\tLoss: 0.006101\n",
      "Train Epoch: 3 [4500/6700 (67%)]\tLoss: 1.779349\n",
      "Train Epoch: 3 [4600/6700 (69%)]\tLoss: 1.661196\n",
      "Train Epoch: 3 [4700/6700 (70%)]\tLoss: 0.177092\n",
      "Train Epoch: 3 [4800/6700 (72%)]\tLoss: 2.329959\n",
      "Train Epoch: 3 [4900/6700 (73%)]\tLoss: 0.204493\n",
      "Train Epoch: 3 [5000/6700 (75%)]\tLoss: 1.851310\n",
      "Train Epoch: 3 [5100/6700 (76%)]\tLoss: 0.086548\n",
      "Train Epoch: 3 [5200/6700 (78%)]\tLoss: 1.382392\n",
      "Train Epoch: 3 [5300/6700 (79%)]\tLoss: 0.515427\n",
      "Train Epoch: 3 [5400/6700 (81%)]\tLoss: 0.148474\n",
      "Train Epoch: 3 [5500/6700 (82%)]\tLoss: 2.319941\n",
      "Train Epoch: 3 [5600/6700 (84%)]\tLoss: 2.818436\n",
      "Train Epoch: 3 [5700/6700 (85%)]\tLoss: 2.669088\n",
      "Train Epoch: 3 [5800/6700 (87%)]\tLoss: 1.525743\n",
      "Train Epoch: 3 [5900/6700 (88%)]\tLoss: 0.094076\n",
      "Train Epoch: 3 [6000/6700 (90%)]\tLoss: 0.403571\n",
      "Train Epoch: 3 [6100/6700 (91%)]\tLoss: 0.004072\n",
      "Train Epoch: 3 [6200/6700 (93%)]\tLoss: 0.049373\n",
      "Train Epoch: 3 [6300/6700 (94%)]\tLoss: 0.028866\n",
      "Train Epoch: 3 [6400/6700 (96%)]\tLoss: 0.242928\n",
      "Train Epoch: 3 [6500/6700 (97%)]\tLoss: 0.215813\n",
      "Train Epoch: 3 [6600/6700 (99%)]\tLoss: 0.050858\n",
      "====> Epoch: 3 Average loss: 0.8950\n",
      "Train Epoch: 4 [0/6700 (0%)]\tLoss: 0.312617\n",
      "Train Epoch: 4 [100/6700 (1%)]\tLoss: 0.035907\n",
      "Train Epoch: 4 [200/6700 (3%)]\tLoss: 0.119244\n",
      "Train Epoch: 4 [300/6700 (4%)]\tLoss: 0.168673\n",
      "Train Epoch: 4 [400/6700 (6%)]\tLoss: 3.406347\n",
      "Train Epoch: 4 [500/6700 (7%)]\tLoss: 0.193697\n",
      "Train Epoch: 4 [600/6700 (9%)]\tLoss: 0.327917\n",
      "Train Epoch: 4 [700/6700 (10%)]\tLoss: 0.438645\n",
      "Train Epoch: 4 [800/6700 (12%)]\tLoss: 1.282815\n",
      "Train Epoch: 4 [900/6700 (13%)]\tLoss: 0.084129\n",
      "Train Epoch: 4 [1000/6700 (15%)]\tLoss: 2.485879\n",
      "Train Epoch: 4 [1100/6700 (16%)]\tLoss: 0.001988\n",
      "Train Epoch: 4 [1200/6700 (18%)]\tLoss: 5.910106\n",
      "Train Epoch: 4 [1300/6700 (19%)]\tLoss: 0.024007\n",
      "Train Epoch: 4 [1400/6700 (21%)]\tLoss: 0.018028\n",
      "Train Epoch: 4 [1500/6700 (22%)]\tLoss: 0.182604\n",
      "Train Epoch: 4 [1600/6700 (24%)]\tLoss: 0.008310\n",
      "Train Epoch: 4 [1700/6700 (25%)]\tLoss: 0.006065\n",
      "Train Epoch: 4 [1800/6700 (27%)]\tLoss: 0.674611\n",
      "Train Epoch: 4 [1900/6700 (28%)]\tLoss: 1.031247\n",
      "Train Epoch: 4 [2000/6700 (30%)]\tLoss: 6.465096\n",
      "Train Epoch: 4 [2100/6700 (31%)]\tLoss: 0.058595\n",
      "Train Epoch: 4 [2200/6700 (33%)]\tLoss: 0.975766\n",
      "Train Epoch: 4 [2300/6700 (34%)]\tLoss: 0.011438\n",
      "Train Epoch: 4 [2400/6700 (36%)]\tLoss: 0.082933\n",
      "Train Epoch: 4 [2500/6700 (37%)]\tLoss: 0.036404\n",
      "Train Epoch: 4 [2600/6700 (39%)]\tLoss: 0.447156\n",
      "Train Epoch: 4 [2700/6700 (40%)]\tLoss: 1.006084\n",
      "Train Epoch: 4 [2800/6700 (42%)]\tLoss: 0.109699\n",
      "Train Epoch: 4 [2900/6700 (43%)]\tLoss: 0.001620\n",
      "Train Epoch: 4 [3000/6700 (45%)]\tLoss: 0.732351\n",
      "Train Epoch: 4 [3100/6700 (46%)]\tLoss: 0.162476\n",
      "Train Epoch: 4 [3200/6700 (48%)]\tLoss: 0.149946\n",
      "Train Epoch: 4 [3300/6700 (49%)]\tLoss: 2.380825\n",
      "Train Epoch: 4 [3400/6700 (51%)]\tLoss: 0.027782\n",
      "Train Epoch: 4 [3500/6700 (52%)]\tLoss: 1.215932\n",
      "Train Epoch: 4 [3600/6700 (54%)]\tLoss: 2.164824\n",
      "Train Epoch: 4 [3700/6700 (55%)]\tLoss: 0.098303\n",
      "Train Epoch: 4 [3800/6700 (57%)]\tLoss: 0.041590\n",
      "Train Epoch: 4 [3900/6700 (58%)]\tLoss: 0.029473\n",
      "Train Epoch: 4 [4000/6700 (60%)]\tLoss: 1.592401\n",
      "Train Epoch: 4 [4100/6700 (61%)]\tLoss: 0.332798\n",
      "Train Epoch: 4 [4200/6700 (63%)]\tLoss: 0.004763\n",
      "Train Epoch: 4 [4300/6700 (64%)]\tLoss: 0.802504\n",
      "Train Epoch: 4 [4400/6700 (66%)]\tLoss: 0.005646\n",
      "Train Epoch: 4 [4500/6700 (67%)]\tLoss: 1.417122\n",
      "Train Epoch: 4 [4600/6700 (69%)]\tLoss: 1.109676\n",
      "Train Epoch: 4 [4700/6700 (70%)]\tLoss: 0.118633\n",
      "Train Epoch: 4 [4800/6700 (72%)]\tLoss: 2.697193\n",
      "Train Epoch: 4 [4900/6700 (73%)]\tLoss: 0.062072\n",
      "Train Epoch: 4 [5000/6700 (75%)]\tLoss: 1.207633\n",
      "Train Epoch: 4 [5100/6700 (76%)]\tLoss: 0.079998\n",
      "Train Epoch: 4 [5200/6700 (78%)]\tLoss: 0.936794\n",
      "Train Epoch: 4 [5300/6700 (79%)]\tLoss: 0.438110\n",
      "Train Epoch: 4 [5400/6700 (81%)]\tLoss: 0.171726\n",
      "Train Epoch: 4 [5500/6700 (82%)]\tLoss: 1.960487\n",
      "Train Epoch: 4 [5600/6700 (84%)]\tLoss: 2.266309\n",
      "Train Epoch: 4 [5700/6700 (85%)]\tLoss: 2.819089\n",
      "Train Epoch: 4 [5800/6700 (87%)]\tLoss: 1.478070\n",
      "Train Epoch: 4 [5900/6700 (88%)]\tLoss: 0.147636\n",
      "Train Epoch: 4 [6000/6700 (90%)]\tLoss: 0.252881\n",
      "Train Epoch: 4 [6100/6700 (91%)]\tLoss: 0.002414\n",
      "Train Epoch: 4 [6200/6700 (93%)]\tLoss: 0.035536\n",
      "Train Epoch: 4 [6300/6700 (94%)]\tLoss: 0.016539\n",
      "Train Epoch: 4 [6400/6700 (96%)]\tLoss: 0.149103\n",
      "Train Epoch: 4 [6500/6700 (97%)]\tLoss: 0.194624\n",
      "Train Epoch: 4 [6600/6700 (99%)]\tLoss: 0.023115\n",
      "====> Epoch: 4 Average loss: 0.7697\n",
      "Train Epoch: 5 [0/6700 (0%)]\tLoss: 0.188845\n",
      "Train Epoch: 5 [100/6700 (1%)]\tLoss: 0.021554\n",
      "Train Epoch: 5 [200/6700 (3%)]\tLoss: 0.134255\n",
      "Train Epoch: 5 [300/6700 (4%)]\tLoss: 0.051006\n",
      "Train Epoch: 5 [400/6700 (6%)]\tLoss: 2.663390\n",
      "Train Epoch: 5 [500/6700 (7%)]\tLoss: 0.303770\n",
      "Train Epoch: 5 [600/6700 (9%)]\tLoss: 0.233404\n",
      "Train Epoch: 5 [700/6700 (10%)]\tLoss: 0.409540\n",
      "Train Epoch: 5 [800/6700 (12%)]\tLoss: 1.157987\n",
      "Train Epoch: 5 [900/6700 (13%)]\tLoss: 0.073695\n",
      "Train Epoch: 5 [1000/6700 (15%)]\tLoss: 1.205920\n",
      "Train Epoch: 5 [1100/6700 (16%)]\tLoss: 0.030807\n",
      "Train Epoch: 5 [1200/6700 (18%)]\tLoss: 0.022300\n",
      "Train Epoch: 5 [1300/6700 (19%)]\tLoss: 0.018741\n",
      "Train Epoch: 5 [1400/6700 (21%)]\tLoss: 0.017804\n",
      "Train Epoch: 5 [1500/6700 (22%)]\tLoss: 0.137718\n",
      "Train Epoch: 5 [1600/6700 (24%)]\tLoss: 1.978884\n",
      "Train Epoch: 5 [1700/6700 (25%)]\tLoss: 0.003773\n",
      "Train Epoch: 5 [1800/6700 (27%)]\tLoss: 0.001933\n",
      "Train Epoch: 5 [1900/6700 (28%)]\tLoss: 0.733446\n",
      "Train Epoch: 5 [2000/6700 (30%)]\tLoss: 5.821757\n",
      "Train Epoch: 5 [2100/6700 (31%)]\tLoss: 0.036473\n",
      "Train Epoch: 5 [2200/6700 (33%)]\tLoss: 0.687799\n",
      "Train Epoch: 5 [2300/6700 (34%)]\tLoss: 0.010499\n",
      "Train Epoch: 5 [2400/6700 (36%)]\tLoss: 0.063713\n",
      "Train Epoch: 5 [2500/6700 (37%)]\tLoss: 0.045167\n",
      "Train Epoch: 5 [2600/6700 (39%)]\tLoss: 0.168423\n",
      "Train Epoch: 5 [2700/6700 (40%)]\tLoss: 0.720369\n",
      "Train Epoch: 5 [2800/6700 (42%)]\tLoss: 0.160290\n",
      "Train Epoch: 5 [2900/6700 (43%)]\tLoss: 0.000763\n",
      "Train Epoch: 5 [3000/6700 (45%)]\tLoss: 0.735557\n",
      "Train Epoch: 5 [3100/6700 (46%)]\tLoss: 0.132206\n",
      "Train Epoch: 5 [3200/6700 (48%)]\tLoss: 0.181107\n",
      "Train Epoch: 5 [3300/6700 (49%)]\tLoss: 2.295967\n",
      "Train Epoch: 5 [3400/6700 (51%)]\tLoss: 0.028120\n",
      "Train Epoch: 5 [3500/6700 (52%)]\tLoss: 0.000001\n",
      "Train Epoch: 5 [3600/6700 (54%)]\tLoss: 1.460000\n",
      "Train Epoch: 5 [3700/6700 (55%)]\tLoss: 0.124239\n",
      "Train Epoch: 5 [3800/6700 (57%)]\tLoss: 0.024179\n",
      "Train Epoch: 5 [3900/6700 (58%)]\tLoss: 0.010722\n",
      "Train Epoch: 5 [4000/6700 (60%)]\tLoss: 0.674789\n",
      "Train Epoch: 5 [4100/6700 (61%)]\tLoss: 0.367526\n",
      "Train Epoch: 5 [4200/6700 (63%)]\tLoss: 0.003211\n",
      "Train Epoch: 5 [4300/6700 (64%)]\tLoss: 0.493300\n",
      "Train Epoch: 5 [4400/6700 (66%)]\tLoss: 0.001875\n",
      "Train Epoch: 5 [4500/6700 (67%)]\tLoss: 0.913957\n",
      "Train Epoch: 5 [4600/6700 (69%)]\tLoss: 0.601328\n",
      "Train Epoch: 5 [4700/6700 (70%)]\tLoss: 0.094282\n",
      "Train Epoch: 5 [4800/6700 (72%)]\tLoss: 2.603652\n",
      "Train Epoch: 5 [4900/6700 (73%)]\tLoss: 0.032926\n",
      "Train Epoch: 5 [5000/6700 (75%)]\tLoss: 0.686948\n",
      "Train Epoch: 5 [5100/6700 (76%)]\tLoss: 0.034922\n",
      "Train Epoch: 5 [5200/6700 (78%)]\tLoss: 0.476208\n",
      "Train Epoch: 5 [5300/6700 (79%)]\tLoss: 0.469291\n",
      "Train Epoch: 5 [5400/6700 (81%)]\tLoss: 0.180899\n",
      "Train Epoch: 5 [5500/6700 (82%)]\tLoss: 6.444139\n",
      "Train Epoch: 5 [5600/6700 (84%)]\tLoss: 1.554086\n",
      "Train Epoch: 5 [5700/6700 (85%)]\tLoss: 2.360974\n",
      "Train Epoch: 5 [5800/6700 (87%)]\tLoss: 1.243462\n",
      "Train Epoch: 5 [5900/6700 (88%)]\tLoss: 0.190857\n",
      "Train Epoch: 5 [6000/6700 (90%)]\tLoss: 0.118582\n",
      "Train Epoch: 5 [6100/6700 (91%)]\tLoss: 0.000915\n",
      "Train Epoch: 5 [6200/6700 (93%)]\tLoss: 0.042407\n",
      "Train Epoch: 5 [6300/6700 (94%)]\tLoss: 0.021339\n",
      "Train Epoch: 5 [6400/6700 (96%)]\tLoss: 0.078510\n",
      "Train Epoch: 5 [6500/6700 (97%)]\tLoss: 0.165962\n",
      "Train Epoch: 5 [6600/6700 (99%)]\tLoss: 0.020862\n",
      "====> Epoch: 5 Average loss: 0.7014\n",
      "Train Epoch: 6 [0/6700 (0%)]\tLoss: 0.452299\n",
      "Train Epoch: 6 [100/6700 (1%)]\tLoss: 0.014436\n",
      "Train Epoch: 6 [200/6700 (3%)]\tLoss: 0.099876\n",
      "Train Epoch: 6 [300/6700 (4%)]\tLoss: 0.063423\n",
      "Train Epoch: 6 [400/6700 (6%)]\tLoss: 4.107328\n",
      "Train Epoch: 6 [500/6700 (7%)]\tLoss: 0.309595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [600/6700 (9%)]\tLoss: 0.177326\n",
      "Train Epoch: 6 [700/6700 (10%)]\tLoss: 0.323159\n",
      "Train Epoch: 6 [800/6700 (12%)]\tLoss: 0.818677\n",
      "Train Epoch: 6 [900/6700 (13%)]\tLoss: 0.082390\n",
      "Train Epoch: 6 [1000/6700 (15%)]\tLoss: 0.507445\n",
      "Train Epoch: 6 [1100/6700 (16%)]\tLoss: 0.049179\n",
      "Train Epoch: 6 [1200/6700 (18%)]\tLoss: 0.182306\n",
      "Train Epoch: 6 [1300/6700 (19%)]\tLoss: 0.020370\n",
      "Train Epoch: 6 [1400/6700 (21%)]\tLoss: 0.005878\n",
      "Train Epoch: 6 [1500/6700 (22%)]\tLoss: 0.096973\n",
      "Train Epoch: 6 [1600/6700 (24%)]\tLoss: 0.000310\n",
      "Train Epoch: 6 [1700/6700 (25%)]\tLoss: 0.001634\n",
      "Train Epoch: 6 [1800/6700 (27%)]\tLoss: 0.012320\n",
      "Train Epoch: 6 [1900/6700 (28%)]\tLoss: 0.427249\n",
      "Train Epoch: 6 [2000/6700 (30%)]\tLoss: 6.026429\n",
      "Train Epoch: 6 [2100/6700 (31%)]\tLoss: 0.027305\n",
      "Train Epoch: 6 [2200/6700 (33%)]\tLoss: 0.570731\n",
      "Train Epoch: 6 [2300/6700 (34%)]\tLoss: 0.004261\n",
      "Train Epoch: 6 [2400/6700 (36%)]\tLoss: 0.072330\n",
      "Train Epoch: 6 [2500/6700 (37%)]\tLoss: 0.050775\n",
      "Train Epoch: 6 [2600/6700 (39%)]\tLoss: 0.161449\n",
      "Train Epoch: 6 [2700/6700 (40%)]\tLoss: 0.462479\n",
      "Train Epoch: 6 [2800/6700 (42%)]\tLoss: 0.095724\n",
      "Train Epoch: 6 [2900/6700 (43%)]\tLoss: 0.000188\n",
      "Train Epoch: 6 [3000/6700 (45%)]\tLoss: 0.661491\n",
      "Train Epoch: 6 [3100/6700 (46%)]\tLoss: 0.083400\n",
      "Train Epoch: 6 [3200/6700 (48%)]\tLoss: 0.143928\n",
      "Train Epoch: 6 [3300/6700 (49%)]\tLoss: 2.257053\n",
      "Train Epoch: 6 [3400/6700 (51%)]\tLoss: 0.023525\n",
      "Train Epoch: 6 [3500/6700 (52%)]\tLoss: 0.074338\n",
      "Train Epoch: 6 [3600/6700 (54%)]\tLoss: 1.401872\n",
      "Train Epoch: 6 [3700/6700 (55%)]\tLoss: 0.127490\n",
      "Train Epoch: 6 [3800/6700 (57%)]\tLoss: 0.050899\n",
      "Train Epoch: 6 [3900/6700 (58%)]\tLoss: 0.008485\n",
      "Train Epoch: 6 [4000/6700 (60%)]\tLoss: 2.259363\n",
      "Train Epoch: 6 [4100/6700 (61%)]\tLoss: 0.437207\n",
      "Train Epoch: 6 [4200/6700 (63%)]\tLoss: 0.000911\n",
      "Train Epoch: 6 [4300/6700 (64%)]\tLoss: 0.850179\n",
      "Train Epoch: 6 [4400/6700 (66%)]\tLoss: 0.000483\n",
      "Train Epoch: 6 [4500/6700 (67%)]\tLoss: 0.664252\n",
      "Train Epoch: 6 [4600/6700 (69%)]\tLoss: 0.755178\n",
      "Train Epoch: 6 [4700/6700 (70%)]\tLoss: 0.073466\n",
      "Train Epoch: 6 [4800/6700 (72%)]\tLoss: 2.527415\n",
      "Train Epoch: 6 [4900/6700 (73%)]\tLoss: 0.019550\n",
      "Train Epoch: 6 [5000/6700 (75%)]\tLoss: 0.623475\n",
      "Train Epoch: 6 [5100/6700 (76%)]\tLoss: 0.016388\n",
      "Train Epoch: 6 [5200/6700 (78%)]\tLoss: 0.543706\n",
      "Train Epoch: 6 [5300/6700 (79%)]\tLoss: 0.393755\n",
      "Train Epoch: 6 [5400/6700 (81%)]\tLoss: 0.144301\n",
      "Train Epoch: 6 [5500/6700 (82%)]\tLoss: 1.016174\n",
      "Train Epoch: 6 [5600/6700 (84%)]\tLoss: 0.976506\n",
      "Train Epoch: 6 [5700/6700 (85%)]\tLoss: 3.351353\n",
      "Train Epoch: 6 [5800/6700 (87%)]\tLoss: 1.419175\n",
      "Train Epoch: 6 [5900/6700 (88%)]\tLoss: 0.339123\n",
      "Train Epoch: 6 [6000/6700 (90%)]\tLoss: 0.715409\n",
      "Train Epoch: 6 [6100/6700 (91%)]\tLoss: 0.000457\n",
      "Train Epoch: 6 [6200/6700 (93%)]\tLoss: 0.021941\n",
      "Train Epoch: 6 [6300/6700 (94%)]\tLoss: 0.015870\n",
      "Train Epoch: 6 [6400/6700 (96%)]\tLoss: 0.075437\n",
      "Train Epoch: 6 [6500/6700 (97%)]\tLoss: 0.126725\n",
      "Train Epoch: 6 [6600/6700 (99%)]\tLoss: 0.011718\n",
      "====> Epoch: 6 Average loss: 0.6217\n",
      "Train Epoch: 7 [0/6700 (0%)]\tLoss: 0.257592\n",
      "Train Epoch: 7 [100/6700 (1%)]\tLoss: 0.008060\n",
      "Train Epoch: 7 [200/6700 (3%)]\tLoss: 0.142841\n",
      "Train Epoch: 7 [300/6700 (4%)]\tLoss: 0.024585\n",
      "Train Epoch: 7 [400/6700 (6%)]\tLoss: 2.429160\n",
      "Train Epoch: 7 [500/6700 (7%)]\tLoss: 0.287127\n",
      "Train Epoch: 7 [600/6700 (9%)]\tLoss: 0.112915\n",
      "Train Epoch: 7 [700/6700 (10%)]\tLoss: 0.460675\n",
      "Train Epoch: 7 [800/6700 (12%)]\tLoss: 1.067346\n",
      "Train Epoch: 7 [900/6700 (13%)]\tLoss: 0.108899\n",
      "Train Epoch: 7 [1000/6700 (15%)]\tLoss: 0.349002\n",
      "Train Epoch: 7 [1100/6700 (16%)]\tLoss: 0.023101\n",
      "Train Epoch: 7 [1200/6700 (18%)]\tLoss: 0.087512\n",
      "Train Epoch: 7 [1300/6700 (19%)]\tLoss: 0.016928\n",
      "Train Epoch: 7 [1400/6700 (21%)]\tLoss: 0.005155\n",
      "Train Epoch: 7 [1500/6700 (22%)]\tLoss: 0.094519\n",
      "Train Epoch: 7 [1600/6700 (24%)]\tLoss: 0.026314\n",
      "Train Epoch: 7 [1700/6700 (25%)]\tLoss: 0.000524\n",
      "Train Epoch: 7 [1800/6700 (27%)]\tLoss: 0.001361\n",
      "Train Epoch: 7 [1900/6700 (28%)]\tLoss: 0.545008\n",
      "Train Epoch: 7 [2000/6700 (30%)]\tLoss: 5.917023\n",
      "Train Epoch: 7 [2100/6700 (31%)]\tLoss: 0.023732\n",
      "Train Epoch: 7 [2200/6700 (33%)]\tLoss: 0.204893\n",
      "Train Epoch: 7 [2300/6700 (34%)]\tLoss: 0.005145\n",
      "Train Epoch: 7 [2400/6700 (36%)]\tLoss: 0.090370\n",
      "Train Epoch: 7 [2500/6700 (37%)]\tLoss: 0.043771\n",
      "Train Epoch: 7 [2600/6700 (39%)]\tLoss: 0.160464\n",
      "Train Epoch: 7 [2700/6700 (40%)]\tLoss: 0.450502\n",
      "Train Epoch: 7 [2800/6700 (42%)]\tLoss: 0.113088\n",
      "Train Epoch: 7 [2900/6700 (43%)]\tLoss: 0.000088\n",
      "Train Epoch: 7 [3000/6700 (45%)]\tLoss: 0.716683\n",
      "Train Epoch: 7 [3100/6700 (46%)]\tLoss: 0.050796\n",
      "Train Epoch: 7 [3200/6700 (48%)]\tLoss: 0.147033\n",
      "Train Epoch: 7 [3300/6700 (49%)]\tLoss: 3.335016\n",
      "Train Epoch: 7 [3400/6700 (51%)]\tLoss: 0.026849\n",
      "Train Epoch: 7 [3500/6700 (52%)]\tLoss: 3.126963\n",
      "Train Epoch: 7 [3600/6700 (54%)]\tLoss: 3.080588\n",
      "Train Epoch: 7 [3700/6700 (55%)]\tLoss: 0.103515\n",
      "Train Epoch: 7 [3800/6700 (57%)]\tLoss: 0.036200\n",
      "Train Epoch: 7 [3900/6700 (58%)]\tLoss: 0.010575\n",
      "Train Epoch: 7 [4000/6700 (60%)]\tLoss: 1.109440\n",
      "Train Epoch: 7 [4100/6700 (61%)]\tLoss: 0.567891\n",
      "Train Epoch: 7 [4200/6700 (63%)]\tLoss: 0.000688\n",
      "Train Epoch: 7 [4300/6700 (64%)]\tLoss: 0.194866\n",
      "Train Epoch: 7 [4400/6700 (66%)]\tLoss: 0.000189\n",
      "Train Epoch: 7 [4500/6700 (67%)]\tLoss: 0.921113\n",
      "Train Epoch: 7 [4600/6700 (69%)]\tLoss: 0.519955\n",
      "Train Epoch: 7 [4700/6700 (70%)]\tLoss: 0.050440\n",
      "Train Epoch: 7 [4800/6700 (72%)]\tLoss: 2.648196\n",
      "Train Epoch: 7 [4900/6700 (73%)]\tLoss: 0.012084\n",
      "Train Epoch: 7 [5000/6700 (75%)]\tLoss: 0.518875\n",
      "Train Epoch: 7 [5100/6700 (76%)]\tLoss: 0.014059\n",
      "Train Epoch: 7 [5200/6700 (78%)]\tLoss: 0.322711\n",
      "Train Epoch: 7 [5300/6700 (79%)]\tLoss: 0.323700\n",
      "Train Epoch: 7 [5400/6700 (81%)]\tLoss: 0.146482\n",
      "Train Epoch: 7 [5500/6700 (82%)]\tLoss: 0.624672\n",
      "Train Epoch: 7 [5600/6700 (84%)]\tLoss: 1.049134\n",
      "Train Epoch: 7 [5700/6700 (85%)]\tLoss: 3.038287\n",
      "Train Epoch: 7 [5800/6700 (87%)]\tLoss: 1.415923\n",
      "Train Epoch: 7 [5900/6700 (88%)]\tLoss: 0.248685\n",
      "Train Epoch: 7 [6000/6700 (90%)]\tLoss: 0.141257\n",
      "Train Epoch: 7 [6100/6700 (91%)]\tLoss: 0.000443\n",
      "Train Epoch: 7 [6200/6700 (93%)]\tLoss: 0.021753\n",
      "Train Epoch: 7 [6300/6700 (94%)]\tLoss: 0.010246\n",
      "Train Epoch: 7 [6400/6700 (96%)]\tLoss: 0.063602\n",
      "Train Epoch: 7 [6500/6700 (97%)]\tLoss: 0.179158\n",
      "Train Epoch: 7 [6600/6700 (99%)]\tLoss: 0.009390\n",
      "====> Epoch: 7 Average loss: 0.5682\n",
      "Train Epoch: 8 [0/6700 (0%)]\tLoss: 0.312101\n",
      "Train Epoch: 8 [100/6700 (1%)]\tLoss: 0.006538\n",
      "Train Epoch: 8 [200/6700 (3%)]\tLoss: 0.129050\n",
      "Train Epoch: 8 [300/6700 (4%)]\tLoss: 0.023956\n",
      "Train Epoch: 8 [400/6700 (6%)]\tLoss: 1.658880\n",
      "Train Epoch: 8 [500/6700 (7%)]\tLoss: 0.298392\n",
      "Train Epoch: 8 [600/6700 (9%)]\tLoss: 0.086706\n",
      "Train Epoch: 8 [700/6700 (10%)]\tLoss: 0.384089\n",
      "Train Epoch: 8 [800/6700 (12%)]\tLoss: 0.822123\n",
      "Train Epoch: 8 [900/6700 (13%)]\tLoss: 0.084341\n",
      "Train Epoch: 8 [1000/6700 (15%)]\tLoss: 0.255724\n",
      "Train Epoch: 8 [1100/6700 (16%)]\tLoss: 0.001534\n",
      "Train Epoch: 8 [1200/6700 (18%)]\tLoss: 0.005968\n",
      "Train Epoch: 8 [1300/6700 (19%)]\tLoss: 0.012019\n",
      "Train Epoch: 8 [1400/6700 (21%)]\tLoss: 0.007080\n",
      "Train Epoch: 8 [1500/6700 (22%)]\tLoss: 0.088453\n",
      "Train Epoch: 8 [1600/6700 (24%)]\tLoss: 0.023448\n",
      "Train Epoch: 8 [1700/6700 (25%)]\tLoss: 0.000225\n",
      "Train Epoch: 8 [1800/6700 (27%)]\tLoss: 0.000621\n",
      "Train Epoch: 8 [1900/6700 (28%)]\tLoss: 0.444041\n",
      "Train Epoch: 8 [2000/6700 (30%)]\tLoss: 6.527614\n",
      "Train Epoch: 8 [2100/6700 (31%)]\tLoss: 0.036364\n",
      "Train Epoch: 8 [2200/6700 (33%)]\tLoss: 0.199816\n",
      "Train Epoch: 8 [2300/6700 (34%)]\tLoss: 0.001935\n",
      "Train Epoch: 8 [2400/6700 (36%)]\tLoss: 0.073822\n",
      "Train Epoch: 8 [2500/6700 (37%)]\tLoss: 0.035888\n",
      "Train Epoch: 8 [2600/6700 (39%)]\tLoss: 0.081350\n",
      "Train Epoch: 8 [2700/6700 (40%)]\tLoss: 0.173660\n",
      "Train Epoch: 8 [2800/6700 (42%)]\tLoss: 0.070870\n",
      "Train Epoch: 8 [2900/6700 (43%)]\tLoss: 0.000042\n",
      "Train Epoch: 8 [3000/6700 (45%)]\tLoss: 0.796231\n",
      "Train Epoch: 8 [3100/6700 (46%)]\tLoss: 0.071607\n",
      "Train Epoch: 8 [3200/6700 (48%)]\tLoss: 0.152072\n",
      "Train Epoch: 8 [3300/6700 (49%)]\tLoss: 1.373277\n",
      "Train Epoch: 8 [3400/6700 (51%)]\tLoss: 0.033438\n",
      "Train Epoch: 8 [3500/6700 (52%)]\tLoss: 0.000389\n",
      "Train Epoch: 8 [3600/6700 (54%)]\tLoss: 1.122450\n",
      "Train Epoch: 8 [3700/6700 (55%)]\tLoss: 0.138056\n",
      "Train Epoch: 8 [3800/6700 (57%)]\tLoss: 0.043137\n",
      "Train Epoch: 8 [3900/6700 (58%)]\tLoss: 0.007744\n",
      "Train Epoch: 8 [4000/6700 (60%)]\tLoss: 2.312443\n",
      "Train Epoch: 8 [4100/6700 (61%)]\tLoss: 0.437379\n",
      "Train Epoch: 8 [4200/6700 (63%)]\tLoss: 0.001615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [4300/6700 (64%)]\tLoss: 0.771900\n",
      "Train Epoch: 8 [4400/6700 (66%)]\tLoss: 0.000346\n",
      "Train Epoch: 8 [4500/6700 (67%)]\tLoss: 0.441234\n",
      "Train Epoch: 8 [4600/6700 (69%)]\tLoss: 0.321379\n",
      "Train Epoch: 8 [4700/6700 (70%)]\tLoss: 0.059993\n",
      "Train Epoch: 8 [4800/6700 (72%)]\tLoss: 3.109362\n",
      "Train Epoch: 8 [4900/6700 (73%)]\tLoss: 0.007931\n",
      "Train Epoch: 8 [5000/6700 (75%)]\tLoss: 0.294278\n",
      "Train Epoch: 8 [5100/6700 (76%)]\tLoss: 0.019273\n",
      "Train Epoch: 8 [5200/6700 (78%)]\tLoss: 0.263948\n",
      "Train Epoch: 8 [5300/6700 (79%)]\tLoss: 0.365098\n",
      "Train Epoch: 8 [5400/6700 (81%)]\tLoss: 0.105974\n",
      "Train Epoch: 8 [5500/6700 (82%)]\tLoss: 0.162612\n",
      "Train Epoch: 8 [5600/6700 (84%)]\tLoss: 0.717741\n",
      "Train Epoch: 8 [5700/6700 (85%)]\tLoss: 2.886226\n",
      "Train Epoch: 8 [5800/6700 (87%)]\tLoss: 1.029425\n",
      "Train Epoch: 8 [5900/6700 (88%)]\tLoss: 0.152177\n",
      "Train Epoch: 8 [6000/6700 (90%)]\tLoss: 0.816631\n",
      "Train Epoch: 8 [6100/6700 (91%)]\tLoss: 0.000210\n",
      "Train Epoch: 8 [6200/6700 (93%)]\tLoss: 0.005838\n",
      "Train Epoch: 8 [6300/6700 (94%)]\tLoss: 0.009235\n",
      "Train Epoch: 8 [6400/6700 (96%)]\tLoss: 0.033521\n",
      "Train Epoch: 8 [6500/6700 (97%)]\tLoss: 0.079080\n",
      "Train Epoch: 8 [6600/6700 (99%)]\tLoss: 0.008087\n",
      "====> Epoch: 8 Average loss: 0.5265\n",
      "Train Epoch: 9 [0/6700 (0%)]\tLoss: 0.261288\n",
      "Train Epoch: 9 [100/6700 (1%)]\tLoss: 0.005487\n",
      "Train Epoch: 9 [200/6700 (3%)]\tLoss: 0.169947\n",
      "Train Epoch: 9 [300/6700 (4%)]\tLoss: 0.004508\n",
      "Train Epoch: 9 [400/6700 (6%)]\tLoss: 2.211250\n",
      "Train Epoch: 9 [500/6700 (7%)]\tLoss: 0.292119\n",
      "Train Epoch: 9 [600/6700 (9%)]\tLoss: 0.042976\n",
      "Train Epoch: 9 [700/6700 (10%)]\tLoss: 0.368353\n",
      "Train Epoch: 9 [800/6700 (12%)]\tLoss: 1.036256\n",
      "Train Epoch: 9 [900/6700 (13%)]\tLoss: 0.098648\n",
      "Train Epoch: 9 [1000/6700 (15%)]\tLoss: 0.104193\n",
      "Train Epoch: 9 [1100/6700 (16%)]\tLoss: 0.030201\n",
      "Train Epoch: 9 [1200/6700 (18%)]\tLoss: 0.020313\n",
      "Train Epoch: 9 [1300/6700 (19%)]\tLoss: 0.018976\n",
      "Train Epoch: 9 [1400/6700 (21%)]\tLoss: 0.003831\n",
      "Train Epoch: 9 [1500/6700 (22%)]\tLoss: 0.077984\n",
      "Train Epoch: 9 [1600/6700 (24%)]\tLoss: 0.001592\n",
      "Train Epoch: 9 [1700/6700 (25%)]\tLoss: 0.000026\n",
      "Train Epoch: 9 [1800/6700 (27%)]\tLoss: 0.000144\n",
      "Train Epoch: 9 [1900/6700 (28%)]\tLoss: 0.457711\n",
      "Train Epoch: 9 [2000/6700 (30%)]\tLoss: 5.983302\n",
      "Train Epoch: 9 [2100/6700 (31%)]\tLoss: 0.027549\n",
      "Train Epoch: 9 [2200/6700 (33%)]\tLoss: 0.112402\n",
      "Train Epoch: 9 [2300/6700 (34%)]\tLoss: 0.005304\n",
      "Train Epoch: 9 [2400/6700 (36%)]\tLoss: 0.086379\n",
      "Train Epoch: 9 [2500/6700 (37%)]\tLoss: 0.042279\n",
      "Train Epoch: 9 [2600/6700 (39%)]\tLoss: 0.078622\n",
      "Train Epoch: 9 [2700/6700 (40%)]\tLoss: 0.148836\n",
      "Train Epoch: 9 [2800/6700 (42%)]\tLoss: 0.059142\n",
      "Train Epoch: 9 [2900/6700 (43%)]\tLoss: 0.000017\n",
      "Train Epoch: 9 [3000/6700 (45%)]\tLoss: 0.648082\n",
      "Train Epoch: 9 [3100/6700 (46%)]\tLoss: 0.020432\n",
      "Train Epoch: 9 [3200/6700 (48%)]\tLoss: 0.160284\n",
      "Train Epoch: 9 [3300/6700 (49%)]\tLoss: 2.453766\n",
      "Train Epoch: 9 [3400/6700 (51%)]\tLoss: 0.052603\n",
      "Train Epoch: 9 [3500/6700 (52%)]\tLoss: 0.010304\n",
      "Train Epoch: 9 [3600/6700 (54%)]\tLoss: 1.335239\n",
      "Train Epoch: 9 [3700/6700 (55%)]\tLoss: 0.136432\n",
      "Train Epoch: 9 [3800/6700 (57%)]\tLoss: 0.016415\n",
      "Train Epoch: 9 [3900/6700 (58%)]\tLoss: 0.005518\n",
      "Train Epoch: 9 [4000/6700 (60%)]\tLoss: 2.615640\n",
      "Train Epoch: 9 [4100/6700 (61%)]\tLoss: 0.424315\n",
      "Train Epoch: 9 [4200/6700 (63%)]\tLoss: 0.000572\n",
      "Train Epoch: 9 [4300/6700 (64%)]\tLoss: 0.142612\n",
      "Train Epoch: 9 [4400/6700 (66%)]\tLoss: 0.000052\n",
      "Train Epoch: 9 [4500/6700 (67%)]\tLoss: 0.354585\n",
      "Train Epoch: 9 [4600/6700 (69%)]\tLoss: 0.226699\n",
      "Train Epoch: 9 [4700/6700 (70%)]\tLoss: 0.021678\n",
      "Train Epoch: 9 [4800/6700 (72%)]\tLoss: 3.040078\n",
      "Train Epoch: 9 [4900/6700 (73%)]\tLoss: 0.006710\n",
      "Train Epoch: 9 [5000/6700 (75%)]\tLoss: 0.381485\n",
      "Train Epoch: 9 [5100/6700 (76%)]\tLoss: 0.004440\n",
      "Train Epoch: 9 [5200/6700 (78%)]\tLoss: 0.275822\n",
      "Train Epoch: 9 [5300/6700 (79%)]\tLoss: 0.224154\n",
      "Train Epoch: 9 [5400/6700 (81%)]\tLoss: 0.132434\n",
      "Train Epoch: 9 [5500/6700 (82%)]\tLoss: 0.686840\n",
      "Train Epoch: 9 [5600/6700 (84%)]\tLoss: 0.756241\n",
      "Train Epoch: 9 [5700/6700 (85%)]\tLoss: 3.029126\n",
      "Train Epoch: 9 [5800/6700 (87%)]\tLoss: 0.903185\n",
      "Train Epoch: 9 [5900/6700 (88%)]\tLoss: 0.091033\n",
      "Train Epoch: 9 [6000/6700 (90%)]\tLoss: 0.028934\n",
      "Train Epoch: 9 [6100/6700 (91%)]\tLoss: 0.000182\n",
      "Train Epoch: 9 [6200/6700 (93%)]\tLoss: 0.006891\n",
      "Train Epoch: 9 [6300/6700 (94%)]\tLoss: 0.006292\n",
      "Train Epoch: 9 [6400/6700 (96%)]\tLoss: 0.035882\n",
      "Train Epoch: 9 [6500/6700 (97%)]\tLoss: 0.091371\n",
      "Train Epoch: 9 [6600/6700 (99%)]\tLoss: 0.005594\n",
      "====> Epoch: 9 Average loss: 0.4961\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@1: 0.780 prec@3: 0.926 prec@5: 0.962\n",
      "mprec@1: 5.306e-01 mprec@3: 7.742e-01 mprec@5: 8.665e-01\n",
      "prec matrix [0.78       0.88818182 0.92606061 0.94606061 0.96151515]\n",
      "mprec matrix [0.53062151 0.69080002 0.77422045 0.82144886 0.86652688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Vpy35/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(test_set_X)\n",
    "k = 5\n",
    "y_pr = ans.numpy() \n",
    "y_pred = np.argsort(-y_pr,axis=1)[:,:k]\n",
    "# eval functions for Deep Learning\n",
    "preck = utils.getPrecAtK( y_test, y_pred, k )\n",
    "# The macro precision code takes a bit longer to execute due to the for loop over labels\n",
    "mpreck = utils.getMPrecAtK( y_test, y_pred, k )\n",
    "\n",
    "# According to our definitions, both prec@k and mprec@k should go up as k goes up i.e. for your\n",
    "# method, prec@i > prec@j if i > j and mprec@i > mprec@j if i > j. See the assignment description\n",
    "# to convince yourself why this must be the case.\n",
    "\n",
    "print( \"prec@1: %0.3f\" % preck[0], \"prec@3: %0.3f\" % preck[2], \"prec@5: %0.3f\" % preck[4] )\n",
    "# Dont be surprised if mprec is small -- it is hard to do well on rare error classes\n",
    "print( \"mprec@1: %0.3e\" % mpreck[0], \"mprec@3: %0.3e\" % mpreck[2], \"mprec@5: %0.3e\" % mpreck[4] )\n",
    "print (\"prec matrix\",preck)\n",
    "print (\"mprec matrix\",mpreck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
